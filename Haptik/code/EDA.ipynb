{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "metropolitan-census",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys\n",
    "from constants import *\n",
    "from utility import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "concrete-solomon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.57 ms, sys: 807 µs, total: 3.37 ms\n",
      "Wall time: 2.64 ms\n",
      "CPU times: user 2.56 ms, sys: 576 µs, total: 3.14 ms\n",
      "Wall time: 2.67 ms\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "%time df_train = pd.read_csv(TRAIN_FN)\n",
    "%time df_test = pd.read_csv(TEST_FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "medical-kelly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  (328, 2) \t (397, 2)\n",
      "shape after dropping duplicates:  (324, 2) \t (394, 2)\n",
      "                                         sentence label\n",
      "0                    You guys provide EMI option?   EMI\n",
      "1  Do you offer Zero Percent EMI payment options?   EMI\n",
      "2                                         0% EMI.   EMI\n",
      "3                                             EMI   EMI\n",
      "4                           I want in installment   EMI\n",
      "                                   sentence              label\n",
      "0                   There are only 2 models  NO_NODES_DETECTED\n",
      "1                                    Single  NO_NODES_DETECTED\n",
      "2  What's difference between ergo and ortho         COMPARISON\n",
      "3                              Return order    RETURN_EXCHANGE\n",
      "4               Hai not recieved my product  DELAY_IN_DELIVERY\n"
     ]
    }
   ],
   "source": [
    "print('shape: ', df_train.shape, '\\t', df_test.shape)\n",
    "df_train.drop_duplicates(inplace=True)\n",
    "df_test.drop_duplicates(inplace=True)\n",
    "print('shape after dropping duplicates: ', df_train.shape, '\\t', df_test.shape)\n",
    "print(df_train.head())\n",
    "print(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "substantial-detective",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class distribution in Train\n",
      "\n",
      "DISTRIBUTORS             33\n",
      "EMI                      25\n",
      "LEAD_GEN                 21\n",
      "MATTRESS_COST            21\n",
      "PRODUCT_VARIANTS         21\n",
      "ORDER_STATUS             20\n",
      "WHAT_SIZE_TO_ORDER       19\n",
      "100_NIGHT_TRIAL_OFFER    18\n",
      "ORTHO_FEATURES           17\n",
      "RETURN_EXCHANGE          14\n",
      "COD                      12\n",
      "DELAY_IN_DELIVERY        11\n",
      "ABOUT_SOF_MATTRESS       11\n",
      "ERGO_FEATURES            11\n",
      "COMPARISON               11\n",
      "PILLOWS                  10\n",
      "OFFERS                   10\n",
      "CHECK_PINCODE            10\n",
      "WARRANTY                 10\n",
      "CANCEL_ORDER             10\n",
      "SIZE_CUSTOMIZATION        9\n",
      "Name: label, dtype: int64\n",
      "\n",
      "XXX\n",
      "\n",
      "class distribution in Test\n",
      "\n",
      "NO_NODES_DETECTED        163\n",
      "SIZE_CUSTOMIZATION        24\n",
      "CHECK_PINCODE             22\n",
      "MATTRESS_COST             21\n",
      "COMPARISON                18\n",
      "LEAD_GEN                  16\n",
      "EMI                       16\n",
      "DELAY_IN_DELIVERY         13\n",
      "PILLOWS                   13\n",
      "RETURN_EXCHANGE           12\n",
      "ORTHO_FEATURES            11\n",
      "WHAT_SIZE_TO_ORDER         9\n",
      "OFFERS                     9\n",
      "PRODUCT_VARIANTS           8\n",
      "COD                        8\n",
      "ORDER_STATUS               8\n",
      "DISTRIBUTORS               7\n",
      "CANCEL_ORDER               6\n",
      "100_NIGHT_TRIAL_OFFER      5\n",
      "ERGO_FEATURES              3\n",
      "ABOUT_SOF_MATTRESS         2\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('class distribution in Train\\n')\n",
    "print(df_train['label'].value_counts())\n",
    "print('\\nXXX\\n')\n",
    "print('class distribution in Test\\n')\n",
    "print(df_test['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "choice-drink",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes in test that are not in train\n",
      "{'NO_NODES_DETECTED'}\n",
      "\n",
      "classes in train that are not in test\n",
      "{'WARRANTY'}\n"
     ]
    }
   ],
   "source": [
    "print('classes in test that are not in train')\n",
    "train_labels = df_train['label'].unique().tolist()\n",
    "test_labels = df_test['label'].unique().tolist()\n",
    "print(set(test_labels) - set(train_labels))\n",
    "\n",
    "print('\\nclasses in train that are not in test')\n",
    "print(set(train_labels) - set(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "affecting-reading",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_obj = Text_Preprocessing(keep_eng=False, remove_nonalpha=True, lower_case=True,\n",
    "                         remove_punkt=False, remove_stop=False, remove_numerals=False,\n",
    "                         spell_check=False, contraction=True,\n",
    "                         contraction_var=CONTRACTIONS, stem=False,\n",
    "                         lem=False, filter_pos=False, pos_var=('N', 'J'),\n",
    "                         tokenize=True, template_removal=False,\n",
    "                         template_start_string='', regex_cleaning=False,\n",
    "                         remove_ignore_words=False, ignore_words=IGNORE_WORDS,\n",
    "                         custom_stoplist=[], word_size=2, word_size_filter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "minute-current",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's been a month\n",
      "contraction\n",
      "lower case\n",
      "remove non-alphabets\n",
      "tokenization\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25a7991763244ee880f16be3e77776e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['it', 'has', 'been', 'a', 'month']\n"
     ]
    }
   ],
   "source": [
    "a = df_train.loc[252, 'sentence']\n",
    "print(a)\n",
    "a_pre = preprocess_obj.fit_transform(pd.Series([a])).values[0]\n",
    "print(a_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "industrial-suite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contraction\n",
      "lower case\n",
      "remove non-alphabets\n",
      "tokenization\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58eba63e53bd4315be0a8bf012d832e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contraction\n",
      "lower case\n",
      "remove non-alphabets\n",
      "tokenization\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afe3d4d28df34d6f95b60390de136b4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/394 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Vocab Size:  271 \t Test Vocab Size:  548\n",
      "# Words in test but not in train:  375\n"
     ]
    }
   ],
   "source": [
    "# difference in vocab b/w train and test\n",
    "train_sentences = preprocess_obj.fit_transform(df_train['sentence']).tolist()\n",
    "test_sentences = preprocess_obj.fit_transform(df_test['sentence']).tolist()\n",
    "test_labels = df_test['label'].tolist()\n",
    "train_vocab = set()\n",
    "for row in train_sentences:\n",
    "    train_vocab.update(row)\n",
    "\n",
    "test_vocab = set()\n",
    "for row in test_sentences:\n",
    "    test_vocab.update(row)\n",
    "    \n",
    "print('Train Vocab Size: ', len(train_vocab), '\\t', 'Test Vocab Size: ', len(test_vocab))\n",
    "print('# Words in test but not in train: ', len(test_vocab-train_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "alpine-allen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['serviceable', 'recieved', 'queen', 'bareilly', 'support', 'chhattisgarh', 'per', 'karnataka', 'whether', 'locking']\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "# classes that span the unseen words in test\n",
    "unseen_test_words = list(test_vocab - train_vocab)\n",
    "print(unseen_test_words[:10])\n",
    "\n",
    "out = {}\n",
    "for i, test_sent in enumerate(test_sentences):\n",
    "    for token in test_sent:\n",
    "        if token in unseen_test_words:\n",
    "            if test_labels[i] in out:\n",
    "                out[test_labels[i]].append((i, token))\n",
    "            else:\n",
    "                out[test_labels[i]] = [(i, token)]\n",
    "\n",
    "print(len(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "false-syracuse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO_NODES_DETECTED \t 349 \t [(0, 'only'), (0, 'models'), (1, 'single'), (10, 'send'), (10, 'them'), (10, 'after'), (10, 'lockdown'), (11, 'recieved'), (11, 'regard'), (15, 'purchase')]\n",
      "\n",
      "XXX\n",
      "\n",
      "DELAY_IN_DELIVERY \t 17 \t [(4, 'hai'), (4, 'recieved'), (8, 'completed'), (39, 'completed'), (105, 'ordered'), (153, 'shipped'), (207, 'weeks'), (240, 'since'), (240, 'ordered'), (240, 'but')]\n",
      "\n",
      "XXX\n",
      "\n",
      "CHECK_PINCODE \t 37 \t [(6, 'item'), (6, 'karnataka'), (69, 'code'), (89, 'code'), (138, 'u'), (155, 'u'), (155, 'at'), (155, 'kerala'), (175, 'u'), (175, 'at')]\n",
      "\n",
      "XXX\n",
      "\n",
      "PRODUCT_VARIANTS \t 12 \t [(9, 'double'), (73, 'hello'), (73, 'confusion'), (73, 'suggest'), (73, 'should'), (97, 'queen'), (97, 'pls'), (97, 'assist'), (168, 'variant'), (168, 'matters')]\n",
      "\n",
      "XXX\n",
      "\n",
      "ABOUT_SOF_MATTRESS \t 2 \t [(12, 'planning'), (12, 'purchase')]\n",
      "\n",
      "XXX\n",
      "\n",
      "SIZE_CUSTOMIZATION \t 26 \t [(19, 'customize'), (107, 'foot'), (154, 'queen'), (179, 'wany'), (179, 'custimize'), (199, 'inch'), (199, 'height'), (204, 'hi'), (204, 'queen'), (213, 'scaled')]\n",
      "\n",
      "XXX\n",
      "\n",
      "PILLOWS \t 22 \t [(25, 'bough'), (25, 'pillow'), (25, 'comfortable'), (35, 'pillow'), (50, 'go'), (50, 'pillow'), (71, 'prepare'), (71, 'pillow'), (74, 'pillow'), (81, 'pillow')]\n",
      "\n",
      "XXX\n",
      "\n",
      "MATTRESS_COST \t 14 \t [(28, 'less'), (160, 'matt'), (174, 'prices'), (174, 'queen'), (210, 'hello'), (210, 'matress'), (222, 'prize'), (222, 'double'), (223, 'prize'), (223, 'single')]\n",
      "\n",
      "XXX\n",
      "\n",
      "OFFERS \t 8 \t [(31, 'their'), (31, 'right'), (31, 'face'), (31, 'book'), (45, 'additional'), (369, 'going'), (369, 'at'), (369, 'along')]\n",
      "\n",
      "XXX\n",
      "\n",
      "WHAT_SIZE_TO_ORDER \t 19 \t [(38, 'someone'), (38, 'according'), (124, 'kbow'), (148, 'but'), (148, 'sure'), (161, 'toh'), (163, 'measure'), (163, 'actually'), (163, 'measure'), (163, 'corner')]\n",
      "\n",
      "XXX\n",
      "\n",
      "ORTHO_FEATURES \t 16 \t [(42, 'types'), (42, 'material'), (42, 'variant'), (95, 'matterss'), (98, 'years'), (98, 'slight'), (98, 'using'), (98, 'doble'), (98, 'pocketed'), (98, 'spring')]\n",
      "\n",
      "XXX\n",
      "\n",
      "COMPARISON \t 35 \t [(58, 'amd'), (65, 'egro'), (66, 'or'), (75, 'pls'), (75, 'age'), (75, 'or'), (94, 'wats'), (94, 'vertho'), (231, 'variation'), (267, 'vs')]\n",
      "\n",
      "XXX\n",
      "\n",
      "CANCEL_ORDER \t 3 \t [(64, 'ordr'), (84, 'like'), (130, 'because')]\n",
      "\n",
      "XXX\n",
      "\n",
      "EMI \t 9 \t [(72, 'bajaj'), (114, 'go'), (116, 'iam'), (116, 'saying'), (203, 'debitcard'), (288, 'convert'), (333, 'emidetail'), (360, 'bajaj'), (360, 'accepted')]\n",
      "\n",
      "XXX\n",
      "\n",
      "COD \t 6 \t [(78, 'sorry'), (78, 'showing'), (86, 'showing'), (190, 'leda'), (208, 'showing'), (220, 'required')]\n",
      "\n",
      "XXX\n",
      "\n",
      "DISTRIBUTORS \t 10 \t [(80, 'hi'), (80, 'wil'), (80, 'supply'), (177, 'tamilnadu'), (185, 'mangalore'), (266, 'u'), (266, 'outlets'), (276, 'u'), (276, 'acoimbatore'), (276, 'our')]\n",
      "\n",
      "XXX\n",
      "\n",
      "RETURN_EXCHANGE \t 15 \t [(82, 'if'), (82, 'satisfied'), (82, 'or'), (82, 'another'), (82, 'if'), (82, 'yes'), (82, 'then'), (159, 'if'), (159, 'v'), (188, 'old')]\n",
      "\n",
      "XXX\n",
      "\n",
      "ORDER_STATUS \t 9 \t [(200, 'booked'), (244, 'orderd'), (278, 'if'), (278, 'today'), (351, 'ordered'), (351, 'adjustable'), (351, 'pillow'), (351, 'march'), (353, 'deliverd')]\n",
      "\n",
      "XXX\n",
      "\n",
      "ERGO_FEATURES \t 6 \t [(201, 'pls'), (201, 'explain'), (201, 'verities'), (201, 'like'), (201, 'etc'), (265, 'kind')]\n",
      "\n",
      "XXX\n",
      "\n",
      "LEAD_GEN \t 12 \t [(206, 'ok'), (206, 'calling'), (235, 'after'), (235, 'pm'), (268, 'mi'), (284, 'mi'), (292, 'or'), (299, 'if'), (299, 'put'), (299, 'mobile')]\n",
      "\n",
      "XXX\n",
      "\n",
      "100_NIGHT_TRIAL_OFFER \t 3 \t [(258, 'trail'), (312, 'trail'), (389, 'trail')]\n",
      "\n",
      "XXX\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k, v in out.items():\n",
    "    print(k, '\\t', len(v), '\\t', v[:10])\n",
    "    print('\\nXXX\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-appendix",
   "metadata": {},
   "source": [
    "### Most of the unseen words come from OOS class. However, a good chunk of unseen words do come from in scope classes and a majority of such words are spelled wrongly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lucky-lecture",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
