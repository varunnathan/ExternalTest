{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "organic-citizenship",
   "metadata": {},
   "source": [
    "# Modelling Experiments\n",
    "1. Spacy - from scratch, fine-tuning\n",
    "2. Flair - from scratch, fine-tuning\n",
    "3. Bert - fine-tuning of FinBERT\n",
    "4. NER Bert trained on GMB data\n",
    "\n",
    "# Evaluation Strategy\n",
    "1. leave one out validation\n",
    "\n",
    "# Evaluation Metrics\n",
    "1. Precision, recall and f1 score for every class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "patient-logic",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/varunnathan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/varunnathan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/varunnathan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/varunnathan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/varunnathan/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys, swifter, re, json\n",
    "from constants import *\n",
    "from utility import *\n",
    "from preprocess_utils import _remove_non_ascii_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "accompanied-nigeria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "df = json.load(open(TRAIN_FN))\n",
    "\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cloudy-promotion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# find instances of overlapping entities and address them - could be because of wrong tagging\n",
    "from itertools import combinations\n",
    "\n",
    "out = []\n",
    "for i, row in enumerate(df):\n",
    "    spans = [x['span'] for x in row['entity']]\n",
    "    for l1, l2 in combinations(spans, 2):\n",
    "        if set(range(*l1)).intersection(set(range(*l2))):\n",
    "            out.append((i, l1, l2))\n",
    "\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "younger-joshua",
   "metadata": {},
   "source": [
    "### this is an issue with tagging. Manually updated with the correct tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "grand-contrast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace PAYMEN_AMOUNT with PAYMENT_AMOUNT\n",
    "for i, row in enumerate(df):\n",
    "    for j, ent in enumerate(row['entity']):\n",
    "        if ent['type'] == 'PAYMEN_AMOUNT':\n",
    "            df[i]['entity'][j]['type'] = 'PAYMENT_AMOUNT'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italic-johnson",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "1. removing non-ascii characters\n",
    "2. Contraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acceptable-stevens",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_obj = Text_Preprocessing(keep_eng=False, remove_nonalpha=False, lower_case=False,\n",
    "                         remove_punkt=False, remove_stop=False, remove_numerals=False,\n",
    "                         spell_check=False, contraction=True,\n",
    "                         contraction_var=CONTRACTIONS, stem=False,\n",
    "                         lem=False, filter_pos=False, pos_var=('N', 'J'),\n",
    "                         tokenize=False, template_removal=False,\n",
    "                         template_start_string='', regex_cleaning=False,\n",
    "                         remove_ignore_words=False, ignore_words=IGNORE_WORDS,\n",
    "                         custom_stoplist=[], word_size=2, word_size_filter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "extraordinary-vermont",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text_pre = _remove_non_ascii_characters(text)\n",
    "    text_pre = preprocess_obj.fit_transform(pd.Series([text_pre])).values[0]\n",
    "    return text_pre\n",
    "\n",
    "def preprocess_row_A1(row):\n",
    "    row1 = row.copy()\n",
    "    row1['text'] = preprocess(row1['text'])\n",
    "    out = []\n",
    "    for ent in row1['entity']:\n",
    "        string_pre = preprocess(ent['string'])\n",
    "        pattern = re.compile(r'\\b({})\\b'.format(string_pre))\n",
    "        _iter = pattern.finditer(row1['text'])\n",
    "        if _iter:\n",
    "            tmp_out = []\n",
    "            for item in _iter:\n",
    "                s_span, e_span = item.span()\n",
    "                span = [s_span, e_span]\n",
    "                tmp_out.append({'string': string_pre, 'span': span, 'type': ent['type']})\n",
    "        for item in tmp_out:\n",
    "            if item not in out:\n",
    "                out.append(item)\n",
    "    row1['entity'] = out\n",
    "    return row1\n",
    "\n",
    "\n",
    "def convert_to_seq_format(text, entity):\n",
    "    spans = [row['span'][0] for row in entity]\n",
    "    idxs = np.argsort(spans)\n",
    "    entity_new = [entity[i] for i in idxs]\n",
    "    text1 = text\n",
    "    new_chars_len = 0\n",
    "    for ent in entity_new:\n",
    "        s_span, e_span = ent['span'][0], ent['span'][-1]\n",
    "        s_span += new_chars_len\n",
    "        e_span += new_chars_len\n",
    "        _type = ent['type']\n",
    "        new_chars_len += len('[]({}) '.format(_type))\n",
    "        text1 = text1[:s_span] + '[' + text1[s_span:e_span] + ']({}) '.format(\n",
    "            _type) + text1[e_span:]\n",
    "    return text1\n",
    "\n",
    "\n",
    "def convert_from_seq_original_format(utterance):\n",
    "    start_pos_lst = []\n",
    "    end_pos_lst = []\n",
    "    value_lst = []\n",
    "    entity_lst = []\n",
    "    start_iters = [x.start() for x in re.finditer('\\[', utterance)]\n",
    "    end_iters = [x.start() for x in re.finditer('\\]', utterance)]\n",
    "    start_iters_ent = [x.start() for x in re.finditer('\\(', utterance)]\n",
    "    end_iters_ent = [x.start() for x in re.finditer('\\)', utterance)]\n",
    "    for i, start_it in enumerate(start_iters):\n",
    "        start_pos_lst.append(start_it+1)\n",
    "        end_pos_lst.append(end_iters[i])\n",
    "        value_lst.append(utterance[start_it+1:end_iters[i]])\n",
    "        entity_lst.append(utterance[start_iters_ent[i]+1:end_iters_ent[i]])\n",
    "\n",
    "    utterance1 = utterance\n",
    "    n_start_pos_lst, n_end_pos_lst = [], []\n",
    "    new_chars_len = 0\n",
    "    for i, s_span in enumerate(start_pos_lst):\n",
    "        e_span = end_pos_lst[i]\n",
    "        v = value_lst[i]\n",
    "        ent = entity_lst[i]\n",
    "        a_v = '[{}]({})'.format(v, ent)\n",
    "        #new_chars_len += len('[]({})'.format(ent))\n",
    "        #print(i, s_span, e_span, new_chars_len)\n",
    "        utterance1 = utterance1.replace(a_v, v)\n",
    "        if i == 0:\n",
    "            n_start_pos_lst.append(s_span-1)\n",
    "            n_end_pos_lst.append(e_span-1)\n",
    "        else:\n",
    "            n_start_pos_lst.append(s_span-new_chars_len-1)\n",
    "            n_end_pos_lst.append(e_span-new_chars_len-1)\n",
    "        new_chars_len += len('[]({})'.format(ent))\n",
    "        #print(n_start_pos_lst, n_end_pos_lst)\n",
    "    return value_lst, entity_lst, n_start_pos_lst, n_end_pos_lst, utterance1\n",
    "\n",
    "\n",
    "def preprocess_row_A2(row):\n",
    "    row1 = row.copy()\n",
    "    \n",
    "    text = row['text']\n",
    "    entity = row['entity']\n",
    "    \n",
    "    # convert to seq format\n",
    "    text1 = convert_to_seq_format(text, entity)\n",
    "    \n",
    "    # preprocess\n",
    "    text1_pre = preprocess(text1)\n",
    "    \n",
    "    # convert to original format\n",
    "    values, ents, s_spans, e_spans, text2 = convert_from_seq_original_format(text1_pre)\n",
    "    \n",
    "    # create desired format\n",
    "    spans = list(zip(s_spans, e_spans))\n",
    "    out = []\n",
    "    for i, span in enumerate(spans):\n",
    "        d = {}\n",
    "        d['span'] = list(span)\n",
    "        d['string'] = values[i]\n",
    "        d['type'] = ents[i]\n",
    "        out.append(d)\n",
    "    row1['text'] = text2\n",
    "    row1['entity'] = out\n",
    "    \n",
    "    return row1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "medieval-offset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contraction\n",
      "{'_id': '34e575a0-d5c3-47a0-b856-2a3b85dff90a', 'text': \"awesome what if it wasn't that it wouldn't go through would give an invalid next the expiration date is been inquiry entered at least one digit it won't go through alright wouldn't give a transaction right so every time let's review the arrangement must so today is the twenty first of december two thousand twenty you have offers authorized debit transaction in the amount of four hundred dollars to be taken from your debit card and it will be as such one hundred on the of january twenty twenty one one hundred on the eighth of february twenty twenty one one hundred and the of march twenty twenty one and one hundred on the eighth of april twenty twenty one you understand that the payment you're are authorizing will be office as an electronic debit to your account and you calling to this regarding service as the electronic signature for this payment arrangement please state your name and gray\", 'entity': [{'span': [270, 314], 'string': 'twenty first of december two thousand twenty', 'type': 'DATE'}, {'span': [377, 397], 'string': 'four hundred dollars', 'type': 'PAYMENT_AMOUNT'}, {'span': [454, 465], 'string': 'one hundred', 'type': 'PAYMENT_AMOUNT'}, {'span': [502, 513], 'string': 'one hundred', 'type': 'PAYMENT_AMOUNT'}, {'span': [558, 569], 'string': 'one hundred', 'type': 'PAYMENT_AMOUNT'}, {'span': [609, 620], 'string': 'one hundred', 'type': 'PAYMENT_AMOUNT'}, {'span': [476, 501], 'string': 'january twenty twenty one', 'type': 'PAYMENT_DATE'}, {'span': [521, 557], 'string': 'eighth of february twenty twenty one', 'type': 'PAYMENT_DATE'}, {'span': [581, 604], 'string': 'march twenty twenty one', 'type': 'PAYMENT_DATE'}, {'span': [628, 661], 'string': 'eighth of april twenty twenty one', 'type': 'PAYMENT_DATE'}]}\n",
      "\n",
      "{'_id': '34e575a0-d5c3-47a0-b856-2a3b85dff90a', 'text': 'awesome what if it was not that it would not go through would give an invalid next the expiration date is been inquiry entered at least one digit it will not go through alright would not give a transaction right so every time let us review the arrangement must so today is the twenty first of december two thousand twenty you have offers authorized debit transaction in the amount of four hundred dollars to be taken from your debit card and it will be as such one hundred on the of january twenty twenty one one hundred on the eighth of february twenty twenty one one hundred and the of march twenty twenty one and one hundred on the eighth of april twenty twenty one you understand that the payment you are are authorizing will be office as an electronic debit to your account and you calling to this regarding service as the electronic signature for this payment arrangement please state your name and gray', 'entity': [{'span': [277, 321], 'string': 'twenty first of december two thousand twenty', 'type': 'DATE'}, {'span': [384, 404], 'string': 'four hundred dollars', 'type': 'PAYMENT_AMOUNT'}, {'span': [461, 472], 'string': 'one hundred', 'type': 'PAYMENT_AMOUNT'}, {'span': [483, 508], 'string': 'january twenty twenty one', 'type': 'PAYMENT_DATE'}, {'span': [509, 520], 'string': 'one hundred', 'type': 'PAYMENT_AMOUNT'}, {'span': [528, 564], 'string': 'eighth of february twenty twenty one', 'type': 'PAYMENT_DATE'}, {'span': [565, 576], 'string': 'one hundred', 'type': 'PAYMENT_AMOUNT'}, {'span': [588, 611], 'string': 'march twenty twenty one', 'type': 'PAYMENT_DATE'}, {'span': [616, 627], 'string': 'one hundred', 'type': 'PAYMENT_AMOUNT'}, {'span': [635, 668], 'string': 'eighth of april twenty twenty one', 'type': 'PAYMENT_DATE'}]}\n",
      "CPU times: user 2.87 ms, sys: 5.06 ms, total: 7.93 ms\n",
      "Wall time: 9.91 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "row = df[17]\n",
    "row1 = preprocess_row_A2(row)\n",
    "print(row)\n",
    "print()\n",
    "print(row1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "instrumental-skiing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "contraction\n",
      "contraction\n",
      "contraction\n",
      "contraction\n",
      "contraction\n",
      "contraction\n",
      "contraction\n",
      "contraction\n",
      "contraction\n",
      "contraction\n",
      "10\n",
      "contraction\n",
      "contraction\n",
      "contraction\n",
      "contraction\n",
      "contraction\n",
      "contraction\n",
      "contraction\n",
      "contraction\n",
      "contraction\n",
      "contraction\n",
      "20\n",
      "contraction\n",
      "contraction\n",
      "contraction\n",
      "contraction\n",
      "contraction\n",
      "contraction\n",
      "contraction\n",
      "contraction\n",
      "contraction\n",
      "contraction\n",
      "30\n",
      "contraction\n",
      "contraction\n",
      "contraction\n",
      "contraction\n",
      "contraction\n",
      "contraction\n",
      "contraction\n",
      "contraction\n",
      "contraction\n",
      "contraction\n",
      "40\n",
      "contraction\n",
      "contraction\n",
      "contraction\n",
      "contraction\n",
      "contraction\n",
      "contraction\n",
      "contraction\n",
      "contraction\n",
      "contraction\n",
      "contraction\n",
      "CPU times: user 32.4 ms, sys: 2.94 ms, total: 35.4 ms\n",
      "Wall time: 33.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_pre = []\n",
    "for i, row in enumerate(df):\n",
    "    if i % 10 == 0:\n",
    "        print(i)\n",
    "    row1 = preprocess_row_A2(row)\n",
    "    df_pre.append(row1)\n",
    "    \n",
    "assert len(df) == len(df_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "disturbed-finish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': 'cdec241d-a995-480a-be18-baf2ef873315', 'text': \"alright very good so let me go ahead ahead and get these payments logged into the system alright so we have successfully set up six payments to be taken on your debit card on the fourteenth of each month starting with the first month bank in january of the new year and i have copied that information over to your files so that any agent that looks at your account can see that alright now what i'm gonna do charles is review what we've done today today's date is the twenty first of december and you've authorize six payments the debit transactions in amount fifty three eighty five with the first one being fifty three eighty seven to be taken from your debit regions bank account you understand that the payment you are will be processed as a electronic a ach debit to your account and you consent to this recording service visa is your electronic signature for this payment arrangement please state your name and state i agree charles\", 'entity': [{'span': [128, 131], 'string': 'six', 'type': 'NUM_PAYMENTS'}, {'span': [179, 203], 'string': 'fourteenth of each month', 'type': 'PAYMENT_DATE'}, {'span': [468, 492], 'string': 'twenty first of december', 'type': 'DATE'}, {'span': [514, 517], 'string': 'six', 'type': 'NUM_PAYMENTS'}, {'span': [560, 583], 'string': 'fifty three eighty five', 'type': 'PAYMENT_AMOUNT'}, {'span': [609, 633], 'string': 'fifty three eighty seven', 'type': 'PAYMENT_AMOUNT'}]}\n",
      "\n",
      "{'_id': 'cdec241d-a995-480a-be18-baf2ef873315', 'text': \"alright very good so let me go ahead ahead and get these payments logged into the system alright so we have successfully set up six payments to be taken on your debit card on the fourteenth of each month starting with the first month bank in january of the new year and i have copied that information over to your files so that any agent that looks at your account can see that alright now what i am gonna do charles is review what we have done today today's date is the twenty first of december and you have authorize six payments the debit transactions in amount fifty three eighty five with the first one being fifty three eighty seven to be taken from your debit regions bank account you understand that the payment you are will be processed as a electronic a ach debit to your account and you consent to this recording service visa is your electronic signature for this payment arrangement please state your name and state i agree charles\", 'entity': [{'span': [128, 131], 'string': 'six', 'type': 'NUM_PAYMENTS'}, {'span': [179, 203], 'string': 'fourteenth of each month', 'type': 'PAYMENT_DATE'}, {'span': [471, 495], 'string': 'twenty first of december', 'type': 'DATE'}, {'span': [519, 522], 'string': 'six', 'type': 'NUM_PAYMENTS'}, {'span': [565, 588], 'string': 'fifty three eighty five', 'type': 'PAYMENT_AMOUNT'}, {'span': [614, 638], 'string': 'fifty three eighty seven', 'type': 'PAYMENT_AMOUNT'}]}\n"
     ]
    }
   ],
   "source": [
    "print(df[9])\n",
    "print()\n",
    "print(df_pre[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "quick-schedule",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "out = []\n",
    "for i, row in enumerate(df_pre):\n",
    "    spans = [x['span'] for x in row['entity']]\n",
    "    for l1, l2 in combinations(spans, 2):\n",
    "        if set(l1).intersection(set(l2)):\n",
    "            out.append((i, l1, l2))\n",
    "\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "violent-value",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATE \t 51\n",
      "NUM_PAYMENTS \t 38\n",
      "PAYMENT_AMOUNT \t 59\n",
      "PAYMENT_DATE \t 46\n"
     ]
    }
   ],
   "source": [
    "# support for each class\n",
    "from collections import defaultdict\n",
    "\n",
    "label_support_dct = defaultdict(list)\n",
    "for row in df_pre:\n",
    "    for ent in row['entity']:\n",
    "        cur_cnt = label_support_dct.get(ent['type'], 0)\n",
    "        label_support_dct[ent['type']] = cur_cnt + 1\n",
    "    \n",
    "for key, cnt in label_support_dct.items():\n",
    "    print(key, '\\t', cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acceptable-sussex",
   "metadata": {},
   "source": [
    "## Experiment 1 - Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-musical",
   "metadata": {},
   "source": [
    "### Spacy Pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "choice-jefferson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.87 s, sys: 447 ms, total: 2.31 s\n",
      "Wall time: 2.39 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['transformer', 'tagger', 'parser', 'ner', 'attribute_ruler']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time nlp = spacy.load(\"en_core_web_trf\", disable=[\"lemmatizer\"])\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "mighty-amendment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': 'fd69a1f8-6bb0-4624-8052-b6e46fe7622a', 'text': 'nine seven three and then let us just go over with this arrangement and then we will be completely set please state mister is december twenty first two thousand twenty authorize authorized one time transaction and of twelve dollar and ninety seven cents be address from your card will be processed as an electronic and solutions and your stevens if you just need to cause it has  recording shipping is your electronic signature can please speak your full name ai i agree', 'entity': [{'span': [126, 167], 'string': 'december twenty first two thousand twenty', 'type': 'DATE'}, {'span': [189, 197], 'string': 'one time', 'type': 'NUM_PAYMENTS'}, {'span': [217, 253], 'string': 'twelve dollar and ninety seven cents', 'type': 'PAYMENT_AMOUNT'}]}\n",
      "\n",
      "XXXXXXXXXX\n",
      "\n",
      "december twenty first \t DATE\n",
      "twelve dollar \t MONEY\n"
     ]
    }
   ],
   "source": [
    "row = df_pre[0]\n",
    "print(row)\n",
    "print('\\nXXXXXXXXXX\\n')\n",
    "doc = nlp(row['text'])\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, '\\t', ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affected-gasoline",
   "metadata": {},
   "source": [
    "#### Custom tags are not being recognized which is logical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "parental-medication",
   "metadata": {},
   "outputs": [],
   "source": [
    "del nlp, doc, row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "future-truth",
   "metadata": {},
   "source": [
    "### Fine-tuning NER en_core_web_lg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fifteen-christian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.training.example import Example\n",
    "from spacy.scorer import Scorer\n",
    "\n",
    "EVAL_KEYS = ['token_acc', 'token_p', 'token_r', 'token_f', 'ents_p', 'ents_r', 'ents_f',\n",
    "             'ents_per_type']\n",
    "def evaluate(ner_model, examples):\n",
    "    scorer = Scorer()\n",
    "    out = []\n",
    "    for input_, annotations in examples:\n",
    "        pred_value = ner_model(input_)\n",
    "        example = Example.from_dict(pred_value, annotations)\n",
    "        out.append(example)\n",
    "    _score = scorer.score(out)\n",
    "    _score = {k: _score[k] for k in EVAL_KEYS}\n",
    "    return _score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "impaired-numbers",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.11 s, sys: 595 ms, total: 1.7 s\n",
      "Wall time: 1.71 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "ner = nlp.get_pipe(\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "innocent-uganda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_spacy(row):\n",
    "    out = []\n",
    "    for item in row['entity']:\n",
    "        out.append(tuple(item['span']+[item['type']]))\n",
    "    return (row['text'], {'entities': out})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afraid-horror",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('nine seven three and then let us just go over with this arrangement and then we will be completely set please state mister is december twenty first two thousand twenty authorize authorized one time transaction and of twelve dollar and ninety seven cents be address from your card will be processed as an electronic and solutions and your stevens if you just need to cause it has  recording shipping is your electronic signature can please speak your full name ai i agree',\n",
       " {'entities': [(126, 167, 'DATE'),\n",
       "   (189, 197, 'NUM_PAYMENTS'),\n",
       "   (217, 253, 'PAYMENT_AMOUNT')]})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_df = [prepare_data_for_spacy(x) for x in df_pre]\n",
    "assert len(spacy_df) == len(df_pre)\n",
    "spacy_df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "optimum-incident",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding labels to the `ner` model\n",
    "\n",
    "for _, annotations in spacy_df:\n",
    "    for ent in annotations.get(\"entities\"):\n",
    "        ner.add_label(ent[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dress-private",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the names of the components we want to disable during training\n",
    "pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "accredited-radio",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses (1/50) {'ner': 455.39905203371165}\n",
      "Losses (2/50) {'ner': 511.9060763431808}\n",
      "Losses (3/50) {'ner': 547.4542082586504}\n",
      "Losses (4/50) {'ner': 219.97052309654129}\n",
      "Losses (5/50) {'ner': 204.88349174312606}\n",
      "Losses (6/50) {'ner': 164.85501753203914}\n",
      "Losses (7/50) {'ner': 97.49430116069409}\n",
      "Losses (8/50) {'ner': 102.6803981965313}\n",
      "Losses (9/50) {'ner': 88.37078322858133}\n",
      "Losses (10/50) {'ner': 80.1702332334518}\n",
      "Losses (11/50) {'ner': 81.95071236586948}\n",
      "Losses (12/50) {'ner': 64.78147103266346}\n",
      "Losses (13/50) {'ner': 80.45692318131589}\n",
      "Losses (14/50) {'ner': 68.95678567991344}\n",
      "Losses (15/50) {'ner': 69.0375943711553}\n",
      "Losses (16/50) {'ner': 57.02439057136955}\n",
      "Losses (17/50) {'ner': 74.95906127518977}\n",
      "Losses (18/50) {'ner': 58.90506626584116}\n",
      "Losses (19/50) {'ner': 70.55116239806561}\n",
      "Losses (20/50) {'ner': 42.95145840332149}\n",
      "Losses (21/50) {'ner': 34.401681720884376}\n",
      "Losses (22/50) {'ner': 48.73060784359411}\n",
      "Losses (23/50) {'ner': 34.356468189956566}\n",
      "Losses (24/50) {'ner': 26.941513444204617}\n",
      "Losses (25/50) {'ner': 25.658035667817604}\n",
      "Losses (26/50) {'ner': 28.41620723531103}\n",
      "Losses (27/50) {'ner': 26.542088123739564}\n",
      "Losses (28/50) {'ner': 25.701168792945854}\n",
      "Losses (29/50) {'ner': 22.44779133662409}\n",
      "Losses (30/50) {'ner': 45.41646882428805}\n",
      "Losses (31/50) {'ner': 30.071004535622897}\n",
      "Losses (32/50) {'ner': 25.171874044032453}\n",
      "Losses (33/50) {'ner': 27.1382703055783}\n",
      "Losses (34/50) {'ner': 32.09971056687557}\n",
      "Losses (35/50) {'ner': 25.314689135566706}\n",
      "Losses (36/50) {'ner': 22.019541286337205}\n",
      "Losses (37/50) {'ner': 24.030317186037877}\n",
      "Losses (38/50) {'ner': 40.86761500106053}\n",
      "Losses (39/50) {'ner': 26.139355467429816}\n",
      "Losses (40/50) {'ner': 41.67071132918736}\n",
      "Losses (41/50) {'ner': 26.459984771771776}\n",
      "Losses (42/50) {'ner': 25.46228415495629}\n",
      "Losses (43/50) {'ner': 24.600493609696706}\n",
      "Losses (44/50) {'ner': 18.302564419407222}\n",
      "Losses (45/50) {'ner': 29.262322928369958}\n",
      "Losses (46/50) {'ner': 28.910016490355787}\n",
      "Losses (47/50) {'ner': 34.33388482996307}\n",
      "Losses (48/50) {'ner': 26.886759436181038}\n",
      "Losses (49/50) {'ner': 25.668298926851225}\n",
      "Losses (50/50) {'ner': 20.392096833766907}\n"
     ]
    }
   ],
   "source": [
    "# start the training loop, only training NER\n",
    "\n",
    "import random\n",
    "import copy\n",
    "import warnings\n",
    "from spacy.util import minibatch, compounding\n",
    "from spacy.training.example import Example\n",
    "from pathlib import Path\n",
    "\n",
    "epochs = 50\n",
    "optimizer = nlp.resume_training()\n",
    "with nlp.disable_pipes(*other_pipes), warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"once\", category=UserWarning, module='spacy')\n",
    "    sizes = compounding(1.0, 4.0, 1.001)\n",
    "    \n",
    "    # batch up the examples using spaCy's minibatc\n",
    "    for epoch in range(epochs):\n",
    "        examples = copy.deepcopy(spacy_df)\n",
    "        random.shuffle(examples)\n",
    "        batches = minibatch(examples, size=sizes)\n",
    "        losses = {}\n",
    "        \n",
    "        for batch in batches:\n",
    "            for text, annotations in batch:\n",
    "                #print(text, annotations)\n",
    "                doc = nlp.make_doc(text)\n",
    "                ex = Example.from_dict(doc, annotations)\n",
    "                # Update the model\n",
    "                nlp.update([ex], sgd=optimizer, losses=losses, drop=0.3)\n",
    "\n",
    "        print(\"Losses ({}/{})\".format(epoch + 1, epochs), losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "velvet-tomorrow",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "violent-detective",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let's review the arrangement that he all have set up today today's date is monday december the twenty first and you have authorized the total i of two debit transactions in the amount of one hundred dollars should be taken from your debit card on today's date monday the twenty first and on january the sixteenth you understand that the payment you are authorizing will be processed as electronic service to your account and you can send to this recording that trying to signature for this payment arrangement please state your name\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">let's review the arrangement that he all have set up today today's date is monday \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    december the twenty first\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " and you have authorized the total i of \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    two\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NUM_PAYMENTS</span>\n",
       "</mark>\n",
       " debit transactions in the amount of \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    one hundred dollars\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PAYMENT_AMOUNT</span>\n",
       "</mark>\n",
       " should be taken from your debit card on today's date monday the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    twenty first\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PAYMENT_DATE</span>\n",
       "</mark>\n",
       " and on \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    january the sixteenth\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PAYMENT_DATE</span>\n",
       "</mark>\n",
       " you understand that the payment you are authorizing will be processed as electronic service to your account and you can send to this recording that trying to signature for this payment arrangement please state your name</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = \"let's review the arrangement that he all have set up today today's date \\\n",
    "is monday december the twenty first and you have authorized the total i of two debit \\\n",
    "transactions in the amount of one hundred dollars should be taken from your debit card \\\n",
    "on today's date monday the twenty first and on january the sixteenth you understand that \\\n",
    "the payment you are authorizing will be processed as electronic service to your \\\n",
    "account and you can send to this recording that trying to signature for this payment \\\n",
    "arrangement please state your name\"\n",
    "print(text)\n",
    "print()\n",
    "spacy.displacy.render(nlp(text), style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "promotional-alarm",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'spacy.tokens.token.Token' object has no attribute 'ent_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-02d23153f95d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ment_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'spacy.tokens.token.Token' object has no attribute 'ent_'"
     ]
    }
   ],
   "source": [
    "for token in nlp(text):\n",
    "    print(token.text, token.ent_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "lucky-chancellor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 152 ms, sys: 4.11 ms, total: 156 ms\n",
      "Wall time: 154 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'token_acc': 1.0,\n",
       " 'token_p': 1.0,\n",
       " 'token_r': 1.0,\n",
       " 'token_f': 1.0,\n",
       " 'ents_p': 1.0,\n",
       " 'ents_r': 1.0,\n",
       " 'ents_f': 1.0,\n",
       " 'ents_per_type': {'DATE': {'p': 1.0, 'r': 1.0, 'f': 1.0},\n",
       "  'NUM_PAYMENTS': {'p': 1.0, 'r': 1.0, 'f': 1.0},\n",
       "  'PAYMENT_AMOUNT': {'p': 1.0, 'r': 1.0, 'f': 1.0}}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = [('nine seven three and then let us just go over with this arrangement and then we will be completely set please state mister is december twenty first two thousand twenty authorize authorized one time transaction and of twelve dollar and ninety seven cents be address from your card will be processed as an electronic and solutions and your stevens if you just need to cause it has  recording shipping is your electronic signature can please speak your full name ai i agree',\n",
    " {'entities': [(126, 167, 'DATE'),\n",
    "   (189, 197, 'NUM_PAYMENTS'),\n",
    "   (217, 253, 'PAYMENT_AMOUNT')]}), \n",
    "          ('nine seven three and then let us just go over with this arrangement and then we will be completely set please state mister is december twenty first two thousand twenty authorize authorized one time transaction and of twelve dollar and ninety seven cents be address from your card will be processed as an electronic and solutions and your stevens if you just need to cause it has  recording shipping is your electronic signature can please speak your full name ai i agree',\n",
    " {'entities': [(126, 167, 'DATE'),\n",
    "   (189, 197, 'NUM_PAYMENTS'),\n",
    "   (217, 253, 'PAYMENT_AMOUNT')]})]\n",
    "%time evaluate(nlp, example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "binary-electron",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.meta[\"name\"] = \"en_core_web_lg_entity_extractor_v1\"\n",
    "nlp.to_disk(os.path.join(MODEL_DIR, 'spacy_en_lg_v1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "institutional-reporter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.11 s, sys: 610 ms, total: 1.72 s\n",
      "Wall time: 1.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import spacy\n",
    "nlp = spacy.load(SPACY_MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "minimal-beauty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave one out validation\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "import time\n",
    "\n",
    "pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
    "\n",
    "\n",
    "def train_spacy_model(nlp, other_pipes, train_lst, epochs):\n",
    "    optimizer = nlp.resume_training()\n",
    "    with nlp.disable_pipes(*other_pipes), warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"once\", category=UserWarning, module='spacy')\n",
    "        sizes = compounding(1.0, 4.0, 1.001)\n",
    "\n",
    "        # batch up the examples using spaCy's minibatc\n",
    "        overall_losses = []\n",
    "        for epoch in range(epochs):\n",
    "            examples = copy.deepcopy(train_lst)\n",
    "            random.shuffle(examples)\n",
    "            batches = minibatch(examples, size=sizes)\n",
    "            losses = {}\n",
    "\n",
    "            for batch in batches:\n",
    "                for text, annotations in batch:\n",
    "                    #print(text, annotations)\n",
    "                    doc = nlp.make_doc(text)\n",
    "                    ex = Example.from_dict(doc, annotations)\n",
    "                    # Update the model\n",
    "                    nlp.update([ex], sgd=optimizer, losses=losses, drop=0.3)\n",
    "            print(\"Losses ({}/{})\".format(epoch + 1, epochs), losses)\n",
    "\n",
    "            overall_losses.append(losses)\n",
    "    return nlp, overall_losses[-1]\n",
    "\n",
    "\n",
    "def cross_val(spacy_df, epochs, pipe_exceptions=pipe_exceptions, num_evals=10):\n",
    "    loo = LeaveOneOut()\n",
    "    cnt = 0\n",
    "    nlps = []\n",
    "    losses = []\n",
    "    test_eval_metrics = []\n",
    "    start = time.time()\n",
    "    for train_index, test_index in loo.split(spacy_df):\n",
    "        if cnt > num_evals:\n",
    "            break\n",
    "        X_train = [x for i, x in enumerate(spacy_df) if i not in test_index]\n",
    "        X_test = [spacy_df[test_index[0]]]\n",
    "        \n",
    "        print('Model instantiation\\n')\n",
    "        nlp = spacy.load(\"en_core_web_lg\")\n",
    "        ner = nlp.get_pipe(\"ner\")\n",
    "\n",
    "        for _, annotations in X_train:\n",
    "            for ent in annotations.get(\"entities\"):\n",
    "                ner.add_label(ent[2])\n",
    "\n",
    "        other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
    "        \n",
    "        print('Training Loop : {}'.format(cnt + 1))\n",
    "        nlp, loss = train_spacy_model(nlp, other_pipes, X_train, epochs)\n",
    "        print('final loss: ', loss)\n",
    "        \n",
    "        # evaluation on test set\n",
    "        test_eval_metric = evaluate(nlp, X_test)\n",
    "        print('test metrics: ', test_eval_metric)\n",
    "        \n",
    "        nlps.append(nlp)\n",
    "        losses.append(loss)\n",
    "        test_eval_metrics.append(test_eval_metric)\n",
    "        cnt += 1\n",
    "        print('time taken: {}'.format(time.time() - start))\n",
    "        print('\\nXXXXXXXXX\\n')\n",
    "    return nlps, losses, test_eval_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "lasting-territory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Begins...\n",
      "\n",
      "Model instantiation\n",
      "\n",
      "Training Loop : 1\n",
      "Losses (1/50) {'ner': 455.667057522839}\n",
      "Losses (2/50) {'ner': 741.5296075648171}\n",
      "Losses (3/50) {'ner': 456.570073298722}\n",
      "Losses (4/50) {'ner': 227.11811829042102}\n",
      "Losses (5/50) {'ner': 181.2081088586001}\n",
      "Losses (6/50) {'ner': 186.0459412480571}\n",
      "Losses (7/50) {'ner': 117.4174967823696}\n",
      "Losses (8/50) {'ner': 110.53142329123787}\n",
      "Losses (9/50) {'ner': 79.11333160062871}\n",
      "Losses (10/50) {'ner': 97.98347648066097}\n",
      "Losses (11/50) {'ner': 88.84846267244208}\n",
      "Losses (12/50) {'ner': 56.93974718336851}\n",
      "Losses (13/50) {'ner': 74.50347032708991}\n",
      "Losses (14/50) {'ner': 65.63352601655396}\n",
      "Losses (15/50) {'ner': 39.96174946544512}\n",
      "Losses (16/50) {'ner': 37.40590125565213}\n",
      "Losses (17/50) {'ner': 106.00054680152435}\n",
      "Losses (18/50) {'ner': 46.70422535125666}\n",
      "Losses (19/50) {'ner': 39.21400689052706}\n",
      "Losses (20/50) {'ner': 37.59950011699613}\n",
      "Losses (21/50) {'ner': 30.18409829745803}\n",
      "Losses (22/50) {'ner': 59.35291658944035}\n",
      "Losses (23/50) {'ner': 24.905829845758863}\n",
      "Losses (24/50) {'ner': 31.90320637330618}\n",
      "Losses (25/50) {'ner': 32.645580178824524}\n",
      "Losses (26/50) {'ner': 37.637132653032616}\n",
      "Losses (27/50) {'ner': 29.957693764257826}\n",
      "Losses (28/50) {'ner': 36.38959531902665}\n",
      "Losses (29/50) {'ner': 40.236997211881885}\n",
      "Losses (30/50) {'ner': 31.319236555405034}\n",
      "Losses (31/50) {'ner': 20.987965727915125}\n",
      "Losses (32/50) {'ner': 38.07475257774581}\n",
      "Losses (33/50) {'ner': 33.16288999931902}\n",
      "Losses (34/50) {'ner': 34.881290547309966}\n",
      "Losses (35/50) {'ner': 29.628996161856797}\n",
      "Losses (36/50) {'ner': 51.68751622973153}\n",
      "Losses (37/50) {'ner': 27.218819680059468}\n",
      "Losses (38/50) {'ner': 31.88449497398393}\n",
      "Losses (39/50) {'ner': 23.95491669685195}\n",
      "Losses (40/50) {'ner': 18.016890685907924}\n",
      "Losses (41/50) {'ner': 28.292131323941206}\n",
      "Losses (42/50) {'ner': 31.135874417279023}\n",
      "Losses (43/50) {'ner': 35.49192579884511}\n",
      "Losses (44/50) {'ner': 33.99564106982708}\n",
      "Losses (45/50) {'ner': 25.586838495053325}\n",
      "Losses (46/50) {'ner': 24.685132502816515}\n",
      "Losses (47/50) {'ner': 21.32187714363894}\n",
      "Losses (48/50) {'ner': 23.300084825364774}\n",
      "Losses (49/50) {'ner': 21.411837665443308}\n",
      "Losses (50/50) {'ner': 41.87135923200714}\n",
      "final loss:  {'ner': 41.87135923200714}\n",
      "test metrics:  {'token_acc': 1.0, 'token_p': 1.0, 'token_r': 1.0, 'token_f': 1.0, 'ents_p': 1.0, 'ents_r': 1.0, 'ents_f': 1.0, 'ents_per_type': {'DATE': {'p': 1.0, 'r': 1.0, 'f': 1.0}, 'NUM_PAYMENTS': {'p': 1.0, 'r': 1.0, 'f': 1.0}, 'PAYMENT_AMOUNT': {'p': 1.0, 'r': 1.0, 'f': 1.0}}}\n",
      "time taken: 145.75258803367615\n",
      "\n",
      "XXXXXXXXX\n",
      "\n",
      "Model instantiation\n",
      "\n",
      "Training Loop : 2\n",
      "Losses (1/50) {'ner': 372.6762341482105}\n",
      "Losses (2/50) {'ner': 685.3190664478198}\n",
      "Losses (3/50) {'ner': 283.17522070017776}\n",
      "Losses (4/50) {'ner': 214.6429125890568}\n",
      "Losses (5/50) {'ner': 184.01303059477965}\n",
      "Losses (6/50) {'ner': 152.75549046216508}\n",
      "Losses (7/50) {'ner': 106.41180985231132}\n",
      "Losses (8/50) {'ner': 107.52490860564282}\n",
      "Losses (9/50) {'ner': 98.19409319855417}\n",
      "Losses (10/50) {'ner': 66.39753826684635}\n",
      "Losses (11/50) {'ner': 70.51375083897966}\n",
      "Losses (12/50) {'ner': 51.79761842138607}\n",
      "Losses (13/50) {'ner': 58.444465271655176}\n",
      "Losses (14/50) {'ner': 48.87508667985906}\n",
      "Losses (15/50) {'ner': 72.54158507594573}\n",
      "Losses (16/50) {'ner': 64.27095594491281}\n",
      "Losses (17/50) {'ner': 42.47800619771649}\n",
      "Losses (18/50) {'ner': 59.4379787437991}\n",
      "Losses (19/50) {'ner': 43.676240100732976}\n",
      "Losses (20/50) {'ner': 45.83665841101879}\n",
      "Losses (21/50) {'ner': 56.181639965877295}\n",
      "Losses (22/50) {'ner': 46.909243885723676}\n",
      "Losses (23/50) {'ner': 57.04426078961348}\n",
      "Losses (24/50) {'ner': 32.700805158277205}\n",
      "Losses (25/50) {'ner': 49.94881793179951}\n",
      "Losses (26/50) {'ner': 39.633418077678975}\n",
      "Losses (27/50) {'ner': 33.729503371567674}\n",
      "Losses (28/50) {'ner': 36.737931314444445}\n",
      "Losses (29/50) {'ner': 26.053253584611625}\n",
      "Losses (30/50) {'ner': 17.320747953188487}\n",
      "Losses (31/50) {'ner': 46.83315228665832}\n",
      "Losses (32/50) {'ner': 29.71732674106196}\n",
      "Losses (33/50) {'ner': 43.07411166579051}\n",
      "Losses (34/50) {'ner': 30.065018979722737}\n",
      "Losses (35/50) {'ner': 41.32656585849694}\n",
      "Losses (36/50) {'ner': 32.6996592545653}\n",
      "Losses (37/50) {'ner': 30.263892335882023}\n",
      "Losses (38/50) {'ner': 24.46049383731233}\n",
      "Losses (39/50) {'ner': 20.29622294639939}\n",
      "Losses (40/50) {'ner': 31.87813546250819}\n",
      "Losses (41/50) {'ner': 42.08204803500592}\n",
      "Losses (42/50) {'ner': 24.206160006611245}\n",
      "Losses (43/50) {'ner': 39.187150599330224}\n",
      "Losses (44/50) {'ner': 17.341559776149875}\n",
      "Losses (45/50) {'ner': 19.443506158223194}\n",
      "Losses (46/50) {'ner': 28.28491939491131}\n",
      "Losses (47/50) {'ner': 25.217440050911343}\n",
      "Losses (48/50) {'ner': 23.659353729585245}\n",
      "Losses (49/50) {'ner': 20.20550637436745}\n",
      "Losses (50/50) {'ner': 27.10235894175824}\n",
      "final loss:  {'ner': 27.10235894175824}\n",
      "test metrics:  {'token_acc': 1.0, 'token_p': 1.0, 'token_r': 1.0, 'token_f': 1.0, 'ents_p': 0.75, 'ents_r': 1.0, 'ents_f': 0.8571428571428571, 'ents_per_type': {'DATE': {'p': 1.0, 'r': 1.0, 'f': 1.0}, 'NUM_PAYMENTS': {'p': 0.5, 'r': 1.0, 'f': 0.6666666666666666}, 'PAYMENT_AMOUNT': {'p': 1.0, 'r': 1.0, 'f': 1.0}}}\n",
      "time taken: 282.6923761367798\n",
      "\n",
      "XXXXXXXXX\n",
      "\n",
      "Model instantiation\n",
      "\n",
      "Training Loop : 3\n",
      "Losses (1/50) {'ner': 410.49863920524774}\n",
      "Losses (2/50) {'ner': 970.7382404394409}\n",
      "Losses (3/50) {'ner': 695.8213477082237}\n",
      "Losses (4/50) {'ner': 212.5670872543691}\n",
      "Losses (5/50) {'ner': 195.0960160014674}\n",
      "Losses (6/50) {'ner': 153.5769765569858}\n",
      "Losses (7/50) {'ner': 130.21746928249775}\n",
      "Losses (8/50) {'ner': 99.1084631708212}\n",
      "Losses (9/50) {'ner': 76.85212739724517}\n",
      "Losses (10/50) {'ner': 86.66159139101518}\n",
      "Losses (11/50) {'ner': 72.89308515976519}\n",
      "Losses (12/50) {'ner': 94.65921497151723}\n",
      "Losses (13/50) {'ner': 50.958515033717475}\n",
      "Losses (14/50) {'ner': 47.483631914130946}\n",
      "Losses (15/50) {'ner': 65.67729418833102}\n",
      "Losses (16/50) {'ner': 68.62366063195765}\n",
      "Losses (17/50) {'ner': 49.32893595510211}\n",
      "Losses (18/50) {'ner': 60.11992863633105}\n",
      "Losses (19/50) {'ner': 75.78512234286187}\n",
      "Losses (20/50) {'ner': 48.5948014459663}\n",
      "Losses (21/50) {'ner': 40.44772771413593}\n",
      "Losses (22/50) {'ner': 46.08796337806644}\n",
      "Losses (23/50) {'ner': 36.89474530098525}\n",
      "Losses (24/50) {'ner': 33.66463391132962}\n",
      "Losses (25/50) {'ner': 52.24191507224348}\n",
      "Losses (26/50) {'ner': 32.751658905663426}\n",
      "Losses (27/50) {'ner': 35.35128710696094}\n",
      "Losses (28/50) {'ner': 31.668700070403357}\n",
      "Losses (29/50) {'ner': 30.816010942414557}\n",
      "Losses (30/50) {'ner': 40.87083758075518}\n",
      "Losses (31/50) {'ner': 30.22999368063842}\n",
      "Losses (32/50) {'ner': 33.083898173576756}\n",
      "Losses (33/50) {'ner': 37.07101944453869}\n",
      "Losses (34/50) {'ner': 36.31704499186696}\n",
      "Losses (35/50) {'ner': 35.27602017391859}\n",
      "Losses (36/50) {'ner': 32.09325285723223}\n",
      "Losses (37/50) {'ner': 26.059363059451936}\n",
      "Losses (38/50) {'ner': 37.00251535970259}\n",
      "Losses (39/50) {'ner': 24.618972598624445}\n",
      "Losses (40/50) {'ner': 31.27024660198119}\n",
      "Losses (41/50) {'ner': 36.81341473633351}\n",
      "Losses (42/50) {'ner': 39.176465634092615}\n",
      "Losses (43/50) {'ner': 28.98230292235582}\n",
      "Losses (44/50) {'ner': 20.843982827890077}\n",
      "Losses (45/50) {'ner': 19.50824795465465}\n",
      "Losses (46/50) {'ner': 19.419551351946236}\n",
      "Losses (47/50) {'ner': 22.03735968688971}\n",
      "Losses (48/50) {'ner': 24.301956660276602}\n",
      "Losses (49/50) {'ner': 21.79664443053185}\n",
      "Losses (50/50) {'ner': 29.52039819118861}\n",
      "final loss:  {'ner': 29.52039819118861}\n",
      "test metrics:  {'token_acc': 1.0, 'token_p': 1.0, 'token_r': 1.0, 'token_f': 1.0, 'ents_p': 1.0, 'ents_r': 1.0, 'ents_f': 1.0, 'ents_per_type': {'DATE': {'p': 1.0, 'r': 1.0, 'f': 1.0}, 'NUM_PAYMENTS': {'p': 1.0, 'r': 1.0, 'f': 1.0}, 'PAYMENT_AMOUNT': {'p': 1.0, 'r': 1.0, 'f': 1.0}}}\n",
      "time taken: 422.8656840324402\n",
      "\n",
      "XXXXXXXXX\n",
      "\n",
      "Model instantiation\n",
      "\n",
      "Training Loop : 4\n",
      "Losses (1/50) {'ner': 417.9934153914382}\n",
      "Losses (2/50) {'ner': 748.8925066889462}\n",
      "Losses (3/50) {'ner': 773.871870956981}\n",
      "Losses (4/50) {'ner': 235.15205834389587}\n",
      "Losses (5/50) {'ner': 190.58706305223055}\n",
      "Losses (6/50) {'ner': 176.38262942774608}\n",
      "Losses (7/50) {'ner': 160.54627082974042}\n",
      "Losses (8/50) {'ner': 162.61595526106152}\n",
      "Losses (9/50) {'ner': 92.81247578337772}\n",
      "Losses (10/50) {'ner': 97.1084722926196}\n",
      "Losses (11/50) {'ner': 105.86572463386797}\n",
      "Losses (12/50) {'ner': 89.99555722164237}\n",
      "Losses (13/50) {'ner': 48.90996923325256}\n",
      "Losses (14/50) {'ner': 73.00131449423732}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses (15/50) {'ner': 51.27409966114628}\n",
      "Losses (16/50) {'ner': 61.25571166837362}\n",
      "Losses (17/50) {'ner': 68.23742915854206}\n",
      "Losses (18/50) {'ner': 53.097624605755016}\n",
      "Losses (19/50) {'ner': 36.038190105497065}\n",
      "Losses (20/50) {'ner': 31.360904458988355}\n",
      "Losses (21/50) {'ner': 41.93411175237115}\n",
      "Losses (22/50) {'ner': 34.267241475008845}\n",
      "Losses (23/50) {'ner': 29.223945708913963}\n",
      "Losses (24/50) {'ner': 34.40556635198311}\n",
      "Losses (25/50) {'ner': 35.333258753802454}\n",
      "Losses (26/50) {'ner': 33.84417025612629}\n",
      "Losses (27/50) {'ner': 56.11097774581406}\n",
      "Losses (28/50) {'ner': 26.839122420006284}\n",
      "Losses (29/50) {'ner': 40.74904427719278}\n",
      "Losses (30/50) {'ner': 37.66504127334491}\n",
      "Losses (31/50) {'ner': 44.037696409754965}\n",
      "Losses (32/50) {'ner': 32.04673041046788}\n",
      "Losses (33/50) {'ner': 32.36273056861725}\n",
      "Losses (34/50) {'ner': 25.276302871300583}\n",
      "Losses (35/50) {'ner': 26.866953923853295}\n",
      "Losses (36/50) {'ner': 36.72776589783007}\n",
      "Losses (37/50) {'ner': 22.417257431339436}\n",
      "Losses (38/50) {'ner': 28.14968681035656}\n",
      "Losses (39/50) {'ner': 24.765543765848587}\n",
      "Losses (40/50) {'ner': 24.10047681316578}\n",
      "Losses (41/50) {'ner': 55.03155738599687}\n",
      "Losses (42/50) {'ner': 37.427701678565896}\n",
      "Losses (43/50) {'ner': 39.64962163110151}\n",
      "Losses (44/50) {'ner': 23.344599581670735}\n",
      "Losses (45/50) {'ner': 21.941977214743538}\n",
      "Losses (46/50) {'ner': 24.63682548927473}\n",
      "Losses (47/50) {'ner': 26.514310237607166}\n",
      "Losses (48/50) {'ner': 29.349745029367913}\n",
      "Losses (49/50) {'ner': 21.683654033036927}\n",
      "Losses (50/50) {'ner': 15.149938515304576}\n",
      "final loss:  {'ner': 15.149938515304576}\n",
      "test metrics:  {'token_acc': 1.0, 'token_p': 1.0, 'token_r': 1.0, 'token_f': 1.0, 'ents_p': 0.625, 'ents_r': 0.625, 'ents_f': 0.625, 'ents_per_type': {'DATE': {'p': 1.0, 'r': 1.0, 'f': 1.0}, 'NUM_PAYMENTS': {'p': 1.0, 'r': 1.0, 'f': 1.0}, 'PAYMENT_DATE': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'PAYMENT_AMOUNT': {'p': 1.0, 'r': 1.0, 'f': 1.0}}}\n",
      "time taken: 559.314934015274\n",
      "\n",
      "XXXXXXXXX\n",
      "\n",
      "Model instantiation\n",
      "\n",
      "Training Loop : 5\n",
      "Losses (1/50) {'ner': 420.2337339327527}\n",
      "Losses (2/50) {'ner': 602.3916161525353}\n",
      "Losses (3/50) {'ner': 413.1495418631252}\n",
      "Losses (4/50) {'ner': 211.22855775610938}\n",
      "Losses (5/50) {'ner': 193.90661632970108}\n",
      "Losses (6/50) {'ner': 195.645948826588}\n",
      "Losses (7/50) {'ner': 143.39604365396002}\n",
      "Losses (8/50) {'ner': 107.35108111556835}\n",
      "Losses (9/50) {'ner': 76.39159935234198}\n",
      "Losses (10/50) {'ner': 95.71408904771346}\n",
      "Losses (11/50) {'ner': 95.54123771374978}\n",
      "Losses (12/50) {'ner': 63.84695852955744}\n",
      "Losses (13/50) {'ner': 74.2540026136751}\n",
      "Losses (14/50) {'ner': 47.453111903311395}\n",
      "Losses (15/50) {'ner': 69.29075458275558}\n",
      "Losses (16/50) {'ner': 62.65020027050803}\n",
      "Losses (17/50) {'ner': 52.89722552253033}\n",
      "Losses (18/50) {'ner': 44.197604305856714}\n",
      "Losses (19/50) {'ner': 52.78893735460198}\n",
      "Losses (20/50) {'ner': 36.33660561080227}\n",
      "Losses (21/50) {'ner': 29.0536317786565}\n",
      "Losses (22/50) {'ner': 37.442380398736695}\n",
      "Losses (23/50) {'ner': 32.33431049129998}\n",
      "Losses (24/50) {'ner': 31.821164086121595}\n",
      "Losses (25/50) {'ner': 25.231701057849214}\n",
      "Losses (26/50) {'ner': 34.92967019343321}\n",
      "Losses (27/50) {'ner': 29.664305741107455}\n",
      "Losses (28/50) {'ner': 38.88392780836622}\n",
      "Losses (29/50) {'ner': 27.65409816844787}\n",
      "Losses (30/50) {'ner': 52.80667669029552}\n",
      "Losses (31/50) {'ner': 55.879280954744885}\n",
      "Losses (32/50) {'ner': 51.0933693394403}\n",
      "Losses (33/50) {'ner': 30.785641251006297}\n",
      "Losses (34/50) {'ner': 55.31537748643641}\n",
      "Losses (35/50) {'ner': 23.74759225685859}\n",
      "Losses (36/50) {'ner': 36.547997359387956}\n",
      "Losses (37/50) {'ner': 26.23523790721925}\n",
      "Losses (38/50) {'ner': 25.508373865084604}\n",
      "Losses (39/50) {'ner': 39.43278903172889}\n",
      "Losses (40/50) {'ner': 38.70880821587495}\n",
      "Losses (41/50) {'ner': 42.814503997053684}\n",
      "Losses (42/50) {'ner': 30.840027255696373}\n",
      "Losses (43/50) {'ner': 30.31261721914539}\n",
      "Losses (44/50) {'ner': 35.85629173270065}\n",
      "Losses (45/50) {'ner': 41.08429991081931}\n",
      "Losses (46/50) {'ner': 31.903472991267613}\n",
      "Losses (47/50) {'ner': 23.691065625272945}\n",
      "Losses (48/50) {'ner': 27.95180520274382}\n",
      "Losses (49/50) {'ner': 37.33780726873076}\n",
      "Losses (50/50) {'ner': 27.315871089080584}\n",
      "final loss:  {'ner': 27.315871089080584}\n",
      "test metrics:  {'token_acc': 1.0, 'token_p': 1.0, 'token_r': 1.0, 'token_f': 1.0, 'ents_p': 0.75, 'ents_r': 1.0, 'ents_f': 0.8571428571428571, 'ents_per_type': {'DATE': {'p': 1.0, 'r': 1.0, 'f': 1.0}, 'NUM_PAYMENTS': {'p': 0.5, 'r': 1.0, 'f': 0.6666666666666666}, 'PAYMENT_AMOUNT': {'p': 1.0, 'r': 1.0, 'f': 1.0}}}\n",
      "time taken: 694.5331239700317\n",
      "\n",
      "XXXXXXXXX\n",
      "\n",
      "Model instantiation\n",
      "\n",
      "Training Loop : 6\n",
      "Losses (1/50) {'ner': 365.61966834271334}\n",
      "Losses (2/50) {'ner': 820.6255274606131}\n",
      "Losses (3/50) {'ner': 538.0569108944094}\n",
      "Losses (4/50) {'ner': 231.18030534173445}\n",
      "Losses (5/50) {'ner': 164.34455938049436}\n",
      "Losses (6/50) {'ner': 135.56229822119104}\n",
      "Losses (7/50) {'ner': 122.9765933519412}\n",
      "Losses (8/50) {'ner': 107.52314366457658}\n",
      "Losses (9/50) {'ner': 117.37124274651698}\n",
      "Losses (10/50) {'ner': 162.69103622959764}\n",
      "Losses (11/50) {'ner': 83.1715796757098}\n",
      "Losses (12/50) {'ner': 81.25741972936461}\n",
      "Losses (13/50) {'ner': 65.73547530066834}\n",
      "Losses (14/50) {'ner': 60.75842222109951}\n",
      "Losses (15/50) {'ner': 46.93763218941847}\n",
      "Losses (16/50) {'ner': 52.94530972153766}\n",
      "Losses (17/50) {'ner': 50.91330359359415}\n",
      "Losses (18/50) {'ner': 78.49629151542464}\n",
      "Losses (19/50) {'ner': 49.93859091871568}\n",
      "Losses (20/50) {'ner': 35.225495260697855}\n",
      "Losses (21/50) {'ner': 41.07702250285559}\n",
      "Losses (22/50) {'ner': 32.3910212076071}\n",
      "Losses (23/50) {'ner': 40.53569279817336}\n",
      "Losses (24/50) {'ner': 41.27313404280238}\n",
      "Losses (25/50) {'ner': 59.78410945171247}\n",
      "Losses (26/50) {'ner': 39.15996290444773}\n",
      "Losses (27/50) {'ner': 65.8651115699114}\n",
      "Losses (28/50) {'ner': 33.799067842930704}\n",
      "Losses (29/50) {'ner': 34.48267398684985}\n",
      "Losses (30/50) {'ner': 35.657751138132255}\n",
      "Losses (31/50) {'ner': 34.89098044309076}\n",
      "Losses (32/50) {'ner': 25.66075625169941}\n",
      "Losses (33/50) {'ner': 27.7124643944829}\n",
      "Losses (34/50) {'ner': 23.572149498682194}\n",
      "Losses (35/50) {'ner': 36.573720862981965}\n",
      "Losses (36/50) {'ner': 27.8476898656719}\n",
      "Losses (37/50) {'ner': 38.198199503088986}\n",
      "Losses (38/50) {'ner': 27.838724534134958}\n",
      "Losses (39/50) {'ner': 42.06784658592532}\n",
      "Losses (40/50) {'ner': 28.455400063733446}\n",
      "Losses (41/50) {'ner': 40.06316224894195}\n",
      "Losses (42/50) {'ner': 13.925904195165307}\n",
      "Losses (43/50) {'ner': 41.07555894310933}\n",
      "Losses (44/50) {'ner': 29.83826675046556}\n",
      "Losses (45/50) {'ner': 27.965327440923087}\n",
      "Losses (46/50) {'ner': 31.22897556709073}\n",
      "Losses (47/50) {'ner': 24.71329039382524}\n",
      "Losses (48/50) {'ner': 18.490239575552913}\n",
      "Losses (49/50) {'ner': 17.20370491610538}\n",
      "Losses (50/50) {'ner': 25.553136613272546}\n",
      "final loss:  {'ner': 25.553136613272546}\n",
      "test metrics:  {'token_acc': 1.0, 'token_p': 1.0, 'token_r': 1.0, 'token_f': 1.0, 'ents_p': 0.3333333333333333, 'ents_r': 0.5, 'ents_f': 0.4, 'ents_per_type': {'DATE': {'p': 0.5, 'r': 1.0, 'f': 0.6666666666666666}, 'NUM_PAYMENTS': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'PAYMENT_DATE': {'p': 0.0, 'r': 0.0, 'f': 0.0}}}\n",
      "time taken: 829.2802228927612\n",
      "\n",
      "XXXXXXXXX\n",
      "\n",
      "Model instantiation\n",
      "\n",
      "Training Loop : 7\n",
      "Losses (1/50) {'ner': 450.36711843869335}\n",
      "Losses (2/50) {'ner': 709.6784146669049}\n",
      "Losses (3/50) {'ner': 602.6361417587844}\n",
      "Losses (4/50) {'ner': 226.3243122141604}\n",
      "Losses (5/50) {'ner': 167.614257214847}\n",
      "Losses (6/50) {'ner': 165.04018539622322}\n",
      "Losses (7/50) {'ner': 117.10159509702261}\n",
      "Losses (8/50) {'ner': 152.20556888924241}\n",
      "Losses (9/50) {'ner': 93.37195315729836}\n",
      "Losses (10/50) {'ner': 88.03070654971013}\n",
      "Losses (11/50) {'ner': 113.14238157049915}\n",
      "Losses (12/50) {'ner': 73.88214727135741}\n",
      "Losses (13/50) {'ner': 69.25682601530454}\n",
      "Losses (14/50) {'ner': 52.35134961968172}\n",
      "Losses (15/50) {'ner': 38.517216175698366}\n",
      "Losses (16/50) {'ner': 48.71050299646388}\n",
      "Losses (17/50) {'ner': 54.091850083827815}\n",
      "Losses (18/50) {'ner': 49.841247293866815}\n",
      "Losses (19/50) {'ner': 46.74532367530565}\n",
      "Losses (20/50) {'ner': 41.55087586481522}\n",
      "Losses (21/50) {'ner': 45.29108772631236}\n",
      "Losses (22/50) {'ner': 32.75501019877653}\n",
      "Losses (23/50) {'ner': 24.7069823194368}\n",
      "Losses (24/50) {'ner': 34.38477216054846}\n",
      "Losses (25/50) {'ner': 24.586477862610185}\n",
      "Losses (26/50) {'ner': 41.43068975274894}\n",
      "Losses (27/50) {'ner': 32.87641926661794}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses (28/50) {'ner': 37.49977325242533}\n",
      "Losses (29/50) {'ner': 57.90144826187794}\n",
      "Losses (30/50) {'ner': 54.42428903899563}\n",
      "Losses (31/50) {'ner': 42.845764172666904}\n",
      "Losses (32/50) {'ner': 28.59525468677697}\n",
      "Losses (33/50) {'ner': 39.90007421352513}\n",
      "Losses (34/50) {'ner': 34.73126976741644}\n",
      "Losses (35/50) {'ner': 25.182112354077255}\n",
      "Losses (36/50) {'ner': 29.455407713713807}\n",
      "Losses (37/50) {'ner': 30.231883408372507}\n",
      "Losses (38/50) {'ner': 27.42094649845676}\n",
      "Losses (39/50) {'ner': 22.019005664525082}\n",
      "Losses (40/50) {'ner': 25.334188507835684}\n",
      "Losses (41/50) {'ner': 43.10863948646541}\n",
      "Losses (42/50) {'ner': 40.38405749123197}\n",
      "Losses (43/50) {'ner': 27.84715623525123}\n",
      "Losses (44/50) {'ner': 40.42559535160814}\n",
      "Losses (45/50) {'ner': 36.49871629775001}\n",
      "Losses (46/50) {'ner': 38.83127087194581}\n",
      "Losses (47/50) {'ner': 34.598245798669566}\n",
      "Losses (48/50) {'ner': 22.650398048742076}\n",
      "Losses (49/50) {'ner': 43.557711509068724}\n",
      "Losses (50/50) {'ner': 28.178007650354882}\n",
      "final loss:  {'ner': 28.178007650354882}\n",
      "test metrics:  {'token_acc': 1.0, 'token_p': 1.0, 'token_r': 1.0, 'token_f': 1.0, 'ents_p': 0.75, 'ents_r': 1.0, 'ents_f': 0.8571428571428571, 'ents_per_type': {'DATE': {'p': 1.0, 'r': 1.0, 'f': 1.0}, 'NUM_PAYMENTS': {'p': 0.5, 'r': 1.0, 'f': 0.6666666666666666}, 'PAYMENT_AMOUNT': {'p': 1.0, 'r': 1.0, 'f': 1.0}}}\n",
      "time taken: 965.8886120319366\n",
      "\n",
      "XXXXXXXXX\n",
      "\n",
      "Model instantiation\n",
      "\n",
      "Training Loop : 8\n",
      "Losses (1/50) {'ner': 343.15148222690095}\n",
      "Losses (2/50) {'ner': 928.2171471297314}\n",
      "Losses (3/50) {'ner': 458.03205911674274}\n",
      "Losses (4/50) {'ner': 222.05744538850638}\n",
      "Losses (5/50) {'ner': 196.616903941559}\n",
      "Losses (6/50) {'ner': 122.17040605458033}\n",
      "Losses (7/50) {'ner': 109.83167483811778}\n",
      "Losses (8/50) {'ner': 89.61189156221106}\n",
      "Losses (9/50) {'ner': 99.43939076568493}\n",
      "Losses (10/50) {'ner': 75.16599993028265}\n",
      "Losses (11/50) {'ner': 83.62123771512516}\n",
      "Losses (12/50) {'ner': 51.36946321727178}\n",
      "Losses (13/50) {'ner': 45.50232703166719}\n",
      "Losses (14/50) {'ner': 43.62009124555221}\n",
      "Losses (15/50) {'ner': 56.88902794462376}\n",
      "Losses (16/50) {'ner': 41.86478627601709}\n",
      "Losses (17/50) {'ner': 41.81933765663897}\n",
      "Losses (18/50) {'ner': 38.569082101539784}\n",
      "Losses (19/50) {'ner': 38.37404502260682}\n",
      "Losses (20/50) {'ner': 65.0624074564912}\n",
      "Losses (21/50) {'ner': 45.21357771714644}\n",
      "Losses (22/50) {'ner': 28.232644939884462}\n",
      "Losses (23/50) {'ner': 35.399025226145596}\n",
      "Losses (24/50) {'ner': 32.46137817796495}\n",
      "Losses (25/50) {'ner': 44.738532604033296}\n",
      "Losses (26/50) {'ner': 35.9251837620472}\n",
      "Losses (27/50) {'ner': 34.2661775007422}\n",
      "Losses (28/50) {'ner': 16.124595137907253}\n",
      "Losses (29/50) {'ner': 26.727314680934736}\n",
      "Losses (30/50) {'ner': 21.66336237705862}\n",
      "Losses (31/50) {'ner': 23.77815584830324}\n",
      "Losses (32/50) {'ner': 23.369057499042842}\n",
      "Losses (33/50) {'ner': 16.46898503190281}\n",
      "Losses (34/50) {'ner': 23.079328736380447}\n",
      "Losses (35/50) {'ner': 24.76845650350656}\n",
      "Losses (36/50) {'ner': 18.803929473867967}\n",
      "Losses (37/50) {'ner': 33.222343867277935}\n",
      "Losses (38/50) {'ner': 25.61916463463731}\n",
      "Losses (39/50) {'ner': 30.27322829661333}\n",
      "Losses (40/50) {'ner': 17.438378395726968}\n",
      "Losses (41/50) {'ner': 30.552742676078378}\n",
      "Losses (42/50) {'ner': 19.41170819030881}\n",
      "Losses (43/50) {'ner': 16.567674637523254}\n",
      "Losses (44/50) {'ner': 32.480339582389036}\n",
      "Losses (45/50) {'ner': 19.028378444840786}\n",
      "Losses (46/50) {'ner': 15.22942386479011}\n",
      "Losses (47/50) {'ner': 24.035332474617277}\n",
      "Losses (48/50) {'ner': 33.026750045981956}\n",
      "Losses (49/50) {'ner': 24.70728888491373}\n",
      "Losses (50/50) {'ner': 37.34293901327665}\n",
      "final loss:  {'ner': 37.34293901327665}\n",
      "test metrics:  {'token_acc': 1.0, 'token_p': 1.0, 'token_r': 1.0, 'token_f': 1.0, 'ents_p': 0.5, 'ents_r': 0.4, 'ents_f': 0.4444444444444445, 'ents_per_type': {'DATE': {'p': 0.5, 'r': 0.5, 'f': 0.5}, 'PAYMENT_DATE': {'p': 0.5, 'r': 1.0, 'f': 0.6666666666666666}, 'PAYMENT_AMOUNT': {'p': 0.0, 'r': 0.0, 'f': 0.0}}}\n",
      "time taken: 1101.3111629486084\n",
      "\n",
      "XXXXXXXXX\n",
      "\n",
      "Model instantiation\n",
      "\n",
      "Training Loop : 9\n",
      "Losses (1/50) {'ner': 378.42273174956114}\n",
      "Losses (2/50) {'ner': 712.2096910816006}\n",
      "Losses (3/50) {'ner': 604.2831823451855}\n",
      "Losses (4/50) {'ner': 293.63689996998073}\n",
      "Losses (5/50) {'ner': 233.93060043303473}\n",
      "Losses (6/50) {'ner': 133.99567664832205}\n",
      "Losses (7/50) {'ner': 136.35422178410215}\n",
      "Losses (8/50) {'ner': 107.93164321116976}\n",
      "Losses (9/50) {'ner': 92.71104193334361}\n",
      "Losses (10/50) {'ner': 89.07829712371223}\n",
      "Losses (11/50) {'ner': 68.95660697245738}\n",
      "Losses (12/50) {'ner': 71.49956558168246}\n",
      "Losses (13/50) {'ner': 54.02142973417515}\n",
      "Losses (14/50) {'ner': 44.20988413946232}\n",
      "Losses (15/50) {'ner': 46.12316423051831}\n",
      "Losses (16/50) {'ner': 39.00886422353942}\n",
      "Losses (17/50) {'ner': 43.77956709524924}\n",
      "Losses (18/50) {'ner': 54.70021483677207}\n",
      "Losses (19/50) {'ner': 42.56839774690792}\n",
      "Losses (20/50) {'ner': 34.30816879752235}\n",
      "Losses (21/50) {'ner': 42.44684359311997}\n",
      "Losses (22/50) {'ner': 41.0179522602814}\n",
      "Losses (23/50) {'ner': 54.71658661996137}\n",
      "Losses (24/50) {'ner': 38.8292991684884}\n",
      "Losses (25/50) {'ner': 48.77490211780735}\n",
      "Losses (26/50) {'ner': 28.58525840000379}\n",
      "Losses (27/50) {'ner': 28.970129268935082}\n",
      "Losses (28/50) {'ner': 29.946264397726136}\n",
      "Losses (29/50) {'ner': 29.581150179128173}\n",
      "Losses (30/50) {'ner': 19.61388737579482}\n",
      "Losses (31/50) {'ner': 36.83537779817843}\n",
      "Losses (32/50) {'ner': 30.437982876978065}\n",
      "Losses (33/50) {'ner': 25.201746581417353}\n",
      "Losses (34/50) {'ner': 28.160298356501286}\n",
      "Losses (35/50) {'ner': 22.68773919466234}\n",
      "Losses (36/50) {'ner': 33.60151175327675}\n",
      "Losses (37/50) {'ner': 24.203608904532}\n",
      "Losses (38/50) {'ner': 34.853068475578326}\n",
      "Losses (39/50) {'ner': 56.52401858244708}\n",
      "Losses (40/50) {'ner': 27.205898184632083}\n",
      "Losses (41/50) {'ner': 57.83108680754841}\n",
      "Losses (42/50) {'ner': 36.313498890740085}\n",
      "Losses (43/50) {'ner': 28.19138625706439}\n",
      "Losses (44/50) {'ner': 33.46818089808895}\n",
      "Losses (45/50) {'ner': 30.58616318637377}\n",
      "Losses (46/50) {'ner': 29.278717884621415}\n",
      "Losses (47/50) {'ner': 39.88272081158372}\n",
      "Losses (48/50) {'ner': 21.56773170871967}\n",
      "Losses (49/50) {'ner': 30.93269002818171}\n",
      "Losses (50/50) {'ner': 24.32594618982242}\n",
      "final loss:  {'ner': 24.32594618982242}\n",
      "test metrics:  {'token_acc': 1.0, 'token_p': 1.0, 'token_r': 1.0, 'token_f': 1.0, 'ents_p': 0.4, 'ents_r': 0.6666666666666666, 'ents_f': 0.5, 'ents_per_type': {'PAYMENT_AMOUNT': {'p': 0.5, 'r': 1.0, 'f': 0.6666666666666666}, 'PAYMENT_DATE': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'NUM_PAYMENTS': {'p': 1.0, 'r': 1.0, 'f': 1.0}, 'DATE': {'p': 0.0, 'r': 0.0, 'f': 0.0}}}\n",
      "time taken: 1240.4337079524994\n",
      "\n",
      "XXXXXXXXX\n",
      "\n",
      "Model instantiation\n",
      "\n",
      "Training Loop : 10\n",
      "Losses (1/50) {'ner': 438.0905910333196}\n",
      "Losses (2/50) {'ner': 551.795402509738}\n",
      "Losses (3/50) {'ner': 559.2654989159793}\n",
      "Losses (4/50) {'ner': 241.6394397840914}\n",
      "Losses (5/50) {'ner': 160.65953978545346}\n",
      "Losses (6/50) {'ner': 126.81499924734767}\n",
      "Losses (7/50) {'ner': 108.77276249470836}\n",
      "Losses (8/50) {'ner': 110.6536518551362}\n",
      "Losses (9/50) {'ner': 96.09322233110339}\n",
      "Losses (10/50) {'ner': 85.84002612577204}\n",
      "Losses (11/50) {'ner': 80.8146003956586}\n",
      "Losses (12/50) {'ner': 91.19511068523012}\n",
      "Losses (13/50) {'ner': 61.516874399528426}\n",
      "Losses (14/50) {'ner': 66.49075993374372}\n",
      "Losses (15/50) {'ner': 68.21322508293271}\n",
      "Losses (16/50) {'ner': 50.634858925548016}\n",
      "Losses (17/50) {'ner': 34.71024927363287}\n",
      "Losses (18/50) {'ner': 41.59047934187704}\n",
      "Losses (19/50) {'ner': 45.18920502292854}\n",
      "Losses (20/50) {'ner': 34.41554069029487}\n",
      "Losses (21/50) {'ner': 33.44559831295603}\n",
      "Losses (22/50) {'ner': 46.69330397663294}\n",
      "Losses (23/50) {'ner': 49.11291263254916}\n",
      "Losses (24/50) {'ner': 49.61045851819656}\n",
      "Losses (25/50) {'ner': 40.55282215653015}\n",
      "Losses (26/50) {'ner': 28.447973536969975}\n",
      "Losses (27/50) {'ner': 48.12828197617114}\n",
      "Losses (28/50) {'ner': 39.16105595613258}\n",
      "Losses (29/50) {'ner': 57.12741510598134}\n",
      "Losses (30/50) {'ner': 50.903785046825654}\n",
      "Losses (31/50) {'ner': 27.77016176129}\n",
      "Losses (32/50) {'ner': 47.87347553456796}\n",
      "Losses (33/50) {'ner': 30.527383024484585}\n",
      "Losses (34/50) {'ner': 25.38136200193525}\n",
      "Losses (35/50) {'ner': 31.262027171439303}\n",
      "Losses (36/50) {'ner': 36.722527134347864}\n",
      "Losses (37/50) {'ner': 32.682663644876094}\n",
      "Losses (38/50) {'ner': 36.18862274473583}\n",
      "Losses (39/50) {'ner': 25.331828824252323}\n",
      "Losses (40/50) {'ner': 21.261577188575224}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses (41/50) {'ner': 20.102469723626143}\n",
      "Losses (42/50) {'ner': 22.522330598451365}\n",
      "Losses (43/50) {'ner': 24.00248281691108}\n",
      "Losses (44/50) {'ner': 18.204749406594626}\n",
      "Losses (45/50) {'ner': 21.100572618700394}\n",
      "Losses (46/50) {'ner': 24.784985576473467}\n",
      "Losses (47/50) {'ner': 49.913118532176156}\n",
      "Losses (48/50) {'ner': 17.072393444128377}\n",
      "Losses (49/50) {'ner': 30.30205692629643}\n",
      "Losses (50/50) {'ner': 22.361713695643136}\n",
      "final loss:  {'ner': 22.361713695643136}\n",
      "test metrics:  {'token_acc': 1.0, 'token_p': 1.0, 'token_r': 1.0, 'token_f': 1.0, 'ents_p': 0.6, 'ents_r': 0.5, 'ents_f': 0.5454545454545454, 'ents_per_type': {'NUM_PAYMENTS': {'p': 1.0, 'r': 1.0, 'f': 1.0}, 'PAYMENT_DATE': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'DATE': {'p': 1.0, 'r': 1.0, 'f': 1.0}, 'PAYMENT_AMOUNT': {'p': 0.0, 'r': 0.0, 'f': 0.0}}}\n",
      "time taken: 1382.0181481838226\n",
      "\n",
      "XXXXXXXXX\n",
      "\n",
      "Model instantiation\n",
      "\n",
      "Training Loop : 11\n",
      "Losses (1/50) {'ner': 425.5082741729374}\n",
      "Losses (2/50) {'ner': 756.5349874952275}\n",
      "Losses (3/50) {'ner': 535.7460196976328}\n",
      "Losses (4/50) {'ner': 260.4660247978711}\n",
      "Losses (5/50) {'ner': 172.95272717816727}\n",
      "Losses (6/50) {'ner': 153.87663748062872}\n",
      "Losses (7/50) {'ner': 123.70367731932204}\n",
      "Losses (8/50) {'ner': 84.48945101480994}\n",
      "Losses (9/50) {'ner': 64.71439465170155}\n",
      "Losses (10/50) {'ner': 79.44708818229503}\n",
      "Losses (11/50) {'ner': 80.85073351996414}\n",
      "Losses (12/50) {'ner': 82.39298977799929}\n",
      "Losses (13/50) {'ner': 61.98002199220132}\n",
      "Losses (14/50) {'ner': 41.13062424889204}\n",
      "Losses (15/50) {'ner': 48.3912398136569}\n",
      "Losses (16/50) {'ner': 55.74338137799429}\n",
      "Losses (17/50) {'ner': 61.23997672487954}\n",
      "Losses (18/50) {'ner': 32.424439288388875}\n",
      "Losses (19/50) {'ner': 54.40150601246903}\n",
      "Losses (20/50) {'ner': 46.643933465549644}\n",
      "Losses (21/50) {'ner': 50.30575904723391}\n",
      "Losses (22/50) {'ner': 38.345501687602855}\n",
      "Losses (23/50) {'ner': 50.54671657885037}\n",
      "Losses (24/50) {'ner': 44.030265886460754}\n",
      "Losses (25/50) {'ner': 27.016586511356213}\n",
      "Losses (26/50) {'ner': 33.71384291504257}\n",
      "Losses (27/50) {'ner': 30.23576888248056}\n",
      "Losses (28/50) {'ner': 33.199588095079235}\n",
      "Losses (29/50) {'ner': 43.534270939721345}\n",
      "Losses (30/50) {'ner': 30.674339381766373}\n",
      "Losses (31/50) {'ner': 39.532021612335946}\n",
      "Losses (32/50) {'ner': 30.77553519321111}\n",
      "Losses (33/50) {'ner': 24.933157583330257}\n",
      "Losses (34/50) {'ner': 23.044359179473883}\n",
      "Losses (35/50) {'ner': 33.69983402903024}\n",
      "Losses (36/50) {'ner': 28.610322459626026}\n",
      "Losses (37/50) {'ner': 26.96292287330541}\n",
      "Losses (38/50) {'ner': 31.1579614616252}\n",
      "Losses (39/50) {'ner': 21.428460991064252}\n",
      "Losses (40/50) {'ner': 27.261051289073787}\n",
      "Losses (41/50) {'ner': 45.87638707335879}\n",
      "Losses (42/50) {'ner': 40.75007453257474}\n",
      "Losses (43/50) {'ner': 32.703056743796346}\n",
      "Losses (44/50) {'ner': 27.259498004873212}\n",
      "Losses (45/50) {'ner': 28.78553284402818}\n",
      "Losses (46/50) {'ner': 22.29131884885844}\n",
      "Losses (47/50) {'ner': 20.80837423197137}\n",
      "Losses (48/50) {'ner': 21.145674553166213}\n",
      "Losses (49/50) {'ner': 23.123626319670286}\n",
      "Losses (50/50) {'ner': 20.913982963928987}\n",
      "final loss:  {'ner': 20.913982963928987}\n",
      "test metrics:  {'token_acc': 1.0, 'token_p': 1.0, 'token_r': 1.0, 'token_f': 1.0, 'ents_p': 0.8, 'ents_r': 1.0, 'ents_f': 0.888888888888889, 'ents_per_type': {'DATE': {'p': 1.0, 'r': 1.0, 'f': 1.0}, 'NUM_PAYMENTS': {'p': 0.5, 'r': 1.0, 'f': 0.6666666666666666}, 'PAYMENT_AMOUNT': {'p': 1.0, 'r': 1.0, 'f': 1.0}, 'PAYMENT_DATE': {'p': 1.0, 'r': 1.0, 'f': 1.0}}}\n",
      "time taken: 1520.6750888824463\n",
      "\n",
      "XXXXXXXXX\n",
      "\n",
      "CPU times: user 24min 15s, sys: 57.8 s, total: 25min 13s\n",
      "Wall time: 25min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('Training Begins...\\n')\n",
    "nlps, losses, test_eval_metrics = cross_val(spacy_df, epochs=50, num_evals=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "greenhouse-compression",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 11, 11)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlps), len(losses), len(test_eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "stuffed-shock",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ner': 41.87135923200714},\n",
       " {'ner': 27.10235894175824},\n",
       " {'ner': 29.52039819118861},\n",
       " {'ner': 15.149938515304576},\n",
       " {'ner': 27.315871089080584},\n",
       " {'ner': 25.553136613272546},\n",
       " {'ner': 28.178007650354882},\n",
       " {'ner': 37.34293901327665},\n",
       " {'ner': 24.32594618982242},\n",
       " {'ner': 22.361713695643136},\n",
       " {'ner': 20.913982963928987}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "duplicate-insight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 8)\n"
     ]
    }
   ],
   "source": [
    "test_eval_metrics = pd.DataFrame(test_eval_metrics)\n",
    "print(test_eval_metrics.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "boolean-prophet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_acc</th>\n",
       "      <th>token_p</th>\n",
       "      <th>token_r</th>\n",
       "      <th>token_f</th>\n",
       "      <th>ents_p</th>\n",
       "      <th>ents_r</th>\n",
       "      <th>ents_f</th>\n",
       "      <th>ents_per_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'DATE': {'p': 1.0, 'r': 1.0, 'f': 1.0}, 'NUM_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>{'DATE': {'p': 1.0, 'r': 1.0, 'f': 1.0}, 'NUM_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'DATE': {'p': 1.0, 'r': 1.0, 'f': 1.0}, 'NUM_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>{'DATE': {'p': 1.0, 'r': 1.0, 'f': 1.0}, 'NUM_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>{'DATE': {'p': 1.0, 'r': 1.0, 'f': 1.0}, 'NUM_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>{'DATE': {'p': 0.5, 'r': 1.0, 'f': 0.666666666...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>{'DATE': {'p': 1.0, 'r': 1.0, 'f': 1.0}, 'NUM_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>{'DATE': {'p': 0.5, 'r': 0.5, 'f': 0.5}, 'PAYM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>{'PAYMENT_AMOUNT': {'p': 0.5, 'r': 1.0, 'f': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>{'NUM_PAYMENTS': {'p': 1.0, 'r': 1.0, 'f': 1.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>{'DATE': {'p': 1.0, 'r': 1.0, 'f': 1.0}, 'NUM_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    token_acc  token_p  token_r  token_f    ents_p    ents_r    ents_f  \\\n",
       "0         1.0      1.0      1.0      1.0  1.000000  1.000000  1.000000   \n",
       "1         1.0      1.0      1.0      1.0  0.750000  1.000000  0.857143   \n",
       "2         1.0      1.0      1.0      1.0  1.000000  1.000000  1.000000   \n",
       "3         1.0      1.0      1.0      1.0  0.625000  0.625000  0.625000   \n",
       "4         1.0      1.0      1.0      1.0  0.750000  1.000000  0.857143   \n",
       "5         1.0      1.0      1.0      1.0  0.333333  0.500000  0.400000   \n",
       "6         1.0      1.0      1.0      1.0  0.750000  1.000000  0.857143   \n",
       "7         1.0      1.0      1.0      1.0  0.500000  0.400000  0.444444   \n",
       "8         1.0      1.0      1.0      1.0  0.400000  0.666667  0.500000   \n",
       "9         1.0      1.0      1.0      1.0  0.600000  0.500000  0.545455   \n",
       "10        1.0      1.0      1.0      1.0  0.800000  1.000000  0.888889   \n",
       "\n",
       "                                        ents_per_type  \n",
       "0   {'DATE': {'p': 1.0, 'r': 1.0, 'f': 1.0}, 'NUM_...  \n",
       "1   {'DATE': {'p': 1.0, 'r': 1.0, 'f': 1.0}, 'NUM_...  \n",
       "2   {'DATE': {'p': 1.0, 'r': 1.0, 'f': 1.0}, 'NUM_...  \n",
       "3   {'DATE': {'p': 1.0, 'r': 1.0, 'f': 1.0}, 'NUM_...  \n",
       "4   {'DATE': {'p': 1.0, 'r': 1.0, 'f': 1.0}, 'NUM_...  \n",
       "5   {'DATE': {'p': 0.5, 'r': 1.0, 'f': 0.666666666...  \n",
       "6   {'DATE': {'p': 1.0, 'r': 1.0, 'f': 1.0}, 'NUM_...  \n",
       "7   {'DATE': {'p': 0.5, 'r': 0.5, 'f': 0.5}, 'PAYM...  \n",
       "8   {'PAYMENT_AMOUNT': {'p': 0.5, 'r': 1.0, 'f': 0...  \n",
       "9   {'NUM_PAYMENTS': {'p': 1.0, 'r': 1.0, 'f': 1.0...  \n",
       "10  {'DATE': {'p': 1.0, 'r': 1.0, 'f': 1.0}, 'NUM_...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_eval_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "south-florence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DATE': {'p': 1.0, 'r': 1.0, 'f': 1.0},\n",
       " 'NUM_PAYMENTS': {'p': 0.5, 'r': 1.0, 'f': 0.6666666666666666},\n",
       " 'PAYMENT_AMOUNT': {'p': 1.0, 'r': 1.0, 'f': 1.0},\n",
       " 'PAYMENT_DATE': {'p': 1.0, 'r': 1.0, 'f': 1.0}}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_eval_metrics['ents_per_type'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "solved-instruction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Precision across 11 runs:  0.6825757575757575\n",
      "Average Recall across 11 runs:  0.7901515151515152\n",
      "Average F-Score across 11 runs:  0.7250196772924046\n"
     ]
    }
   ],
   "source": [
    "print('Average Precision across 11 runs: ', test_eval_metrics['ents_p'].mean())\n",
    "print('Average Recall across 11 runs: ', test_eval_metrics['ents_r'].mean())\n",
    "print('Average F-Score across 11 runs: ', test_eval_metrics['ents_f'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-piece",
   "metadata": {},
   "source": [
    "## Experiment 2 - Flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "confirmed-identification",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preparation\n",
    "def _tokenize(text, case_sensitive): \n",
    "      \n",
    "    if not case_sensitive: \n",
    "        text = text.lower() \n",
    "\n",
    "    words = re.sub( \n",
    "         # there is a space or an end of a string after it \n",
    "         r\"[^\\w#@&]+(?=\\s|$)|\" \n",
    "         # there is a space or beginning of a string before it \n",
    "         # not followed by a number \n",
    "         r\"(\\s|^)[^\\w#@&]+(?=[^0-9\\s])|\" \n",
    "         # not in between numbers and not . or @ or & or - or # \n",
    "         # e.g. 10'000.00 or blabla@gmail.com \n",
    "         # and not url characters \n",
    "         r\"(?<=[^0-9\\s])[^\\w._~:/?#\\[\\]()@!$&*+,;=-]+(?=[^0-9\\s])\", \n",
    "         \" \", \n",
    "         text, \n",
    "    ).split() \n",
    "\n",
    "    return words\n",
    "\n",
    "\n",
    "def _format_input(example, case_sensitive):\n",
    "    inp, entities = example.get('text'), example.get('entities')\n",
    "    if entities:\n",
    "        texts = [] \n",
    "        new_start = 0\n",
    "        for entity in entities: \n",
    "            start, end = entity['start'], entity['end'] \n",
    "            other_text_tokens = [(x, 'O') for x in\n",
    "                                 _tokenize(inp[new_start:start],\n",
    "                                                case_sensitive)] \n",
    "            if other_text_tokens: \n",
    "                texts += other_text_tokens\n",
    "            text_tokens = []\n",
    "            for token in _tokenize(entity['value'], case_sensitive):\n",
    "                text_tokens.append((token, entity['entity']))\n",
    "            texts += text_tokens\n",
    "            #value = entity['value'].replace(' ', '_')\n",
    "            #texts += [(value, entity['entity'])] \n",
    "            new_start = end\n",
    "        other_text_tokens = [(x, 'O') for x in _tokenize(inp[new_start:], case_sensitive)]\n",
    "        if other_text_tokens:\n",
    "            texts += other_text_tokens\n",
    "    else:\n",
    "        texts = [(x, 'O') for x in _tokenize(inp, case_sensitive)]\n",
    "\n",
    "    return texts\n",
    "\n",
    "\n",
    "def prepare_data_for_flair(row):\n",
    "    out = []\n",
    "    for ent in row['entity']:\n",
    "        ent_n = {'start': ent['span'][0],\n",
    "                 'end': ent['span'][-1],\n",
    "                 'value': ent['string'],\n",
    "                 'entity': ent['type']}\n",
    "        out.append(ent_n)\n",
    "    return {'text': row['text'], 'entities': out}\n",
    "\n",
    "\n",
    "def _save_data_for_training(examples, file_name, model_dir, case_sensitive=True):\n",
    "        \n",
    "    file_name = os.path.join(model_dir, file_name)\n",
    "    fn = open(file_name, 'w')\n",
    "    for example in examples:\n",
    "        example_prep = prepare_data_for_flair(example)\n",
    "        out = _format_input(example_prep, case_sensitive)\n",
    "        fn.write('\\n'.join(str(x[0])+' '+str(x[1]) for x in out))\n",
    "        fn.write('\\n\\n')\n",
    "    fn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "decent-potato",
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAIR_FT_MODEL_DIR = os.path.join(MODEL_DIR, \"flair_ft_v1\")\n",
    "FLAIR_MODEL_DIR = os.path.join(MODEL_DIR, \"flair_v1\")\n",
    "_save_data_for_training(df_pre, 'train.txt', FLAIR_FT_MODEL_DIR, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "decent-collectible",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 20:12:28,512 Reading data from /Users/varunnathan/Documents/General/ExternalTest/Prodigal/model/flair_ft_v1\n",
      "2021-06-20 20:12:28,513 Train: /Users/varunnathan/Documents/General/ExternalTest/Prodigal/model/flair_ft_v1/train.txt\n",
      "2021-06-20 20:12:28,513 Dev: None\n",
      "2021-06-20 20:12:28,514 Test: None\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Corpus\n",
    "from flair.datasets import ColumnCorpus\n",
    "\n",
    "# define columns\n",
    "columns = {0: 'text', 1: 'ner'}\n",
    "\n",
    "# this is the folder in which train, test and dev files reside\n",
    "data_folder = FLAIR_FT_MODEL_DIR\n",
    "\n",
    "# init a corpus using column format, data folder and the names of the train, dev and test files\n",
    "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
    "                              train_file='train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "relative-senegal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "nine seven three and then let us just go over with this arrangement and then we will be completely set please state mister is december <DATE> twenty <DATE> first <DATE> two <DATE> thousand <DATE> twenty <DATE> authorize authorized one <NUM_PAYMENTS> time <NUM_PAYMENTS> transaction and of twelve <PAYMENT_AMOUNT> dollar <PAYMENT_AMOUNT> and <PAYMENT_AMOUNT> ninety <PAYMENT_AMOUNT> seven <PAYMENT_AMOUNT> cents <PAYMENT_AMOUNT> be address from your card will be processed as an electronic and solutions and your stevens if you just need to cause it has recording shipping is your electronic signature can please speak your full name ai i agree\n"
     ]
    }
   ],
   "source": [
    "print(len(corpus.train))\n",
    "print(corpus.train[0].to_tagged_string('ner'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "urban-karma",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flair\n",
    "from flair.embeddings import (TokenEmbeddings,StackedEmbeddings, FlairEmbeddings)\n",
    "from flair.trainers import ModelTrainer\n",
    "from flair.models import SequenceTagger\n",
    "import torch\n",
    "\n",
    "\n",
    "def train(corpus, model_dir, fine_tuning=True, config={\"use_crf\": True,\n",
    "                \"hidden_size\": 256,\n",
    "                \"learning_rate\": 0.1,\n",
    "                \"mini_batch_size\": 32,\n",
    "                \"max_epochs\": 75}):\n",
    "\n",
    "    flair.device = torch.device('cpu')\n",
    "    \n",
    "    print('create tag dictionary')\n",
    "    tag_type = 'ner'\n",
    "    tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n",
    "\n",
    "    if not fine_tuning:\n",
    "        print('training from scratch\\n')\n",
    "        \n",
    "        print('Embeddings init')\n",
    "        embedding_types: List[TokenEmbeddings] = [\n",
    "            FlairEmbeddings('news-forward'),\n",
    "            FlairEmbeddings('news-backward'),\n",
    "        ]\n",
    "\n",
    "        embeddings: StackedEmbeddings = StackedEmbeddings(\n",
    "            embeddings=embedding_types)\n",
    "\n",
    "        print('Sequence tagger init')\n",
    "        tagger: SequenceTagger = SequenceTagger(hidden_size=config['hidden_size'],\n",
    "                                        embeddings=embeddings,\n",
    "                                        tag_dictionary=tag_dictionary,\n",
    "                                        tag_type=tag_type,\n",
    "                                        use_crf=config['use_crf'])\n",
    "    else:\n",
    "        print('fine-tuning\\n')\n",
    "        tagger: SequenceTagger = SequenceTagger.load('ner')\n",
    "\n",
    "    print('Model Trainer')\n",
    "    trainer: ModelTrainer = ModelTrainer(tagger, corpus)\n",
    "\n",
    "    print('Training begins')\n",
    "    trainer.train(model_dir, learning_rate=config['learning_rate'],\n",
    "                  mini_batch_size=config['mini_batch_size'],\n",
    "                  max_epochs=config['max_epochs'])\n",
    "\n",
    "    print('load model')\n",
    "    model = SequenceTagger.load(os.path.join(model_dir, 'final-model.pt'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "faced-plaza",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence\n",
    "import copy\n",
    "flair.device = torch.device('cpu')\n",
    "\n",
    "\n",
    "def combine_contiguous_words(entity_n, label_k='pred_label', start_pos_k='start_pos',\n",
    "                             end_pos_k='end_pos', text_k='text', score_k='pred_score'):\n",
    "    out = []\n",
    "    for i, ent in enumerate(entity_n[1:]):\n",
    "        if i == 0:\n",
    "            prev_ent = entity_n[0]\n",
    "        else:\n",
    "            if out:\n",
    "                prev_ent = out[-1]\n",
    "            else:\n",
    "                prev_ent = entity_n[i-1]\n",
    "        if ((prev_ent[label_k] == ent[label_k])\n",
    "            and (prev_ent[end_pos_k] == ent[start_pos_k] - 1)):\n",
    "            d = {text_k: prev_ent[text_k] + ' ' + ent[text_k],\n",
    "                 start_pos_k: prev_ent[start_pos_k], end_pos_k: ent[end_pos_k],\n",
    "                 label_k: prev_ent[label_k],\n",
    "                 score_k: min([prev_ent[score_k], ent[score_k]])}\n",
    "            if i == 0:\n",
    "                out.append(d)\n",
    "            else:\n",
    "                out[-1] = d\n",
    "        else:\n",
    "            out.append(ent)\n",
    "    return out\n",
    "\n",
    "\n",
    "def predict(model, text):\n",
    "    text_pre = preprocess(text)\n",
    "    sentence = Sentence(text_pre)\n",
    "    model.predict(sentence)\n",
    "    out = sentence.to_dict(tag_type='ner')\n",
    "    entity = out.get('entities', [])\n",
    "    entity_n = []\n",
    "    for row in entity:\n",
    "        row1 = copy.deepcopy(row)\n",
    "        row1['pred_label'] = row['labels'][0]._value\n",
    "        row1['pred_score'] = row['labels'][0]._score\n",
    "        entity_n.append(row1)\n",
    "    \n",
    "    # combine contiguous parts\n",
    "    out = combine_contiguous_words(entity_n)\n",
    "    \n",
    "    return entity_n, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fundamental-relay",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create tag dictionary\n",
      "fine-tuning\n",
      "\n",
      "2021-06-20 21:22:46,095 loading file /Users/varunnathan/.flair/models/en-ner-conll03-v0.4.pt\n",
      "Model Trainer\n",
      "Training begins\n",
      "2021-06-20 21:22:49,359 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:22:49,362 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings('/home/aakbik/.flair/embeddings/glove.gensim')\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.05, inplace=False)\n",
      "        (encoder): Embedding(300, 100)\n",
      "        (rnn): LSTM(100, 2048)\n",
      "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (list_embedding_2): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.05, inplace=False)\n",
      "        (encoder): Embedding(300, 100)\n",
      "        (rnn): LSTM(100, 2048)\n",
      "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=4196, out_features=4196, bias=True)\n",
      "  (rnn): LSTM(4196, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2021-06-20 21:22:49,362 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:22:49,363 Corpus: \"Corpus: 41 train + 4 dev + 5 test sentences\"\n",
      "2021-06-20 21:22:49,364 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:22:49,364 Parameters:\n",
      "2021-06-20 21:22:49,365  - learning_rate: \"0.1\"\n",
      "2021-06-20 21:22:49,366  - mini_batch_size: \"8\"\n",
      "2021-06-20 21:22:49,366  - patience: \"3\"\n",
      "2021-06-20 21:22:49,367  - anneal_factor: \"0.5\"\n",
      "2021-06-20 21:22:49,367  - max_epochs: \"75\"\n",
      "2021-06-20 21:22:49,368  - shuffle: \"True\"\n",
      "2021-06-20 21:22:49,369  - train_with_dev: \"False\"\n",
      "2021-06-20 21:22:49,369  - batch_growth_annealing: \"False\"\n",
      "2021-06-20 21:22:49,370 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:22:49,371 Model training base path: \"/Users/varunnathan/Documents/General/ExternalTest/Prodigal/model/flair_ft_v1\"\n",
      "2021-06-20 21:22:49,372 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:22:49,372 Device: cpu\n",
      "2021-06-20 21:22:49,373 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:22:49,374 Embeddings storage mode: cpu\n",
      "2021-06-20 21:22:49,379 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:22:51,527 epoch 1 - iter 1/6 - loss 392.45190430 - samples/sec: 3.73 - lr: 0.100000\n",
      "2021-06-20 21:22:54,069 epoch 1 - iter 2/6 - loss 392.21998596 - samples/sec: 3.15 - lr: 0.100000\n",
      "2021-06-20 21:22:55,981 epoch 1 - iter 3/6 - loss 337.60635885 - samples/sec: 4.19 - lr: 0.100000\n",
      "2021-06-20 21:22:58,029 epoch 1 - iter 4/6 - loss 296.59355164 - samples/sec: 3.91 - lr: 0.100000\n",
      "2021-06-20 21:23:00,594 epoch 1 - iter 5/6 - loss 270.43263550 - samples/sec: 3.12 - lr: 0.100000\n",
      "2021-06-20 21:23:01,191 epoch 1 - iter 6/6 - loss 242.06166077 - samples/sec: 13.42 - lr: 0.100000\n",
      "2021-06-20 21:23:01,193 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:23:01,193 EPOCH 1 done: loss 242.0617 - lr 0.1000000\n",
      "2021-06-20 21:23:01,634 DEV : loss 64.82209777832031 - score 0.0\n",
      "2021-06-20 21:23:01,638 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-06-20 21:23:04,382 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:23:06,581 epoch 2 - iter 1/6 - loss 74.80157471 - samples/sec: 3.64 - lr: 0.100000\n",
      "2021-06-20 21:23:08,124 epoch 2 - iter 2/6 - loss 72.91359329 - samples/sec: 5.19 - lr: 0.100000\n",
      "2021-06-20 21:23:09,781 epoch 2 - iter 3/6 - loss 64.92178345 - samples/sec: 4.83 - lr: 0.100000\n",
      "2021-06-20 21:23:11,755 epoch 2 - iter 4/6 - loss 57.31455040 - samples/sec: 4.06 - lr: 0.100000\n",
      "2021-06-20 21:23:14,307 epoch 2 - iter 5/6 - loss 58.11056671 - samples/sec: 3.13 - lr: 0.100000\n",
      "2021-06-20 21:23:14,687 epoch 2 - iter 6/6 - loss 51.56699244 - samples/sec: 21.15 - lr: 0.100000\n",
      "2021-06-20 21:23:14,688 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:23:14,688 EPOCH 2 done: loss 51.5670 - lr 0.1000000\n",
      "2021-06-20 21:23:15,126 DEV : loss 39.376739501953125 - score 0.0\n",
      "2021-06-20 21:23:15,130 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-06-20 21:23:18,002 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:23:20,215 epoch 3 - iter 1/6 - loss 31.52667999 - samples/sec: 3.62 - lr: 0.100000\n",
      "2021-06-20 21:23:21,864 epoch 3 - iter 2/6 - loss 33.05952454 - samples/sec: 4.85 - lr: 0.100000\n",
      "2021-06-20 21:23:23,491 epoch 3 - iter 3/6 - loss 29.77582677 - samples/sec: 4.92 - lr: 0.100000\n",
      "2021-06-20 21:23:25,612 epoch 3 - iter 4/6 - loss 28.96148205 - samples/sec: 3.77 - lr: 0.100000\n",
      "2021-06-20 21:23:28,109 epoch 3 - iter 5/6 - loss 27.52233810 - samples/sec: 3.21 - lr: 0.100000\n",
      "2021-06-20 21:23:28,577 epoch 3 - iter 6/6 - loss 25.23809751 - samples/sec: 17.11 - lr: 0.100000\n",
      "2021-06-20 21:23:28,579 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:23:28,580 EPOCH 3 done: loss 25.2381 - lr 0.1000000\n",
      "2021-06-20 21:23:28,957 DEV : loss 6.162933349609375 - score 0.0\n",
      "2021-06-20 21:23:28,959 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-06-20 21:23:31,467 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:23:33,232 epoch 4 - iter 1/6 - loss 21.60051727 - samples/sec: 4.54 - lr: 0.100000\n",
      "2021-06-20 21:23:35,372 epoch 4 - iter 2/6 - loss 20.57049942 - samples/sec: 3.74 - lr: 0.100000\n",
      "2021-06-20 21:23:37,222 epoch 4 - iter 3/6 - loss 17.90667725 - samples/sec: 4.33 - lr: 0.100000\n",
      "2021-06-20 21:23:39,269 epoch 4 - iter 4/6 - loss 16.48545837 - samples/sec: 3.91 - lr: 0.100000\n",
      "2021-06-20 21:23:41,776 epoch 4 - iter 5/6 - loss 17.33080750 - samples/sec: 3.19 - lr: 0.100000\n",
      "2021-06-20 21:23:42,129 epoch 4 - iter 6/6 - loss 19.74501292 - samples/sec: 22.68 - lr: 0.100000\n",
      "2021-06-20 21:23:42,130 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:23:42,131 EPOCH 4 done: loss 19.7450 - lr 0.1000000\n",
      "2021-06-20 21:23:42,480 DEV : loss 4.452056884765625 - score 0.0\n",
      "2021-06-20 21:23:42,482 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-06-20 21:23:44,960 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:23:47,660 epoch 5 - iter 1/6 - loss 18.39698792 - samples/sec: 2.96 - lr: 0.100000\n",
      "2021-06-20 21:23:50,218 epoch 5 - iter 2/6 - loss 21.38674164 - samples/sec: 3.13 - lr: 0.100000\n",
      "2021-06-20 21:23:52,002 epoch 5 - iter 3/6 - loss 21.22187297 - samples/sec: 4.49 - lr: 0.100000\n",
      "2021-06-20 21:23:53,827 epoch 5 - iter 4/6 - loss 23.50336456 - samples/sec: 4.39 - lr: 0.100000\n",
      "2021-06-20 21:23:55,220 epoch 5 - iter 5/6 - loss 21.44048462 - samples/sec: 5.75 - lr: 0.100000\n",
      "2021-06-20 21:23:55,581 epoch 5 - iter 6/6 - loss 18.75319926 - samples/sec: 22.22 - lr: 0.100000\n",
      "2021-06-20 21:23:55,582 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:23:55,582 EPOCH 5 done: loss 18.7532 - lr 0.1000000\n",
      "2021-06-20 21:23:55,941 DEV : loss 4.26239013671875 - score 0.0\n",
      "2021-06-20 21:23:55,944 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-06-20 21:23:58,445 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:24:00,143 epoch 6 - iter 1/6 - loss 11.70266724 - samples/sec: 4.72 - lr: 0.100000\n",
      "2021-06-20 21:24:03,314 epoch 6 - iter 2/6 - loss 12.71459198 - samples/sec: 2.52 - lr: 0.100000\n",
      "2021-06-20 21:24:05,315 epoch 6 - iter 3/6 - loss 21.52324422 - samples/sec: 4.00 - lr: 0.100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 21:24:06,961 epoch 6 - iter 4/6 - loss 19.28216553 - samples/sec: 4.86 - lr: 0.100000\n",
      "2021-06-20 21:24:09,067 epoch 6 - iter 5/6 - loss 18.70411987 - samples/sec: 3.80 - lr: 0.100000\n",
      "2021-06-20 21:24:09,393 epoch 6 - iter 6/6 - loss 16.83625793 - samples/sec: 24.61 - lr: 0.100000\n",
      "2021-06-20 21:24:09,394 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:24:09,395 EPOCH 6 done: loss 16.8363 - lr 0.1000000\n",
      "2021-06-20 21:24:09,751 DEV : loss 6.406829833984375 - score 0.0\n",
      "2021-06-20 21:24:09,753 BAD EPOCHS (no improvement): 1\n",
      "2021-06-20 21:24:09,754 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:24:12,042 epoch 7 - iter 1/6 - loss 9.27673340 - samples/sec: 3.50 - lr: 0.100000\n",
      "2021-06-20 21:24:14,472 epoch 7 - iter 2/6 - loss 13.48899841 - samples/sec: 3.29 - lr: 0.100000\n",
      "2021-06-20 21:24:16,323 epoch 7 - iter 3/6 - loss 19.89616394 - samples/sec: 4.33 - lr: 0.100000\n",
      "2021-06-20 21:24:18,713 epoch 7 - iter 4/6 - loss 20.11148262 - samples/sec: 3.35 - lr: 0.100000\n",
      "2021-06-20 21:24:20,202 epoch 7 - iter 5/6 - loss 22.34629974 - samples/sec: 5.37 - lr: 0.100000\n",
      "2021-06-20 21:24:20,615 epoch 7 - iter 6/6 - loss 20.30003738 - samples/sec: 19.40 - lr: 0.100000\n",
      "2021-06-20 21:24:20,616 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:24:20,617 EPOCH 7 done: loss 20.3000 - lr 0.1000000\n",
      "2021-06-20 21:24:20,985 DEV : loss 5.193359375 - score 0.0\n",
      "2021-06-20 21:24:20,987 BAD EPOCHS (no improvement): 2\n",
      "2021-06-20 21:24:20,988 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:24:22,625 epoch 8 - iter 1/6 - loss 10.70773315 - samples/sec: 4.89 - lr: 0.100000\n",
      "2021-06-20 21:24:24,492 epoch 8 - iter 2/6 - loss 11.43237686 - samples/sec: 4.29 - lr: 0.100000\n",
      "2021-06-20 21:24:26,720 epoch 8 - iter 3/6 - loss 11.15323130 - samples/sec: 3.59 - lr: 0.100000\n",
      "2021-06-20 21:24:28,565 epoch 8 - iter 4/6 - loss 10.59348106 - samples/sec: 4.34 - lr: 0.100000\n",
      "2021-06-20 21:24:30,808 epoch 8 - iter 5/6 - loss 13.54654846 - samples/sec: 3.57 - lr: 0.100000\n",
      "2021-06-20 21:24:31,264 epoch 8 - iter 6/6 - loss 13.07962290 - samples/sec: 17.58 - lr: 0.100000\n",
      "2021-06-20 21:24:31,265 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:24:31,265 EPOCH 8 done: loss 13.0796 - lr 0.1000000\n",
      "2021-06-20 21:24:31,721 DEV : loss 4.746307373046875 - score 0.0\n",
      "2021-06-20 21:24:31,723 BAD EPOCHS (no improvement): 3\n",
      "2021-06-20 21:24:31,724 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:24:33,853 epoch 9 - iter 1/6 - loss 6.09487915 - samples/sec: 3.76 - lr: 0.100000\n",
      "2021-06-20 21:24:36,464 epoch 9 - iter 2/6 - loss 7.58425140 - samples/sec: 3.07 - lr: 0.100000\n",
      "2021-06-20 21:24:38,718 epoch 9 - iter 3/6 - loss 8.65293884 - samples/sec: 3.55 - lr: 0.100000\n",
      "2021-06-20 21:24:40,884 epoch 9 - iter 4/6 - loss 10.26134491 - samples/sec: 3.70 - lr: 0.100000\n",
      "2021-06-20 21:24:42,613 epoch 9 - iter 5/6 - loss 10.73270874 - samples/sec: 4.63 - lr: 0.100000\n",
      "2021-06-20 21:24:43,108 epoch 9 - iter 6/6 - loss 11.05795797 - samples/sec: 16.17 - lr: 0.100000\n",
      "2021-06-20 21:24:43,109 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:24:43,110 EPOCH 9 done: loss 11.0580 - lr 0.1000000\n",
      "2021-06-20 21:24:43,493 DEV : loss 4.450164794921875 - score 0.0\n",
      "Epoch     9: reducing learning rate of group 0 to 5.0000e-02.\n",
      "2021-06-20 21:24:43,496 BAD EPOCHS (no improvement): 4\n",
      "2021-06-20 21:24:43,497 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:24:45,605 epoch 10 - iter 1/6 - loss 11.13775635 - samples/sec: 3.80 - lr: 0.050000\n",
      "2021-06-20 21:24:47,122 epoch 10 - iter 2/6 - loss 10.25659943 - samples/sec: 5.28 - lr: 0.050000\n",
      "2021-06-20 21:24:48,910 epoch 10 - iter 3/6 - loss 10.09435018 - samples/sec: 4.48 - lr: 0.050000\n",
      "2021-06-20 21:24:50,647 epoch 10 - iter 4/6 - loss 8.52490616 - samples/sec: 4.61 - lr: 0.050000\n",
      "2021-06-20 21:24:52,676 epoch 10 - iter 5/6 - loss 9.54586487 - samples/sec: 3.95 - lr: 0.050000\n",
      "2021-06-20 21:24:53,151 epoch 10 - iter 6/6 - loss 9.76366425 - samples/sec: 16.88 - lr: 0.050000\n",
      "2021-06-20 21:24:53,151 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:24:53,152 EPOCH 10 done: loss 9.7637 - lr 0.0500000\n",
      "2021-06-20 21:24:53,520 DEV : loss 6.385528564453125 - score 0.0\n",
      "2021-06-20 21:24:53,522 BAD EPOCHS (no improvement): 1\n",
      "2021-06-20 21:24:53,523 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:24:55,348 epoch 11 - iter 1/6 - loss 9.01979065 - samples/sec: 4.39 - lr: 0.050000\n",
      "2021-06-20 21:24:57,238 epoch 11 - iter 2/6 - loss 7.53023529 - samples/sec: 4.23 - lr: 0.050000\n",
      "2021-06-20 21:24:59,211 epoch 11 - iter 3/6 - loss 9.34491475 - samples/sec: 4.06 - lr: 0.050000\n",
      "2021-06-20 21:25:01,353 epoch 11 - iter 4/6 - loss 9.43075943 - samples/sec: 3.74 - lr: 0.050000\n",
      "2021-06-20 21:25:03,079 epoch 11 - iter 5/6 - loss 10.05975494 - samples/sec: 4.64 - lr: 0.050000\n",
      "2021-06-20 21:25:03,583 epoch 11 - iter 6/6 - loss 12.59309006 - samples/sec: 15.92 - lr: 0.050000\n",
      "2021-06-20 21:25:03,584 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:25:03,585 EPOCH 11 done: loss 12.5931 - lr 0.0500000\n",
      "2021-06-20 21:25:04,086 DEV : loss 4.66912841796875 - score 0.0\n",
      "2021-06-20 21:25:04,089 BAD EPOCHS (no improvement): 2\n",
      "2021-06-20 21:25:04,091 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:25:05,936 epoch 12 - iter 1/6 - loss 12.72525787 - samples/sec: 4.34 - lr: 0.050000\n",
      "2021-06-20 21:25:08,482 epoch 12 - iter 2/6 - loss 9.41929245 - samples/sec: 3.14 - lr: 0.050000\n",
      "2021-06-20 21:25:10,281 epoch 12 - iter 3/6 - loss 8.76757050 - samples/sec: 4.45 - lr: 0.050000\n",
      "2021-06-20 21:25:12,254 epoch 12 - iter 4/6 - loss 8.24442863 - samples/sec: 4.06 - lr: 0.050000\n",
      "2021-06-20 21:25:15,048 epoch 12 - iter 5/6 - loss 9.15937347 - samples/sec: 2.86 - lr: 0.050000\n",
      "2021-06-20 21:25:15,446 epoch 12 - iter 6/6 - loss 7.81471634 - samples/sec: 20.13 - lr: 0.050000\n",
      "2021-06-20 21:25:15,447 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:25:15,448 EPOCH 12 done: loss 7.8147 - lr 0.0500000\n",
      "2021-06-20 21:25:15,894 DEV : loss 7.9442138671875 - score 0.0\n",
      "2021-06-20 21:25:15,896 BAD EPOCHS (no improvement): 3\n",
      "2021-06-20 21:25:15,897 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:25:17,639 epoch 13 - iter 1/6 - loss 7.57351685 - samples/sec: 4.60 - lr: 0.050000\n",
      "2021-06-20 21:25:19,136 epoch 13 - iter 2/6 - loss 8.67258835 - samples/sec: 5.35 - lr: 0.050000\n",
      "2021-06-20 21:25:21,140 epoch 13 - iter 3/6 - loss 9.31925201 - samples/sec: 3.99 - lr: 0.050000\n",
      "2021-06-20 21:25:23,218 epoch 13 - iter 4/6 - loss 10.01461983 - samples/sec: 3.85 - lr: 0.050000\n",
      "2021-06-20 21:25:25,321 epoch 13 - iter 5/6 - loss 9.66357574 - samples/sec: 3.81 - lr: 0.050000\n",
      "2021-06-20 21:25:25,696 epoch 13 - iter 6/6 - loss 9.24522018 - samples/sec: 21.39 - lr: 0.050000\n",
      "2021-06-20 21:25:25,697 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:25:25,698 EPOCH 13 done: loss 9.2452 - lr 0.0500000\n",
      "2021-06-20 21:25:26,057 DEV : loss 4.477203369140625 - score 0.0\n",
      "Epoch    13: reducing learning rate of group 0 to 2.5000e-02.\n",
      "2021-06-20 21:25:26,059 BAD EPOCHS (no improvement): 4\n",
      "2021-06-20 21:25:26,062 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:25:27,991 epoch 14 - iter 1/6 - loss 10.48356628 - samples/sec: 4.15 - lr: 0.025000\n",
      "2021-06-20 21:25:29,567 epoch 14 - iter 2/6 - loss 8.19225311 - samples/sec: 5.08 - lr: 0.025000\n",
      "2021-06-20 21:25:31,414 epoch 14 - iter 3/6 - loss 7.77636719 - samples/sec: 4.33 - lr: 0.025000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 21:25:33,400 epoch 14 - iter 4/6 - loss 7.19572067 - samples/sec: 4.03 - lr: 0.025000\n",
      "2021-06-20 21:25:35,468 epoch 14 - iter 5/6 - loss 7.56903687 - samples/sec: 3.87 - lr: 0.025000\n",
      "2021-06-20 21:25:35,815 epoch 14 - iter 6/6 - loss 9.77489726 - samples/sec: 23.12 - lr: 0.025000\n",
      "2021-06-20 21:25:35,816 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:25:35,817 EPOCH 14 done: loss 9.7749 - lr 0.0250000\n",
      "2021-06-20 21:25:36,174 DEV : loss 3.838226318359375 - score 0.0\n",
      "2021-06-20 21:25:36,176 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-06-20 21:25:38,716 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:25:40,943 epoch 15 - iter 1/6 - loss 6.75820923 - samples/sec: 3.59 - lr: 0.025000\n",
      "2021-06-20 21:25:42,586 epoch 15 - iter 2/6 - loss 6.39347839 - samples/sec: 4.87 - lr: 0.025000\n",
      "2021-06-20 21:25:44,520 epoch 15 - iter 3/6 - loss 7.06682332 - samples/sec: 4.14 - lr: 0.025000\n",
      "2021-06-20 21:25:46,117 epoch 15 - iter 4/6 - loss 7.60510826 - samples/sec: 5.01 - lr: 0.025000\n",
      "2021-06-20 21:25:47,635 epoch 15 - iter 5/6 - loss 7.25601349 - samples/sec: 5.27 - lr: 0.025000\n",
      "2021-06-20 21:25:48,005 epoch 15 - iter 6/6 - loss 6.95602036 - samples/sec: 21.71 - lr: 0.025000\n",
      "2021-06-20 21:25:48,006 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:25:48,006 EPOCH 15 done: loss 6.9560 - lr 0.0250000\n",
      "2021-06-20 21:25:48,363 DEV : loss 3.480255126953125 - score 0.0\n",
      "2021-06-20 21:25:48,364 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-06-20 21:25:50,757 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:25:52,927 epoch 16 - iter 1/6 - loss 8.69311523 - samples/sec: 3.69 - lr: 0.025000\n",
      "2021-06-20 21:25:55,052 epoch 16 - iter 2/6 - loss 8.60190582 - samples/sec: 3.77 - lr: 0.025000\n",
      "2021-06-20 21:25:56,738 epoch 16 - iter 3/6 - loss 8.16721598 - samples/sec: 4.75 - lr: 0.025000\n",
      "2021-06-20 21:25:58,154 epoch 16 - iter 4/6 - loss 7.03853798 - samples/sec: 5.65 - lr: 0.025000\n",
      "2021-06-20 21:25:59,914 epoch 16 - iter 5/6 - loss 7.54121552 - samples/sec: 4.55 - lr: 0.025000\n",
      "2021-06-20 21:26:00,270 epoch 16 - iter 6/6 - loss 7.17047501 - samples/sec: 22.56 - lr: 0.025000\n",
      "2021-06-20 21:26:00,271 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:26:00,271 EPOCH 16 done: loss 7.1705 - lr 0.0250000\n",
      "2021-06-20 21:26:00,626 DEV : loss 3.47119140625 - score 0.0\n",
      "2021-06-20 21:26:00,627 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-06-20 21:26:02,996 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:26:04,883 epoch 17 - iter 1/6 - loss 6.17561340 - samples/sec: 4.24 - lr: 0.025000\n",
      "2021-06-20 21:26:06,493 epoch 17 - iter 2/6 - loss 6.52970123 - samples/sec: 4.97 - lr: 0.025000\n",
      "2021-06-20 21:26:08,232 epoch 17 - iter 3/6 - loss 6.89270528 - samples/sec: 4.60 - lr: 0.025000\n",
      "2021-06-20 21:26:09,905 epoch 17 - iter 4/6 - loss 6.34642601 - samples/sec: 4.78 - lr: 0.025000\n",
      "2021-06-20 21:26:12,065 epoch 17 - iter 5/6 - loss 6.84262848 - samples/sec: 3.71 - lr: 0.025000\n",
      "2021-06-20 21:26:12,575 epoch 17 - iter 6/6 - loss 6.88912074 - samples/sec: 15.70 - lr: 0.025000\n",
      "2021-06-20 21:26:12,576 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:26:12,577 EPOCH 17 done: loss 6.8891 - lr 0.0250000\n",
      "2021-06-20 21:26:12,941 DEV : loss 4.772735595703125 - score 0.0\n",
      "2021-06-20 21:26:12,943 BAD EPOCHS (no improvement): 1\n",
      "2021-06-20 21:26:12,944 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:26:15,070 epoch 18 - iter 1/6 - loss 7.07453918 - samples/sec: 3.76 - lr: 0.025000\n",
      "2021-06-20 21:26:16,503 epoch 18 - iter 2/6 - loss 7.63768768 - samples/sec: 5.59 - lr: 0.025000\n",
      "2021-06-20 21:26:18,702 epoch 18 - iter 3/6 - loss 8.16446431 - samples/sec: 3.64 - lr: 0.025000\n",
      "2021-06-20 21:26:20,346 epoch 18 - iter 4/6 - loss 8.09637451 - samples/sec: 4.87 - lr: 0.025000\n",
      "2021-06-20 21:26:21,818 epoch 18 - iter 5/6 - loss 7.74434814 - samples/sec: 5.44 - lr: 0.025000\n",
      "2021-06-20 21:26:22,184 epoch 18 - iter 6/6 - loss 6.74295044 - samples/sec: 21.94 - lr: 0.025000\n",
      "2021-06-20 21:26:22,185 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:26:22,185 EPOCH 18 done: loss 6.7430 - lr 0.0250000\n",
      "2021-06-20 21:26:22,543 DEV : loss 3.3909912109375 - score 0.0\n",
      "2021-06-20 21:26:22,545 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-06-20 21:26:24,937 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:26:26,615 epoch 19 - iter 1/6 - loss 6.12611389 - samples/sec: 4.77 - lr: 0.025000\n",
      "2021-06-20 21:26:28,279 epoch 19 - iter 2/6 - loss 7.15130615 - samples/sec: 4.81 - lr: 0.025000\n",
      "2021-06-20 21:26:30,650 epoch 19 - iter 3/6 - loss 7.07329051 - samples/sec: 3.37 - lr: 0.025000\n",
      "2021-06-20 21:26:32,201 epoch 19 - iter 4/6 - loss 6.35500908 - samples/sec: 5.16 - lr: 0.025000\n",
      "2021-06-20 21:26:33,745 epoch 19 - iter 5/6 - loss 6.58858185 - samples/sec: 5.19 - lr: 0.025000\n",
      "2021-06-20 21:26:34,190 epoch 19 - iter 6/6 - loss 7.61967595 - samples/sec: 18.02 - lr: 0.025000\n",
      "2021-06-20 21:26:34,191 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:26:34,192 EPOCH 19 done: loss 7.6197 - lr 0.0250000\n",
      "2021-06-20 21:26:34,553 DEV : loss 3.78485107421875 - score 0.0\n",
      "2021-06-20 21:26:34,555 BAD EPOCHS (no improvement): 1\n",
      "2021-06-20 21:26:34,556 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:26:36,701 epoch 20 - iter 1/6 - loss 7.96398926 - samples/sec: 3.73 - lr: 0.025000\n",
      "2021-06-20 21:26:38,297 epoch 20 - iter 2/6 - loss 7.59691620 - samples/sec: 5.02 - lr: 0.025000\n",
      "2021-06-20 21:26:40,123 epoch 20 - iter 3/6 - loss 8.11485036 - samples/sec: 4.38 - lr: 0.025000\n",
      "2021-06-20 21:26:42,141 epoch 20 - iter 4/6 - loss 7.42490196 - samples/sec: 3.97 - lr: 0.025000\n",
      "2021-06-20 21:26:43,849 epoch 20 - iter 5/6 - loss 6.83703156 - samples/sec: 4.68 - lr: 0.025000\n",
      "2021-06-20 21:26:44,173 epoch 20 - iter 6/6 - loss 6.31564967 - samples/sec: 24.81 - lr: 0.025000\n",
      "2021-06-20 21:26:44,174 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:26:44,174 EPOCH 20 done: loss 6.3156 - lr 0.0250000\n",
      "2021-06-20 21:26:44,540 DEV : loss 5.270904541015625 - score 0.0\n",
      "2021-06-20 21:26:44,542 BAD EPOCHS (no improvement): 2\n",
      "2021-06-20 21:26:44,543 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:26:46,335 epoch 21 - iter 1/6 - loss 4.90844727 - samples/sec: 4.47 - lr: 0.025000\n",
      "2021-06-20 21:26:47,947 epoch 21 - iter 2/6 - loss 5.59324646 - samples/sec: 4.96 - lr: 0.025000\n",
      "2021-06-20 21:26:50,045 epoch 21 - iter 3/6 - loss 6.04827881 - samples/sec: 3.82 - lr: 0.025000\n",
      "2021-06-20 21:26:51,527 epoch 21 - iter 4/6 - loss 6.00622177 - samples/sec: 5.40 - lr: 0.025000\n",
      "2021-06-20 21:26:53,328 epoch 21 - iter 5/6 - loss 5.81248322 - samples/sec: 4.45 - lr: 0.025000\n",
      "2021-06-20 21:26:53,861 epoch 21 - iter 6/6 - loss 5.73826726 - samples/sec: 15.03 - lr: 0.025000\n",
      "2021-06-20 21:26:53,862 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:26:53,862 EPOCH 21 done: loss 5.7383 - lr 0.0250000\n",
      "2021-06-20 21:26:54,224 DEV : loss 3.56396484375 - score 0.0\n",
      "2021-06-20 21:26:54,226 BAD EPOCHS (no improvement): 3\n",
      "2021-06-20 21:26:54,227 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:26:55,722 epoch 22 - iter 1/6 - loss 8.28283691 - samples/sec: 5.36 - lr: 0.025000\n",
      "2021-06-20 21:26:57,675 epoch 22 - iter 2/6 - loss 7.66311646 - samples/sec: 4.10 - lr: 0.025000\n",
      "2021-06-20 21:26:59,274 epoch 22 - iter 3/6 - loss 6.31515503 - samples/sec: 5.01 - lr: 0.025000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 21:27:01,465 epoch 22 - iter 4/6 - loss 6.63114166 - samples/sec: 3.65 - lr: 0.025000\n",
      "2021-06-20 21:27:03,317 epoch 22 - iter 5/6 - loss 6.86806335 - samples/sec: 4.32 - lr: 0.025000\n",
      "2021-06-20 21:27:03,677 epoch 22 - iter 6/6 - loss 6.08947500 - samples/sec: 22.23 - lr: 0.025000\n",
      "2021-06-20 21:27:03,678 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:27:03,679 EPOCH 22 done: loss 6.0895 - lr 0.0250000\n",
      "2021-06-20 21:27:04,040 DEV : loss 4.98663330078125 - score 0.0\n",
      "Epoch    22: reducing learning rate of group 0 to 1.2500e-02.\n",
      "2021-06-20 21:27:04,042 BAD EPOCHS (no improvement): 4\n",
      "2021-06-20 21:27:04,043 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:27:06,041 epoch 23 - iter 1/6 - loss 7.31309509 - samples/sec: 4.01 - lr: 0.012500\n",
      "2021-06-20 21:27:08,320 epoch 23 - iter 2/6 - loss 7.21899796 - samples/sec: 3.51 - lr: 0.012500\n",
      "2021-06-20 21:27:09,798 epoch 23 - iter 3/6 - loss 7.17875926 - samples/sec: 5.42 - lr: 0.012500\n",
      "2021-06-20 21:27:11,652 epoch 23 - iter 4/6 - loss 6.55895424 - samples/sec: 4.32 - lr: 0.012500\n",
      "2021-06-20 21:27:13,288 epoch 23 - iter 5/6 - loss 6.01216278 - samples/sec: 4.89 - lr: 0.012500\n",
      "2021-06-20 21:27:13,746 epoch 23 - iter 6/6 - loss 5.60124079 - samples/sec: 17.49 - lr: 0.012500\n",
      "2021-06-20 21:27:13,747 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:27:13,748 EPOCH 23 done: loss 5.6012 - lr 0.0125000\n",
      "2021-06-20 21:27:14,109 DEV : loss 4.121734619140625 - score 0.0\n",
      "2021-06-20 21:27:14,111 BAD EPOCHS (no improvement): 1\n",
      "2021-06-20 21:27:14,112 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:27:16,029 epoch 24 - iter 1/6 - loss 6.23097992 - samples/sec: 4.18 - lr: 0.012500\n",
      "2021-06-20 21:27:17,720 epoch 24 - iter 2/6 - loss 5.56715012 - samples/sec: 4.73 - lr: 0.012500\n",
      "2021-06-20 21:27:19,672 epoch 24 - iter 3/6 - loss 5.43163300 - samples/sec: 4.10 - lr: 0.012500\n",
      "2021-06-20 21:27:21,289 epoch 24 - iter 4/6 - loss 6.47820473 - samples/sec: 4.95 - lr: 0.012500\n",
      "2021-06-20 21:27:23,457 epoch 24 - iter 5/6 - loss 6.21012726 - samples/sec: 3.69 - lr: 0.012500\n",
      "2021-06-20 21:27:23,847 epoch 24 - iter 6/6 - loss 6.88447698 - samples/sec: 20.60 - lr: 0.012500\n",
      "2021-06-20 21:27:23,847 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:27:23,848 EPOCH 24 done: loss 6.8845 - lr 0.0125000\n",
      "2021-06-20 21:27:24,219 DEV : loss 3.570343017578125 - score 0.0\n",
      "2021-06-20 21:27:24,220 BAD EPOCHS (no improvement): 2\n",
      "2021-06-20 21:27:24,222 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:27:26,110 epoch 25 - iter 1/6 - loss 5.94630432 - samples/sec: 4.24 - lr: 0.012500\n",
      "2021-06-20 21:27:27,889 epoch 25 - iter 2/6 - loss 5.86750031 - samples/sec: 4.50 - lr: 0.012500\n",
      "2021-06-20 21:27:29,504 epoch 25 - iter 3/6 - loss 5.32797750 - samples/sec: 4.96 - lr: 0.012500\n",
      "2021-06-20 21:27:31,970 epoch 25 - iter 4/6 - loss 5.94923401 - samples/sec: 3.24 - lr: 0.012500\n",
      "2021-06-20 21:27:33,625 epoch 25 - iter 5/6 - loss 5.64235229 - samples/sec: 4.84 - lr: 0.012500\n",
      "2021-06-20 21:27:34,064 epoch 25 - iter 6/6 - loss 5.41240946 - samples/sec: 18.28 - lr: 0.012500\n",
      "2021-06-20 21:27:34,064 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:27:34,065 EPOCH 25 done: loss 5.4124 - lr 0.0125000\n",
      "2021-06-20 21:27:34,449 DEV : loss 3.98284912109375 - score 0.0\n",
      "2021-06-20 21:27:34,451 BAD EPOCHS (no improvement): 3\n",
      "2021-06-20 21:27:34,452 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:27:36,007 epoch 26 - iter 1/6 - loss 6.89244080 - samples/sec: 5.15 - lr: 0.012500\n",
      "2021-06-20 21:27:38,309 epoch 26 - iter 2/6 - loss 7.94023895 - samples/sec: 3.48 - lr: 0.012500\n",
      "2021-06-20 21:27:39,843 epoch 26 - iter 3/6 - loss 7.66388957 - samples/sec: 5.22 - lr: 0.012500\n",
      "2021-06-20 21:27:41,742 epoch 26 - iter 4/6 - loss 7.93599319 - samples/sec: 4.21 - lr: 0.012500\n",
      "2021-06-20 21:27:43,619 epoch 26 - iter 5/6 - loss 7.71828003 - samples/sec: 4.26 - lr: 0.012500\n",
      "2021-06-20 21:27:44,079 epoch 26 - iter 6/6 - loss 6.83147685 - samples/sec: 17.41 - lr: 0.012500\n",
      "2021-06-20 21:27:44,080 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:27:44,081 EPOCH 26 done: loss 6.8315 - lr 0.0125000\n",
      "2021-06-20 21:27:44,455 DEV : loss 3.936004638671875 - score 0.0\n",
      "Epoch    26: reducing learning rate of group 0 to 6.2500e-03.\n",
      "2021-06-20 21:27:44,457 BAD EPOCHS (no improvement): 4\n",
      "2021-06-20 21:27:44,458 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:27:46,659 epoch 27 - iter 1/6 - loss 7.85945129 - samples/sec: 3.64 - lr: 0.006250\n",
      "2021-06-20 21:27:48,338 epoch 27 - iter 2/6 - loss 6.86109161 - samples/sec: 4.77 - lr: 0.006250\n",
      "2021-06-20 21:27:50,653 epoch 27 - iter 3/6 - loss 6.24558512 - samples/sec: 3.46 - lr: 0.006250\n",
      "2021-06-20 21:27:52,213 epoch 27 - iter 4/6 - loss 6.34280396 - samples/sec: 5.13 - lr: 0.006250\n",
      "2021-06-20 21:27:53,981 epoch 27 - iter 5/6 - loss 6.42732239 - samples/sec: 4.53 - lr: 0.006250\n",
      "2021-06-20 21:27:54,307 epoch 27 - iter 6/6 - loss 6.58142344 - samples/sec: 24.61 - lr: 0.006250\n",
      "2021-06-20 21:27:54,308 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:27:54,308 EPOCH 27 done: loss 6.5814 - lr 0.0062500\n",
      "2021-06-20 21:27:54,667 DEV : loss 3.363311767578125 - score 0.0\n",
      "2021-06-20 21:27:54,670 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-06-20 21:27:57,135 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:27:59,523 epoch 28 - iter 1/6 - loss 7.84556580 - samples/sec: 3.35 - lr: 0.006250\n",
      "2021-06-20 21:28:01,382 epoch 28 - iter 2/6 - loss 6.28073883 - samples/sec: 4.31 - lr: 0.006250\n",
      "2021-06-20 21:28:03,361 epoch 28 - iter 3/6 - loss 6.01614380 - samples/sec: 4.05 - lr: 0.006250\n",
      "2021-06-20 21:28:05,460 epoch 28 - iter 4/6 - loss 5.90348816 - samples/sec: 3.81 - lr: 0.006250\n",
      "2021-06-20 21:28:07,158 epoch 28 - iter 5/6 - loss 6.13067932 - samples/sec: 4.71 - lr: 0.006250\n",
      "2021-06-20 21:28:07,536 epoch 28 - iter 6/6 - loss 5.34024302 - samples/sec: 21.18 - lr: 0.006250\n",
      "2021-06-20 21:28:07,537 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:28:07,538 EPOCH 28 done: loss 5.3402 - lr 0.0062500\n",
      "2021-06-20 21:28:07,900 DEV : loss 3.605255126953125 - score 0.0\n",
      "2021-06-20 21:28:07,902 BAD EPOCHS (no improvement): 1\n",
      "2021-06-20 21:28:07,903 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:28:09,742 epoch 29 - iter 1/6 - loss 5.74700928 - samples/sec: 4.36 - lr: 0.006250\n",
      "2021-06-20 21:28:11,422 epoch 29 - iter 2/6 - loss 5.81243134 - samples/sec: 4.76 - lr: 0.006250\n",
      "2021-06-20 21:28:13,548 epoch 29 - iter 3/6 - loss 7.35962931 - samples/sec: 3.76 - lr: 0.006250\n",
      "2021-06-20 21:28:15,238 epoch 29 - iter 4/6 - loss 6.67764664 - samples/sec: 4.73 - lr: 0.006250\n",
      "2021-06-20 21:28:17,193 epoch 29 - iter 5/6 - loss 6.71430054 - samples/sec: 4.10 - lr: 0.006250\n",
      "2021-06-20 21:28:17,609 epoch 29 - iter 6/6 - loss 5.91845194 - samples/sec: 19.26 - lr: 0.006250\n",
      "2021-06-20 21:28:17,610 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:28:17,611 EPOCH 29 done: loss 5.9185 - lr 0.0062500\n",
      "2021-06-20 21:28:17,980 DEV : loss 3.5277099609375 - score 0.0\n",
      "2021-06-20 21:28:17,981 BAD EPOCHS (no improvement): 2\n",
      "2021-06-20 21:28:17,982 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:28:19,947 epoch 30 - iter 1/6 - loss 7.29187012 - samples/sec: 4.07 - lr: 0.006250\n",
      "2021-06-20 21:28:22,122 epoch 30 - iter 2/6 - loss 6.96421051 - samples/sec: 3.68 - lr: 0.006250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 21:28:23,723 epoch 30 - iter 3/6 - loss 6.73493958 - samples/sec: 5.00 - lr: 0.006250\n",
      "2021-06-20 21:28:25,639 epoch 30 - iter 4/6 - loss 6.71533966 - samples/sec: 4.18 - lr: 0.006250\n",
      "2021-06-20 21:28:27,317 epoch 30 - iter 5/6 - loss 6.07390442 - samples/sec: 4.77 - lr: 0.006250\n",
      "2021-06-20 21:28:27,581 epoch 30 - iter 6/6 - loss 6.46247609 - samples/sec: 30.48 - lr: 0.006250\n",
      "2021-06-20 21:28:27,582 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:28:27,582 EPOCH 30 done: loss 6.4625 - lr 0.0062500\n",
      "2021-06-20 21:28:27,942 DEV : loss 3.510650634765625 - score 0.0\n",
      "2021-06-20 21:28:27,944 BAD EPOCHS (no improvement): 3\n",
      "2021-06-20 21:28:27,945 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:28:29,603 epoch 31 - iter 1/6 - loss 4.28936768 - samples/sec: 4.83 - lr: 0.006250\n",
      "2021-06-20 21:28:31,728 epoch 31 - iter 2/6 - loss 5.86947632 - samples/sec: 3.77 - lr: 0.006250\n",
      "2021-06-20 21:28:33,490 epoch 31 - iter 3/6 - loss 5.01206207 - samples/sec: 4.54 - lr: 0.006250\n",
      "2021-06-20 21:28:35,013 epoch 31 - iter 4/6 - loss 5.41868019 - samples/sec: 5.26 - lr: 0.006250\n",
      "2021-06-20 21:28:37,143 epoch 31 - iter 5/6 - loss 5.68856354 - samples/sec: 3.76 - lr: 0.006250\n",
      "2021-06-20 21:28:37,658 epoch 31 - iter 6/6 - loss 5.24999110 - samples/sec: 15.58 - lr: 0.006250\n",
      "2021-06-20 21:28:37,659 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:28:37,660 EPOCH 31 done: loss 5.2500 - lr 0.0062500\n",
      "2021-06-20 21:28:38,024 DEV : loss 3.35302734375 - score 0.0\n",
      "2021-06-20 21:28:38,026 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-06-20 21:28:40,518 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:28:42,683 epoch 32 - iter 1/6 - loss 8.36770630 - samples/sec: 3.70 - lr: 0.006250\n",
      "2021-06-20 21:28:44,679 epoch 32 - iter 2/6 - loss 6.10986328 - samples/sec: 4.01 - lr: 0.006250\n",
      "2021-06-20 21:28:46,810 epoch 32 - iter 3/6 - loss 6.47101847 - samples/sec: 3.75 - lr: 0.006250\n",
      "2021-06-20 21:28:48,487 epoch 32 - iter 4/6 - loss 6.12883186 - samples/sec: 4.77 - lr: 0.006250\n",
      "2021-06-20 21:28:50,556 epoch 32 - iter 5/6 - loss 6.24958344 - samples/sec: 3.87 - lr: 0.006250\n",
      "2021-06-20 21:28:50,951 epoch 32 - iter 6/6 - loss 5.70515823 - samples/sec: 20.33 - lr: 0.006250\n",
      "2021-06-20 21:28:50,951 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:28:50,952 EPOCH 32 done: loss 5.7052 - lr 0.0062500\n",
      "2021-06-20 21:28:51,318 DEV : loss 3.699310302734375 - score 0.0\n",
      "2021-06-20 21:28:51,320 BAD EPOCHS (no improvement): 1\n",
      "2021-06-20 21:28:51,320 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:28:52,916 epoch 33 - iter 1/6 - loss 8.07748413 - samples/sec: 5.02 - lr: 0.006250\n",
      "2021-06-20 21:28:55,108 epoch 33 - iter 2/6 - loss 6.62026215 - samples/sec: 3.65 - lr: 0.006250\n",
      "2021-06-20 21:28:56,626 epoch 33 - iter 3/6 - loss 6.48737081 - samples/sec: 5.27 - lr: 0.006250\n",
      "2021-06-20 21:28:58,725 epoch 33 - iter 4/6 - loss 6.21553802 - samples/sec: 3.81 - lr: 0.006250\n",
      "2021-06-20 21:29:00,458 epoch 33 - iter 5/6 - loss 6.46985016 - samples/sec: 4.62 - lr: 0.006250\n",
      "2021-06-20 21:29:00,814 epoch 33 - iter 6/6 - loss 5.85435104 - samples/sec: 22.49 - lr: 0.006250\n",
      "2021-06-20 21:29:00,815 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:29:00,816 EPOCH 33 done: loss 5.8544 - lr 0.0062500\n",
      "2021-06-20 21:29:01,176 DEV : loss 3.311676025390625 - score 0.0\n",
      "2021-06-20 21:29:01,178 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-06-20 21:29:03,792 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:29:05,480 epoch 34 - iter 1/6 - loss 5.61694336 - samples/sec: 4.74 - lr: 0.006250\n",
      "2021-06-20 21:29:07,478 epoch 34 - iter 2/6 - loss 4.73923492 - samples/sec: 4.01 - lr: 0.006250\n",
      "2021-06-20 21:29:10,147 epoch 34 - iter 3/6 - loss 5.74984233 - samples/sec: 3.00 - lr: 0.006250\n",
      "2021-06-20 21:29:12,573 epoch 34 - iter 4/6 - loss 5.86219215 - samples/sec: 3.30 - lr: 0.006250\n",
      "2021-06-20 21:29:14,224 epoch 34 - iter 5/6 - loss 5.30398102 - samples/sec: 4.85 - lr: 0.006250\n",
      "2021-06-20 21:29:14,715 epoch 34 - iter 6/6 - loss 6.40252813 - samples/sec: 16.33 - lr: 0.006250\n",
      "2021-06-20 21:29:14,716 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:29:14,717 EPOCH 34 done: loss 6.4025 - lr 0.0062500\n",
      "2021-06-20 21:29:15,088 DEV : loss 3.728240966796875 - score 0.0\n",
      "2021-06-20 21:29:15,090 BAD EPOCHS (no improvement): 1\n",
      "2021-06-20 21:29:15,091 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:29:17,499 epoch 35 - iter 1/6 - loss 4.92930603 - samples/sec: 3.32 - lr: 0.006250\n",
      "2021-06-20 21:29:20,027 epoch 35 - iter 2/6 - loss 6.57964325 - samples/sec: 3.17 - lr: 0.006250\n",
      "2021-06-20 21:29:21,987 epoch 35 - iter 3/6 - loss 6.09437561 - samples/sec: 4.09 - lr: 0.006250\n",
      "2021-06-20 21:29:24,061 epoch 35 - iter 4/6 - loss 5.53302956 - samples/sec: 3.86 - lr: 0.006250\n",
      "2021-06-20 21:29:25,740 epoch 35 - iter 5/6 - loss 6.56387177 - samples/sec: 4.77 - lr: 0.006250\n",
      "2021-06-20 21:29:26,114 epoch 35 - iter 6/6 - loss 6.92971166 - samples/sec: 21.42 - lr: 0.006250\n",
      "2021-06-20 21:29:26,115 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:29:26,116 EPOCH 35 done: loss 6.9297 - lr 0.0062500\n",
      "2021-06-20 21:29:26,478 DEV : loss 3.49212646484375 - score 0.0\n",
      "2021-06-20 21:29:26,480 BAD EPOCHS (no improvement): 2\n",
      "2021-06-20 21:29:26,481 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:29:28,413 epoch 36 - iter 1/6 - loss 3.71954346 - samples/sec: 4.14 - lr: 0.006250\n",
      "2021-06-20 21:29:30,103 epoch 36 - iter 2/6 - loss 5.69031525 - samples/sec: 4.73 - lr: 0.006250\n",
      "2021-06-20 21:29:31,614 epoch 36 - iter 3/6 - loss 5.15385437 - samples/sec: 5.30 - lr: 0.006250\n",
      "2021-06-20 21:29:33,802 epoch 36 - iter 4/6 - loss 6.86755753 - samples/sec: 3.66 - lr: 0.006250\n",
      "2021-06-20 21:29:35,524 epoch 36 - iter 5/6 - loss 6.32685242 - samples/sec: 4.65 - lr: 0.006250\n",
      "2021-06-20 21:29:35,793 epoch 36 - iter 6/6 - loss 6.49571482 - samples/sec: 29.87 - lr: 0.006250\n",
      "2021-06-20 21:29:35,794 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:29:35,794 EPOCH 36 done: loss 6.4957 - lr 0.0062500\n",
      "2021-06-20 21:29:36,162 DEV : loss 3.418243408203125 - score 0.0\n",
      "2021-06-20 21:29:36,164 BAD EPOCHS (no improvement): 3\n",
      "2021-06-20 21:29:36,166 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:29:38,055 epoch 37 - iter 1/6 - loss 5.27819824 - samples/sec: 4.24 - lr: 0.006250\n",
      "2021-06-20 21:29:40,132 epoch 37 - iter 2/6 - loss 5.47827911 - samples/sec: 3.85 - lr: 0.006250\n",
      "2021-06-20 21:29:41,734 epoch 37 - iter 3/6 - loss 5.62295024 - samples/sec: 5.00 - lr: 0.006250\n",
      "2021-06-20 21:29:43,926 epoch 37 - iter 4/6 - loss 5.66825104 - samples/sec: 3.65 - lr: 0.006250\n",
      "2021-06-20 21:29:45,448 epoch 37 - iter 5/6 - loss 5.50756531 - samples/sec: 5.26 - lr: 0.006250\n",
      "2021-06-20 21:29:45,857 epoch 37 - iter 6/6 - loss 5.92354075 - samples/sec: 19.59 - lr: 0.006250\n",
      "2021-06-20 21:29:45,858 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:29:45,859 EPOCH 37 done: loss 5.9235 - lr 0.0062500\n",
      "2021-06-20 21:29:46,227 DEV : loss 3.404388427734375 - score 0.0\n",
      "Epoch    37: reducing learning rate of group 0 to 3.1250e-03.\n",
      "2021-06-20 21:29:46,230 BAD EPOCHS (no improvement): 4\n",
      "2021-06-20 21:29:46,231 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:29:48,330 epoch 38 - iter 1/6 - loss 6.67782593 - samples/sec: 3.81 - lr: 0.003125\n",
      "2021-06-20 21:29:49,971 epoch 38 - iter 2/6 - loss 5.14545441 - samples/sec: 4.88 - lr: 0.003125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 21:29:51,970 epoch 38 - iter 3/6 - loss 5.23704020 - samples/sec: 4.00 - lr: 0.003125\n",
      "2021-06-20 21:29:53,561 epoch 38 - iter 4/6 - loss 5.18378067 - samples/sec: 5.03 - lr: 0.003125\n",
      "2021-06-20 21:29:55,568 epoch 38 - iter 5/6 - loss 5.46337585 - samples/sec: 3.99 - lr: 0.003125\n",
      "2021-06-20 21:29:55,838 epoch 38 - iter 6/6 - loss 5.80941518 - samples/sec: 29.73 - lr: 0.003125\n",
      "2021-06-20 21:29:55,839 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:29:55,840 EPOCH 38 done: loss 5.8094 - lr 0.0031250\n",
      "2021-06-20 21:29:56,196 DEV : loss 3.452545166015625 - score 0.0\n",
      "2021-06-20 21:29:56,198 BAD EPOCHS (no improvement): 1\n",
      "2021-06-20 21:29:56,198 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:29:58,243 epoch 39 - iter 1/6 - loss 4.82949829 - samples/sec: 3.92 - lr: 0.003125\n",
      "2021-06-20 21:29:59,847 epoch 39 - iter 2/6 - loss 4.91387939 - samples/sec: 4.99 - lr: 0.003125\n",
      "2021-06-20 21:30:02,114 epoch 39 - iter 3/6 - loss 4.69903564 - samples/sec: 3.53 - lr: 0.003125\n",
      "2021-06-20 21:30:04,582 epoch 39 - iter 4/6 - loss 5.12702751 - samples/sec: 3.24 - lr: 0.003125\n",
      "2021-06-20 21:30:06,024 epoch 39 - iter 5/6 - loss 5.61340485 - samples/sec: 5.55 - lr: 0.003125\n",
      "2021-06-20 21:30:06,476 epoch 39 - iter 6/6 - loss 4.91912969 - samples/sec: 17.75 - lr: 0.003125\n",
      "2021-06-20 21:30:06,476 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:30:06,477 EPOCH 39 done: loss 4.9191 - lr 0.0031250\n",
      "2021-06-20 21:30:06,932 DEV : loss 3.37066650390625 - score 0.0\n",
      "2021-06-20 21:30:06,935 BAD EPOCHS (no improvement): 2\n",
      "2021-06-20 21:30:06,936 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:30:09,106 epoch 40 - iter 1/6 - loss 5.15516663 - samples/sec: 3.69 - lr: 0.003125\n",
      "2021-06-20 21:30:11,045 epoch 40 - iter 2/6 - loss 4.67833328 - samples/sec: 4.13 - lr: 0.003125\n",
      "2021-06-20 21:30:13,240 epoch 40 - iter 3/6 - loss 5.51938629 - samples/sec: 3.65 - lr: 0.003125\n",
      "2021-06-20 21:30:14,722 epoch 40 - iter 4/6 - loss 5.18068504 - samples/sec: 5.40 - lr: 0.003125\n",
      "2021-06-20 21:30:16,539 epoch 40 - iter 5/6 - loss 5.59909210 - samples/sec: 4.40 - lr: 0.003125\n",
      "2021-06-20 21:30:16,948 epoch 40 - iter 6/6 - loss 4.79048284 - samples/sec: 19.61 - lr: 0.003125\n",
      "2021-06-20 21:30:16,948 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:30:16,949 EPOCH 40 done: loss 4.7905 - lr 0.0031250\n",
      "2021-06-20 21:30:17,308 DEV : loss 3.445465087890625 - score 0.0\n",
      "2021-06-20 21:30:17,310 BAD EPOCHS (no improvement): 3\n",
      "2021-06-20 21:30:17,311 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:30:18,964 epoch 41 - iter 1/6 - loss 9.70440674 - samples/sec: 4.85 - lr: 0.003125\n",
      "2021-06-20 21:30:20,403 epoch 41 - iter 2/6 - loss 6.78022766 - samples/sec: 5.56 - lr: 0.003125\n",
      "2021-06-20 21:30:22,519 epoch 41 - iter 3/6 - loss 6.51973979 - samples/sec: 3.78 - lr: 0.003125\n",
      "2021-06-20 21:30:24,072 epoch 41 - iter 4/6 - loss 6.72402191 - samples/sec: 5.15 - lr: 0.003125\n",
      "2021-06-20 21:30:25,816 epoch 41 - iter 5/6 - loss 6.77488403 - samples/sec: 4.59 - lr: 0.003125\n",
      "2021-06-20 21:30:26,372 epoch 41 - iter 6/6 - loss 8.49278259 - samples/sec: 14.41 - lr: 0.003125\n",
      "2021-06-20 21:30:26,373 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:30:26,374 EPOCH 41 done: loss 8.4928 - lr 0.0031250\n",
      "2021-06-20 21:30:26,738 DEV : loss 3.3944091796875 - score 0.0\n",
      "Epoch    41: reducing learning rate of group 0 to 1.5625e-03.\n",
      "2021-06-20 21:30:26,740 BAD EPOCHS (no improvement): 4\n",
      "2021-06-20 21:30:26,740 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:30:28,459 epoch 42 - iter 1/6 - loss 5.39196777 - samples/sec: 4.66 - lr: 0.001563\n",
      "2021-06-20 21:30:30,703 epoch 42 - iter 2/6 - loss 6.11270905 - samples/sec: 3.57 - lr: 0.001563\n",
      "2021-06-20 21:30:32,711 epoch 42 - iter 3/6 - loss 5.79801432 - samples/sec: 3.99 - lr: 0.001563\n",
      "2021-06-20 21:30:34,367 epoch 42 - iter 4/6 - loss 5.63703918 - samples/sec: 4.83 - lr: 0.001563\n",
      "2021-06-20 21:30:35,879 epoch 42 - iter 5/6 - loss 5.24243469 - samples/sec: 5.30 - lr: 0.001563\n",
      "2021-06-20 21:30:36,242 epoch 42 - iter 6/6 - loss 5.02069346 - samples/sec: 22.10 - lr: 0.001563\n",
      "2021-06-20 21:30:36,243 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:30:36,244 EPOCH 42 done: loss 5.0207 - lr 0.0015625\n",
      "2021-06-20 21:30:36,631 DEV : loss 3.4332275390625 - score 0.0\n",
      "2021-06-20 21:30:36,633 BAD EPOCHS (no improvement): 1\n",
      "2021-06-20 21:30:36,634 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:30:38,284 epoch 43 - iter 1/6 - loss 3.99279785 - samples/sec: 4.85 - lr: 0.001563\n",
      "2021-06-20 21:30:40,261 epoch 43 - iter 2/6 - loss 4.82482910 - samples/sec: 4.05 - lr: 0.001563\n",
      "2021-06-20 21:30:41,966 epoch 43 - iter 3/6 - loss 5.61983236 - samples/sec: 4.70 - lr: 0.001563\n",
      "2021-06-20 21:30:43,575 epoch 43 - iter 4/6 - loss 5.16563797 - samples/sec: 4.97 - lr: 0.001563\n",
      "2021-06-20 21:30:45,778 epoch 43 - iter 5/6 - loss 5.54704590 - samples/sec: 3.63 - lr: 0.001563\n",
      "2021-06-20 21:30:46,146 epoch 43 - iter 6/6 - loss 5.20005290 - samples/sec: 21.82 - lr: 0.001563\n",
      "2021-06-20 21:30:46,147 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:30:46,147 EPOCH 43 done: loss 5.2001 - lr 0.0015625\n",
      "2021-06-20 21:30:46,505 DEV : loss 3.384063720703125 - score 0.0\n",
      "2021-06-20 21:30:46,506 BAD EPOCHS (no improvement): 2\n",
      "2021-06-20 21:30:46,508 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:30:48,455 epoch 44 - iter 1/6 - loss 6.94987488 - samples/sec: 4.11 - lr: 0.001563\n",
      "2021-06-20 21:30:50,252 epoch 44 - iter 2/6 - loss 5.50699615 - samples/sec: 4.45 - lr: 0.001563\n",
      "2021-06-20 21:30:52,050 epoch 44 - iter 3/6 - loss 5.76552836 - samples/sec: 4.45 - lr: 0.001563\n",
      "2021-06-20 21:30:53,715 epoch 44 - iter 4/6 - loss 5.36851883 - samples/sec: 4.81 - lr: 0.001563\n",
      "2021-06-20 21:30:55,661 epoch 44 - iter 5/6 - loss 6.04262695 - samples/sec: 4.11 - lr: 0.001563\n",
      "2021-06-20 21:30:56,152 epoch 44 - iter 6/6 - loss 5.09806315 - samples/sec: 16.34 - lr: 0.001563\n",
      "2021-06-20 21:30:56,153 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:30:56,153 EPOCH 44 done: loss 5.0981 - lr 0.0015625\n",
      "2021-06-20 21:30:56,513 DEV : loss 3.333648681640625 - score 0.0\n",
      "2021-06-20 21:30:56,515 BAD EPOCHS (no improvement): 3\n",
      "2021-06-20 21:30:56,516 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:30:58,140 epoch 45 - iter 1/6 - loss 4.16352844 - samples/sec: 4.93 - lr: 0.001563\n",
      "2021-06-20 21:31:00,175 epoch 45 - iter 2/6 - loss 4.55953217 - samples/sec: 3.93 - lr: 0.001563\n",
      "2021-06-20 21:31:01,776 epoch 45 - iter 3/6 - loss 5.02922058 - samples/sec: 5.00 - lr: 0.001563\n",
      "2021-06-20 21:31:04,262 epoch 45 - iter 4/6 - loss 6.09416962 - samples/sec: 3.22 - lr: 0.001563\n",
      "2021-06-20 21:31:06,010 epoch 45 - iter 5/6 - loss 5.74365997 - samples/sec: 4.58 - lr: 0.001563\n",
      "2021-06-20 21:31:06,512 epoch 45 - iter 6/6 - loss 6.27303696 - samples/sec: 15.99 - lr: 0.001563\n",
      "2021-06-20 21:31:06,513 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:31:06,513 EPOCH 45 done: loss 6.2730 - lr 0.0015625\n",
      "2021-06-20 21:31:06,902 DEV : loss 3.368316650390625 - score 0.0\n",
      "Epoch    45: reducing learning rate of group 0 to 7.8125e-04.\n",
      "2021-06-20 21:31:06,904 BAD EPOCHS (no improvement): 4\n",
      "2021-06-20 21:31:06,905 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:31:09,257 epoch 46 - iter 1/6 - loss 3.79814148 - samples/sec: 3.40 - lr: 0.000781\n",
      "2021-06-20 21:31:11,128 epoch 46 - iter 2/6 - loss 4.48536682 - samples/sec: 4.28 - lr: 0.000781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 21:31:12,713 epoch 46 - iter 3/6 - loss 5.26794434 - samples/sec: 5.05 - lr: 0.000781\n",
      "2021-06-20 21:31:14,793 epoch 46 - iter 4/6 - loss 5.83195114 - samples/sec: 3.85 - lr: 0.000781\n",
      "2021-06-20 21:31:16,849 epoch 46 - iter 5/6 - loss 6.28192444 - samples/sec: 3.89 - lr: 0.000781\n",
      "2021-06-20 21:31:17,277 epoch 46 - iter 6/6 - loss 5.73929087 - samples/sec: 18.80 - lr: 0.000781\n",
      "2021-06-20 21:31:17,278 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:31:17,279 EPOCH 46 done: loss 5.7393 - lr 0.0007813\n",
      "2021-06-20 21:31:17,672 DEV : loss 3.328399658203125 - score 0.0\n",
      "2021-06-20 21:31:17,674 BAD EPOCHS (no improvement): 1\n",
      "2021-06-20 21:31:17,675 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:31:19,773 epoch 47 - iter 1/6 - loss 6.28884888 - samples/sec: 3.82 - lr: 0.000781\n",
      "2021-06-20 21:31:21,490 epoch 47 - iter 2/6 - loss 5.91800690 - samples/sec: 4.66 - lr: 0.000781\n",
      "2021-06-20 21:31:23,552 epoch 47 - iter 3/6 - loss 5.69459534 - samples/sec: 3.88 - lr: 0.000781\n",
      "2021-06-20 21:31:25,181 epoch 47 - iter 4/6 - loss 6.03749466 - samples/sec: 4.91 - lr: 0.000781\n",
      "2021-06-20 21:31:27,338 epoch 47 - iter 5/6 - loss 5.93946686 - samples/sec: 3.71 - lr: 0.000781\n",
      "2021-06-20 21:31:27,718 epoch 47 - iter 6/6 - loss 5.27743657 - samples/sec: 21.06 - lr: 0.000781\n",
      "2021-06-20 21:31:27,719 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:31:27,720 EPOCH 47 done: loss 5.2774 - lr 0.0007813\n",
      "2021-06-20 21:31:28,094 DEV : loss 3.373291015625 - score 0.0\n",
      "2021-06-20 21:31:28,096 BAD EPOCHS (no improvement): 2\n",
      "2021-06-20 21:31:28,097 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:31:29,855 epoch 48 - iter 1/6 - loss 5.56082153 - samples/sec: 4.56 - lr: 0.000781\n",
      "2021-06-20 21:31:31,472 epoch 48 - iter 2/6 - loss 4.15488815 - samples/sec: 4.95 - lr: 0.000781\n",
      "2021-06-20 21:31:33,962 epoch 48 - iter 3/6 - loss 4.81415049 - samples/sec: 3.21 - lr: 0.000781\n",
      "2021-06-20 21:31:35,704 epoch 48 - iter 4/6 - loss 5.15198326 - samples/sec: 4.59 - lr: 0.000781\n",
      "2021-06-20 21:31:38,103 epoch 48 - iter 5/6 - loss 5.04716339 - samples/sec: 3.34 - lr: 0.000781\n",
      "2021-06-20 21:31:38,503 epoch 48 - iter 6/6 - loss 5.07989120 - samples/sec: 20.04 - lr: 0.000781\n",
      "2021-06-20 21:31:38,504 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:31:38,505 EPOCH 48 done: loss 5.0799 - lr 0.0007813\n",
      "2021-06-20 21:31:38,882 DEV : loss 3.347991943359375 - score 0.0\n",
      "2021-06-20 21:31:38,884 BAD EPOCHS (no improvement): 3\n",
      "2021-06-20 21:31:38,885 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:31:40,414 epoch 49 - iter 1/6 - loss 6.39326477 - samples/sec: 5.23 - lr: 0.000781\n",
      "2021-06-20 21:31:42,577 epoch 49 - iter 2/6 - loss 6.43911743 - samples/sec: 3.70 - lr: 0.000781\n",
      "2021-06-20 21:31:44,349 epoch 49 - iter 3/6 - loss 5.82291158 - samples/sec: 4.52 - lr: 0.000781\n",
      "2021-06-20 21:31:45,850 epoch 49 - iter 4/6 - loss 6.74606323 - samples/sec: 5.33 - lr: 0.000781\n",
      "2021-06-20 21:31:48,012 epoch 49 - iter 5/6 - loss 6.41772461 - samples/sec: 3.70 - lr: 0.000781\n",
      "2021-06-20 21:31:48,382 epoch 49 - iter 6/6 - loss 5.83697510 - samples/sec: 21.68 - lr: 0.000781\n",
      "2021-06-20 21:31:48,382 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:31:48,383 EPOCH 49 done: loss 5.8370 - lr 0.0007813\n",
      "2021-06-20 21:31:48,750 DEV : loss 3.4051513671875 - score 0.0\n",
      "Epoch    49: reducing learning rate of group 0 to 3.9063e-04.\n",
      "2021-06-20 21:31:48,752 BAD EPOCHS (no improvement): 4\n",
      "2021-06-20 21:31:48,753 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:31:50,489 epoch 50 - iter 1/6 - loss 4.57156372 - samples/sec: 4.61 - lr: 0.000391\n",
      "2021-06-20 21:31:52,927 epoch 50 - iter 2/6 - loss 4.29137421 - samples/sec: 3.28 - lr: 0.000391\n",
      "2021-06-20 21:31:55,547 epoch 50 - iter 3/6 - loss 5.55988566 - samples/sec: 3.05 - lr: 0.000391\n",
      "2021-06-20 21:31:57,260 epoch 50 - iter 4/6 - loss 5.33219528 - samples/sec: 4.67 - lr: 0.000391\n",
      "2021-06-20 21:31:59,261 epoch 50 - iter 5/6 - loss 5.56487122 - samples/sec: 4.00 - lr: 0.000391\n",
      "2021-06-20 21:31:59,764 epoch 50 - iter 6/6 - loss 5.10262299 - samples/sec: 15.94 - lr: 0.000391\n",
      "2021-06-20 21:31:59,765 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:31:59,766 EPOCH 50 done: loss 5.1026 - lr 0.0003906\n",
      "2021-06-20 21:32:00,257 DEV : loss 3.394256591796875 - score 0.0\n",
      "2021-06-20 21:32:00,259 BAD EPOCHS (no improvement): 1\n",
      "2021-06-20 21:32:00,260 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:32:02,283 epoch 51 - iter 1/6 - loss 5.13778687 - samples/sec: 3.96 - lr: 0.000391\n",
      "2021-06-20 21:32:04,186 epoch 51 - iter 2/6 - loss 5.38872528 - samples/sec: 4.21 - lr: 0.000391\n",
      "2021-06-20 21:32:05,734 epoch 51 - iter 3/6 - loss 6.06467183 - samples/sec: 5.17 - lr: 0.000391\n",
      "2021-06-20 21:32:08,249 epoch 51 - iter 4/6 - loss 5.80126953 - samples/sec: 3.18 - lr: 0.000391\n",
      "2021-06-20 21:32:09,935 epoch 51 - iter 5/6 - loss 5.28029480 - samples/sec: 4.75 - lr: 0.000391\n",
      "2021-06-20 21:32:10,312 epoch 51 - iter 6/6 - loss 5.30844879 - samples/sec: 21.28 - lr: 0.000391\n",
      "2021-06-20 21:32:10,313 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:32:10,314 EPOCH 51 done: loss 5.3084 - lr 0.0003906\n",
      "2021-06-20 21:32:10,691 DEV : loss 3.365692138671875 - score 0.0\n",
      "2021-06-20 21:32:10,694 BAD EPOCHS (no improvement): 2\n",
      "2021-06-20 21:32:10,695 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:32:12,464 epoch 52 - iter 1/6 - loss 5.22602844 - samples/sec: 4.53 - lr: 0.000391\n",
      "2021-06-20 21:32:14,187 epoch 52 - iter 2/6 - loss 5.63951111 - samples/sec: 4.64 - lr: 0.000391\n",
      "2021-06-20 21:32:16,535 epoch 52 - iter 3/6 - loss 6.13720194 - samples/sec: 3.41 - lr: 0.000391\n",
      "2021-06-20 21:32:18,206 epoch 52 - iter 4/6 - loss 5.74331665 - samples/sec: 4.79 - lr: 0.000391\n",
      "2021-06-20 21:32:20,015 epoch 52 - iter 5/6 - loss 5.69050140 - samples/sec: 4.42 - lr: 0.000391\n",
      "2021-06-20 21:32:20,540 epoch 52 - iter 6/6 - loss 5.55865351 - samples/sec: 15.27 - lr: 0.000391\n",
      "2021-06-20 21:32:20,541 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:32:20,541 EPOCH 52 done: loss 5.5587 - lr 0.0003906\n",
      "2021-06-20 21:32:20,905 DEV : loss 3.3353271484375 - score 0.0\n",
      "2021-06-20 21:32:20,907 BAD EPOCHS (no improvement): 3\n",
      "2021-06-20 21:32:20,908 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:32:22,813 epoch 53 - iter 1/6 - loss 6.30960083 - samples/sec: 4.20 - lr: 0.000391\n",
      "2021-06-20 21:32:24,580 epoch 53 - iter 2/6 - loss 5.97077179 - samples/sec: 4.53 - lr: 0.000391\n",
      "2021-06-20 21:32:26,556 epoch 53 - iter 3/6 - loss 5.32509359 - samples/sec: 4.05 - lr: 0.000391\n",
      "2021-06-20 21:32:28,961 epoch 53 - iter 4/6 - loss 6.01760101 - samples/sec: 3.33 - lr: 0.000391\n",
      "2021-06-20 21:32:30,463 epoch 53 - iter 5/6 - loss 6.11172791 - samples/sec: 5.33 - lr: 0.000391\n",
      "2021-06-20 21:32:30,830 epoch 53 - iter 6/6 - loss 7.14380646 - samples/sec: 21.81 - lr: 0.000391\n",
      "2021-06-20 21:32:30,831 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:32:30,832 EPOCH 53 done: loss 7.1438 - lr 0.0003906\n",
      "2021-06-20 21:32:31,192 DEV : loss 3.33526611328125 - score 0.0\n",
      "Epoch    53: reducing learning rate of group 0 to 1.9531e-04.\n",
      "2021-06-20 21:32:31,194 BAD EPOCHS (no improvement): 4\n",
      "2021-06-20 21:32:31,195 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:32:33,404 epoch 54 - iter 1/6 - loss 4.33464050 - samples/sec: 3.62 - lr: 0.000195\n",
      "2021-06-20 21:32:35,119 epoch 54 - iter 2/6 - loss 5.09224701 - samples/sec: 4.67 - lr: 0.000195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 21:32:37,281 epoch 54 - iter 3/6 - loss 5.30440776 - samples/sec: 3.70 - lr: 0.000195\n",
      "2021-06-20 21:32:38,783 epoch 54 - iter 4/6 - loss 6.16687393 - samples/sec: 5.33 - lr: 0.000195\n",
      "2021-06-20 21:32:40,397 epoch 54 - iter 5/6 - loss 5.63813477 - samples/sec: 4.96 - lr: 0.000195\n",
      "2021-06-20 21:32:40,782 epoch 54 - iter 6/6 - loss 5.43918864 - samples/sec: 20.80 - lr: 0.000195\n",
      "2021-06-20 21:32:40,783 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:32:40,784 EPOCH 54 done: loss 5.4392 - lr 0.0001953\n",
      "2021-06-20 21:32:41,143 DEV : loss 3.343048095703125 - score 0.0\n",
      "2021-06-20 21:32:41,145 BAD EPOCHS (no improvement): 1\n",
      "2021-06-20 21:32:41,146 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:32:42,750 epoch 55 - iter 1/6 - loss 3.80401611 - samples/sec: 4.99 - lr: 0.000195\n",
      "2021-06-20 21:32:44,739 epoch 55 - iter 2/6 - loss 5.90249634 - samples/sec: 4.02 - lr: 0.000195\n",
      "2021-06-20 21:32:46,692 epoch 55 - iter 3/6 - loss 6.11983744 - samples/sec: 4.10 - lr: 0.000195\n",
      "2021-06-20 21:32:48,148 epoch 55 - iter 4/6 - loss 5.34341049 - samples/sec: 5.50 - lr: 0.000195\n",
      "2021-06-20 21:32:50,348 epoch 55 - iter 5/6 - loss 5.60485229 - samples/sec: 3.64 - lr: 0.000195\n",
      "2021-06-20 21:32:50,705 epoch 55 - iter 6/6 - loss 5.36661275 - samples/sec: 22.43 - lr: 0.000195\n",
      "2021-06-20 21:32:50,706 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:32:50,707 EPOCH 55 done: loss 5.3666 - lr 0.0001953\n",
      "2021-06-20 21:32:51,065 DEV : loss 3.34991455078125 - score 0.0\n",
      "2021-06-20 21:32:51,067 BAD EPOCHS (no improvement): 2\n",
      "2021-06-20 21:32:51,068 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:32:52,560 epoch 56 - iter 1/6 - loss 6.04621887 - samples/sec: 5.37 - lr: 0.000195\n",
      "2021-06-20 21:32:54,411 epoch 56 - iter 2/6 - loss 5.18530273 - samples/sec: 4.32 - lr: 0.000195\n",
      "2021-06-20 21:32:56,209 epoch 56 - iter 3/6 - loss 5.62041473 - samples/sec: 4.45 - lr: 0.000195\n",
      "2021-06-20 21:32:57,768 epoch 56 - iter 4/6 - loss 5.70508003 - samples/sec: 5.13 - lr: 0.000195\n",
      "2021-06-20 21:33:00,072 epoch 56 - iter 5/6 - loss 5.87703094 - samples/sec: 3.47 - lr: 0.000195\n",
      "2021-06-20 21:33:00,446 epoch 56 - iter 6/6 - loss 5.53105036 - samples/sec: 21.45 - lr: 0.000195\n",
      "2021-06-20 21:33:00,447 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:33:00,448 EPOCH 56 done: loss 5.5311 - lr 0.0001953\n",
      "2021-06-20 21:33:00,811 DEV : loss 3.350128173828125 - score 0.0\n",
      "2021-06-20 21:33:00,813 BAD EPOCHS (no improvement): 3\n",
      "2021-06-20 21:33:00,814 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:33:02,795 epoch 57 - iter 1/6 - loss 7.66958618 - samples/sec: 4.04 - lr: 0.000195\n",
      "2021-06-20 21:33:04,786 epoch 57 - iter 2/6 - loss 7.86307526 - samples/sec: 4.02 - lr: 0.000195\n",
      "2021-06-20 21:33:06,404 epoch 57 - iter 3/6 - loss 7.40633138 - samples/sec: 4.95 - lr: 0.000195\n",
      "2021-06-20 21:33:08,042 epoch 57 - iter 4/6 - loss 6.64317322 - samples/sec: 4.89 - lr: 0.000195\n",
      "2021-06-20 21:33:09,519 epoch 57 - iter 5/6 - loss 6.15330048 - samples/sec: 5.42 - lr: 0.000195\n",
      "2021-06-20 21:33:10,035 epoch 57 - iter 6/6 - loss 5.68040339 - samples/sec: 15.53 - lr: 0.000195\n",
      "2021-06-20 21:33:10,036 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:33:10,036 EPOCH 57 done: loss 5.6804 - lr 0.0001953\n",
      "2021-06-20 21:33:10,395 DEV : loss 3.349822998046875 - score 0.0\n",
      "Epoch    57: reducing learning rate of group 0 to 9.7656e-05.\n",
      "2021-06-20 21:33:10,397 BAD EPOCHS (no improvement): 4\n",
      "2021-06-20 21:33:10,398 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:33:10,399 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:33:10,400 learning rate too small - quitting training!\n",
      "2021-06-20 21:33:10,401 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:33:12,864 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:33:12,865 Testing using best model ...\n",
      "2021-06-20 21:33:12,869 loading file /Users/varunnathan/Documents/General/ExternalTest/Prodigal/model/flair_ft_v1/best-model.pt\n",
      "2021-06-20 21:33:29,374 0.0000\t0.0000\t0.0000\n",
      "2021-06-20 21:33:29,375 \n",
      "Results:\n",
      "- F1-score (micro) 0.0000\n",
      "- F1-score (macro) 0.0000\n",
      "\n",
      "By class:\n",
      "<unk>      tp: 0 - fp: 105 - fn: 0 - precision: 0.0000 - recall: 0.0000 - f1-score: 0.0000\n",
      "DATE       tp: 0 - fp: 0 - fn: 34 - precision: 0.0000 - recall: 0.0000 - f1-score: 0.0000\n",
      "NUM_PAYMENTS tp: 0 - fp: 0 - fn: 4 - precision: 0.0000 - recall: 0.0000 - f1-score: 0.0000\n",
      "PAYMENT_AMOUNT tp: 0 - fp: 0 - fn: 32 - precision: 0.0000 - recall: 0.0000 - f1-score: 0.0000\n",
      "PAYMENT_DATE tp: 0 - fp: 0 - fn: 38 - precision: 0.0000 - recall: 0.0000 - f1-score: 0.0000\n",
      "2021-06-20 21:33:29,376 ----------------------------------------------------------------------------------------------------\n",
      "load model\n",
      "2021-06-20 21:33:29,387 loading file /Users/varunnathan/Documents/General/ExternalTest/Prodigal/model/flair_ft_v1/final-model.pt\n",
      "CPU times: user 10min 1s, sys: 40.2 s, total: 10min 41s\n",
      "Wall time: 10min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "config = {\"use_crf\": True, \"hidden_size\": 100, \"learning_rate\": 0.1, \n",
    "          \"mini_batch_size\": 8, \"max_epochs\": 75}\n",
    "model = train(corpus, FLAIR_FT_MODEL_DIR, fine_tuning=True, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "corresponding-mission",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contraction\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'text': 'december',\n",
       "  'start_pos': 83,\n",
       "  'end_pos': 91,\n",
       "  'labels': [<unk> (0.9993)]},\n",
       " {'text': 'the', 'start_pos': 92, 'end_pos': 95, 'labels': [<unk> (0.9804)]},\n",
       " {'text': 'twenty', 'start_pos': 96, 'end_pos': 102, 'labels': [<unk> (1.0)]},\n",
       " {'text': 'first',\n",
       "  'start_pos': 103,\n",
       "  'end_pos': 108,\n",
       "  'labels': [<unk> (0.9987)]},\n",
       " {'text': 'one', 'start_pos': 188, 'end_pos': 191, 'labels': [<unk> (0.9673)]},\n",
       " {'text': 'hundred',\n",
       "  'start_pos': 192,\n",
       "  'end_pos': 199,\n",
       "  'labels': [<unk> (1.0)]},\n",
       " {'text': 'dollars',\n",
       "  'start_pos': 200,\n",
       "  'end_pos': 207,\n",
       "  'labels': [<unk> (1.0)]},\n",
       " {'text': 'twenty',\n",
       "  'start_pos': 272,\n",
       "  'end_pos': 278,\n",
       "  'labels': [<unk> (0.9989)]},\n",
       " {'text': 'first',\n",
       "  'start_pos': 279,\n",
       "  'end_pos': 284,\n",
       "  'labels': [<unk> (0.9988)]},\n",
       " {'text': 'january',\n",
       "  'start_pos': 292,\n",
       "  'end_pos': 299,\n",
       "  'labels': [<unk> (0.9985)]},\n",
       " {'text': 'the', 'start_pos': 300, 'end_pos': 303, 'labels': [<unk> (0.9435)]},\n",
       " {'text': 'sixteenth',\n",
       "  'start_pos': 304,\n",
       "  'end_pos': 313,\n",
       "  'labels': [<unk> (0.9999)]}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"let's review the arrangement that he all have set up today today's date \\\n",
    "is monday december the twenty first and you have authorized the total i of two debit \\\n",
    "transactions in the amount of one hundred dollars should be taken from your debit card \\\n",
    "on today's date monday the twenty first and on january the sixteenth you understand that \\\n",
    "the payment you are authorizing will be processed as electronic service to your \\\n",
    "account and you can send to this recording that trying to signature for this payment \\\n",
    "arrangement please state your name\"\n",
    "predict(model, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "maritime-convention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create tag dictionary\n",
      "training from scratch\n",
      "\n",
      "Embeddings init\n",
      "2021-06-20 21:41:05,242 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/news-forward-0.4.1.pt not found in cache, downloading to /var/folders/r7/l1g4z9lj3xj_hznsvvcdkzzh0000gn/T/tmpi_kkdwj0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73034624/73034624 [00:07<00:00, 9586994.37B/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 21:41:13,530 copying /var/folders/r7/l1g4z9lj3xj_hznsvvcdkzzh0000gn/T/tmpi_kkdwj0 to cache at /Users/varunnathan/.flair/embeddings/news-forward-0.4.1.pt\n",
      "2021-06-20 21:41:13,577 removing temp file /var/folders/r7/l1g4z9lj3xj_hznsvvcdkzzh0000gn/T/tmpi_kkdwj0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 21:41:14,497 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/news-backward-0.4.1.pt not found in cache, downloading to /var/folders/r7/l1g4z9lj3xj_hznsvvcdkzzh0000gn/T/tmp9lhlrglq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73034575/73034575 [00:07<00:00, 9213175.41B/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 21:41:23,123 copying /var/folders/r7/l1g4z9lj3xj_hznsvvcdkzzh0000gn/T/tmp9lhlrglq to cache at /Users/varunnathan/.flair/embeddings/news-backward-0.4.1.pt\n",
      "2021-06-20 21:41:23,153 removing temp file /var/folders/r7/l1g4z9lj3xj_hznsvvcdkzzh0000gn/T/tmp9lhlrglq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence tagger init\n",
      "Model Trainer\n",
      "Training begins\n",
      "2021-06-20 21:41:23,440 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:41:23,441 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.05, inplace=False)\n",
      "        (encoder): Embedding(300, 100)\n",
      "        (rnn): LSTM(100, 2048)\n",
      "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.05, inplace=False)\n",
      "        (encoder): Embedding(300, 100)\n",
      "        (rnn): LSTM(100, 2048)\n",
      "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (rnn): LSTM(4096, 50, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=100, out_features=8, bias=True)\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2021-06-20 21:41:23,442 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:41:23,442 Corpus: \"Corpus: 41 train + 4 dev + 5 test sentences\"\n",
      "2021-06-20 21:41:23,443 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:41:23,444 Parameters:\n",
      "2021-06-20 21:41:23,444  - learning_rate: \"0.1\"\n",
      "2021-06-20 21:41:23,445  - mini_batch_size: \"8\"\n",
      "2021-06-20 21:41:23,445  - patience: \"3\"\n",
      "2021-06-20 21:41:23,446  - anneal_factor: \"0.5\"\n",
      "2021-06-20 21:41:23,446  - max_epochs: \"75\"\n",
      "2021-06-20 21:41:23,447  - shuffle: \"True\"\n",
      "2021-06-20 21:41:23,447  - train_with_dev: \"False\"\n",
      "2021-06-20 21:41:23,448  - batch_growth_annealing: \"False\"\n",
      "2021-06-20 21:41:23,449 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:41:23,449 Model training base path: \"/Users/varunnathan/Documents/General/ExternalTest/Prodigal/model/flair_v1\"\n",
      "2021-06-20 21:41:23,450 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:41:23,450 Device: cpu\n",
      "2021-06-20 21:41:23,451 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:41:23,452 Embeddings storage mode: cpu\n",
      "2021-06-20 21:41:23,454 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:41:41,380 epoch 1 - iter 1/6 - loss 330.79113770 - samples/sec: 0.45 - lr: 0.100000\n",
      "2021-06-20 21:41:58,286 epoch 1 - iter 2/6 - loss 269.81190491 - samples/sec: 0.47 - lr: 0.100000\n",
      "2021-06-20 21:42:21,436 epoch 1 - iter 3/6 - loss 227.08904012 - samples/sec: 0.35 - lr: 0.100000\n",
      "2021-06-20 21:42:40,753 epoch 1 - iter 4/6 - loss 193.79157829 - samples/sec: 0.41 - lr: 0.100000\n",
      "2021-06-20 21:43:00,298 epoch 1 - iter 5/6 - loss 171.20441742 - samples/sec: 0.41 - lr: 0.100000\n",
      "2021-06-20 21:43:04,895 epoch 1 - iter 6/6 - loss 152.05035273 - samples/sec: 1.74 - lr: 0.100000\n",
      "2021-06-20 21:43:04,897 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:43:04,897 EPOCH 1 done: loss 152.0504 - lr 0.1000000\n",
      "2021-06-20 21:43:19,920 DEV : loss 66.62849426269531 - score 0.8083\n",
      "2021-06-20 21:43:19,922 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-06-20 21:43:20,172 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:43:21,573 epoch 2 - iter 1/6 - loss 50.28189468 - samples/sec: 5.72 - lr: 0.100000\n",
      "2021-06-20 21:43:22,697 epoch 2 - iter 2/6 - loss 55.61107445 - samples/sec: 7.12 - lr: 0.100000\n",
      "2021-06-20 21:43:24,289 epoch 2 - iter 3/6 - loss 57.22785441 - samples/sec: 5.03 - lr: 0.100000\n",
      "2021-06-20 21:43:25,707 epoch 2 - iter 4/6 - loss 55.24176979 - samples/sec: 5.64 - lr: 0.100000\n",
      "2021-06-20 21:43:26,774 epoch 2 - iter 5/6 - loss 54.99479980 - samples/sec: 7.50 - lr: 0.100000\n",
      "2021-06-20 21:43:27,066 epoch 2 - iter 6/6 - loss 49.20051066 - samples/sec: 27.47 - lr: 0.100000\n",
      "2021-06-20 21:43:27,067 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:43:27,068 EPOCH 2 done: loss 49.2005 - lr 0.1000000\n",
      "2021-06-20 21:43:27,425 DEV : loss 43.770538330078125 - score 0.8693\n",
      "2021-06-20 21:43:27,427 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-06-20 21:43:27,670 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:43:29,087 epoch 3 - iter 1/6 - loss 38.25418472 - samples/sec: 5.65 - lr: 0.100000\n",
      "2021-06-20 21:43:30,251 epoch 3 - iter 2/6 - loss 41.03342628 - samples/sec: 6.88 - lr: 0.100000\n",
      "2021-06-20 21:43:31,461 epoch 3 - iter 3/6 - loss 39.79423904 - samples/sec: 6.62 - lr: 0.100000\n",
      "2021-06-20 21:43:32,517 epoch 3 - iter 4/6 - loss 41.28077793 - samples/sec: 7.58 - lr: 0.100000\n",
      "2021-06-20 21:43:33,863 epoch 3 - iter 5/6 - loss 39.90026016 - samples/sec: 5.95 - lr: 0.100000\n",
      "2021-06-20 21:43:34,140 epoch 3 - iter 6/6 - loss 38.60646884 - samples/sec: 28.98 - lr: 0.100000\n",
      "2021-06-20 21:43:34,141 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:43:34,142 EPOCH 3 done: loss 38.6065 - lr 0.1000000\n",
      "2021-06-20 21:43:34,494 DEV : loss 32.73480987548828 - score 0.9041\n",
      "2021-06-20 21:43:34,497 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-06-20 21:43:34,764 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:43:36,229 epoch 4 - iter 1/6 - loss 31.47731400 - samples/sec: 5.47 - lr: 0.100000\n",
      "2021-06-20 21:43:37,530 epoch 4 - iter 2/6 - loss 30.23993874 - samples/sec: 6.16 - lr: 0.100000\n",
      "2021-06-20 21:43:38,681 epoch 4 - iter 3/6 - loss 31.77752686 - samples/sec: 6.96 - lr: 0.100000\n",
      "2021-06-20 21:43:39,964 epoch 4 - iter 4/6 - loss 31.03815079 - samples/sec: 6.24 - lr: 0.100000\n",
      "2021-06-20 21:43:41,270 epoch 4 - iter 5/6 - loss 30.36269531 - samples/sec: 6.13 - lr: 0.100000\n",
      "2021-06-20 21:43:41,585 epoch 4 - iter 6/6 - loss 29.99837240 - samples/sec: 25.39 - lr: 0.100000\n",
      "2021-06-20 21:43:41,586 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:43:41,587 EPOCH 4 done: loss 29.9984 - lr 0.1000000\n",
      "2021-06-20 21:43:41,882 DEV : loss 28.105995178222656 - score 0.8976\n",
      "2021-06-20 21:43:41,884 BAD EPOCHS (no improvement): 1\n",
      "2021-06-20 21:43:41,885 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:43:42,882 epoch 5 - iter 1/6 - loss 21.40777206 - samples/sec: 8.04 - lr: 0.100000\n",
      "2021-06-20 21:43:44,566 epoch 5 - iter 2/6 - loss 25.19058037 - samples/sec: 4.75 - lr: 0.100000\n",
      "2021-06-20 21:43:45,696 epoch 5 - iter 3/6 - loss 23.08773804 - samples/sec: 7.09 - lr: 0.100000\n",
      "2021-06-20 21:43:46,825 epoch 5 - iter 4/6 - loss 24.33450890 - samples/sec: 7.09 - lr: 0.100000\n",
      "2021-06-20 21:43:47,729 epoch 5 - iter 5/6 - loss 24.52275391 - samples/sec: 8.86 - lr: 0.100000\n",
      "2021-06-20 21:43:48,134 epoch 5 - iter 6/6 - loss 22.40468343 - samples/sec: 19.84 - lr: 0.100000\n",
      "2021-06-20 21:43:48,135 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:43:48,136 EPOCH 5 done: loss 22.4047 - lr 0.1000000\n",
      "2021-06-20 21:43:48,498 DEV : loss 23.63579559326172 - score 0.9368\n",
      "2021-06-20 21:43:48,500 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-06-20 21:43:48,765 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:43:50,120 epoch 6 - iter 1/6 - loss 25.60966492 - samples/sec: 5.91 - lr: 0.100000\n",
      "2021-06-20 21:43:51,378 epoch 6 - iter 2/6 - loss 24.77254105 - samples/sec: 6.36 - lr: 0.100000\n",
      "2021-06-20 21:43:52,400 epoch 6 - iter 3/6 - loss 25.25084686 - samples/sec: 7.83 - lr: 0.100000\n",
      "2021-06-20 21:43:53,618 epoch 6 - iter 4/6 - loss 23.02142715 - samples/sec: 6.58 - lr: 0.100000\n",
      "2021-06-20 21:43:54,646 epoch 6 - iter 5/6 - loss 23.65909805 - samples/sec: 7.78 - lr: 0.100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 21:43:54,911 epoch 6 - iter 6/6 - loss 22.31955274 - samples/sec: 30.37 - lr: 0.100000\n",
      "2021-06-20 21:43:54,912 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:43:54,913 EPOCH 6 done: loss 22.3196 - lr 0.1000000\n",
      "2021-06-20 21:43:55,238 DEV : loss 18.203536987304688 - score 0.9368\n",
      "2021-06-20 21:43:55,240 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-06-20 21:43:55,479 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:43:56,993 epoch 7 - iter 1/6 - loss 13.47252655 - samples/sec: 5.29 - lr: 0.100000\n",
      "2021-06-20 21:43:58,255 epoch 7 - iter 2/6 - loss 16.32611465 - samples/sec: 6.34 - lr: 0.100000\n",
      "2021-06-20 21:43:59,582 epoch 7 - iter 3/6 - loss 16.23280970 - samples/sec: 6.04 - lr: 0.100000\n",
      "2021-06-20 21:44:00,507 epoch 7 - iter 4/6 - loss 16.54917526 - samples/sec: 8.65 - lr: 0.100000\n",
      "2021-06-20 21:44:01,778 epoch 7 - iter 5/6 - loss 17.28648071 - samples/sec: 6.30 - lr: 0.100000\n",
      "2021-06-20 21:44:02,039 epoch 7 - iter 6/6 - loss 16.33974711 - samples/sec: 30.73 - lr: 0.100000\n",
      "2021-06-20 21:44:02,040 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:44:02,041 EPOCH 7 done: loss 16.3397 - lr 0.1000000\n",
      "2021-06-20 21:44:02,339 DEV : loss 18.2843017578125 - score 0.9303\n",
      "2021-06-20 21:44:02,341 BAD EPOCHS (no improvement): 1\n",
      "2021-06-20 21:44:02,342 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:44:03,613 epoch 8 - iter 1/6 - loss 20.11071777 - samples/sec: 6.30 - lr: 0.100000\n",
      "2021-06-20 21:44:04,759 epoch 8 - iter 2/6 - loss 17.43512154 - samples/sec: 6.98 - lr: 0.100000\n",
      "2021-06-20 21:44:05,728 epoch 8 - iter 3/6 - loss 17.46235021 - samples/sec: 8.26 - lr: 0.100000\n",
      "2021-06-20 21:44:06,852 epoch 8 - iter 4/6 - loss 17.91523647 - samples/sec: 7.13 - lr: 0.100000\n",
      "2021-06-20 21:44:07,943 epoch 8 - iter 5/6 - loss 16.66387863 - samples/sec: 7.34 - lr: 0.100000\n",
      "2021-06-20 21:44:08,258 epoch 8 - iter 6/6 - loss 17.03306007 - samples/sec: 25.44 - lr: 0.100000\n",
      "2021-06-20 21:44:08,259 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:44:08,260 EPOCH 8 done: loss 17.0331 - lr 0.1000000\n",
      "2021-06-20 21:44:08,622 DEV : loss 14.129592895507812 - score 0.9542\n",
      "2021-06-20 21:44:08,624 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-06-20 21:44:08,890 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:44:10,153 epoch 9 - iter 1/6 - loss 9.63112640 - samples/sec: 6.34 - lr: 0.100000\n",
      "2021-06-20 21:44:11,440 epoch 9 - iter 2/6 - loss 9.99601746 - samples/sec: 6.22 - lr: 0.100000\n",
      "2021-06-20 21:44:12,605 epoch 9 - iter 3/6 - loss 11.85197322 - samples/sec: 6.87 - lr: 0.100000\n",
      "2021-06-20 21:44:13,615 epoch 9 - iter 4/6 - loss 14.83921719 - samples/sec: 7.92 - lr: 0.100000\n",
      "2021-06-20 21:44:14,853 epoch 9 - iter 5/6 - loss 15.98941498 - samples/sec: 6.47 - lr: 0.100000\n",
      "2021-06-20 21:44:15,111 epoch 9 - iter 6/6 - loss 15.39385859 - samples/sec: 31.05 - lr: 0.100000\n",
      "2021-06-20 21:44:15,112 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:44:15,113 EPOCH 9 done: loss 15.3939 - lr 0.1000000\n",
      "2021-06-20 21:44:15,401 DEV : loss 21.470687866210938 - score 0.9172\n",
      "2021-06-20 21:44:15,403 BAD EPOCHS (no improvement): 1\n",
      "2021-06-20 21:44:15,405 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:44:16,657 epoch 10 - iter 1/6 - loss 15.55844116 - samples/sec: 6.40 - lr: 0.100000\n",
      "2021-06-20 21:44:17,542 epoch 10 - iter 2/6 - loss 13.04190254 - samples/sec: 9.05 - lr: 0.100000\n",
      "2021-06-20 21:44:18,541 epoch 10 - iter 3/6 - loss 12.11997350 - samples/sec: 8.01 - lr: 0.100000\n",
      "2021-06-20 21:44:19,763 epoch 10 - iter 4/6 - loss 12.67229748 - samples/sec: 6.55 - lr: 0.100000\n",
      "2021-06-20 21:44:20,725 epoch 10 - iter 5/6 - loss 11.68300095 - samples/sec: 8.33 - lr: 0.100000\n",
      "2021-06-20 21:44:20,990 epoch 10 - iter 6/6 - loss 11.41002846 - samples/sec: 30.30 - lr: 0.100000\n",
      "2021-06-20 21:44:20,991 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:44:20,992 EPOCH 10 done: loss 11.4100 - lr 0.1000000\n",
      "2021-06-20 21:44:21,274 DEV : loss 9.5706787109375 - score 0.9651\n",
      "2021-06-20 21:44:21,279 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-06-20 21:44:21,509 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:44:22,623 epoch 11 - iter 1/6 - loss 7.98710632 - samples/sec: 7.19 - lr: 0.100000\n",
      "2021-06-20 21:44:23,486 epoch 11 - iter 2/6 - loss 10.14479637 - samples/sec: 9.28 - lr: 0.100000\n",
      "2021-06-20 21:44:24,667 epoch 11 - iter 3/6 - loss 8.71977615 - samples/sec: 6.78 - lr: 0.100000\n",
      "2021-06-20 21:44:25,642 epoch 11 - iter 4/6 - loss 8.85907269 - samples/sec: 8.21 - lr: 0.100000\n",
      "2021-06-20 21:44:26,871 epoch 11 - iter 5/6 - loss 9.95669327 - samples/sec: 6.52 - lr: 0.100000\n",
      "2021-06-20 21:44:27,107 epoch 11 - iter 6/6 - loss 9.25169182 - samples/sec: 34.00 - lr: 0.100000\n",
      "2021-06-20 21:44:27,108 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:44:27,109 EPOCH 11 done: loss 9.2517 - lr 0.1000000\n",
      "2021-06-20 21:44:27,394 DEV : loss 7.82305908203125 - score 0.9739\n",
      "2021-06-20 21:44:27,396 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-06-20 21:44:27,633 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:44:28,602 epoch 12 - iter 1/6 - loss 10.67948151 - samples/sec: 8.26 - lr: 0.100000\n",
      "2021-06-20 21:44:29,610 epoch 12 - iter 2/6 - loss 9.13681412 - samples/sec: 7.94 - lr: 0.100000\n",
      "2021-06-20 21:44:30,730 epoch 12 - iter 3/6 - loss 8.75859324 - samples/sec: 7.15 - lr: 0.100000\n",
      "2021-06-20 21:44:31,923 epoch 12 - iter 4/6 - loss 8.21887016 - samples/sec: 6.71 - lr: 0.100000\n",
      "2021-06-20 21:44:33,129 epoch 12 - iter 5/6 - loss 10.25095367 - samples/sec: 6.64 - lr: 0.100000\n",
      "2021-06-20 21:44:33,358 epoch 12 - iter 6/6 - loss 9.94222132 - samples/sec: 35.07 - lr: 0.100000\n",
      "2021-06-20 21:44:33,358 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:44:33,359 EPOCH 12 done: loss 9.9422 - lr 0.1000000\n",
      "2021-06-20 21:44:33,645 DEV : loss 12.223236083984375 - score 0.939\n",
      "2021-06-20 21:44:33,647 BAD EPOCHS (no improvement): 1\n",
      "2021-06-20 21:44:33,649 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:44:34,817 epoch 13 - iter 1/6 - loss 6.27193451 - samples/sec: 6.86 - lr: 0.100000\n",
      "2021-06-20 21:44:35,988 epoch 13 - iter 2/6 - loss 7.72591209 - samples/sec: 6.83 - lr: 0.100000\n",
      "2021-06-20 21:44:37,224 epoch 13 - iter 3/6 - loss 8.36212540 - samples/sec: 6.48 - lr: 0.100000\n",
      "2021-06-20 21:44:39,112 epoch 13 - iter 4/6 - loss 8.74943352 - samples/sec: 4.24 - lr: 0.100000\n",
      "2021-06-20 21:44:40,297 epoch 13 - iter 5/6 - loss 9.51696396 - samples/sec: 6.76 - lr: 0.100000\n",
      "2021-06-20 21:44:40,618 epoch 13 - iter 6/6 - loss 9.72834969 - samples/sec: 25.02 - lr: 0.100000\n",
      "2021-06-20 21:44:40,619 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:44:40,620 EPOCH 13 done: loss 9.7283 - lr 0.1000000\n",
      "2021-06-20 21:44:40,963 DEV : loss 11.991302490234375 - score 0.9651\n",
      "2021-06-20 21:44:40,966 BAD EPOCHS (no improvement): 2\n",
      "2021-06-20 21:44:40,967 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:44:42,181 epoch 14 - iter 1/6 - loss 10.18268585 - samples/sec: 6.59 - lr: 0.100000\n",
      "2021-06-20 21:44:43,551 epoch 14 - iter 2/6 - loss 9.10274506 - samples/sec: 5.84 - lr: 0.100000\n",
      "2021-06-20 21:44:44,617 epoch 14 - iter 3/6 - loss 8.78850555 - samples/sec: 7.51 - lr: 0.100000\n",
      "2021-06-20 21:44:45,688 epoch 14 - iter 4/6 - loss 8.60966682 - samples/sec: 7.47 - lr: 0.100000\n",
      "2021-06-20 21:44:47,047 epoch 14 - iter 5/6 - loss 8.76427917 - samples/sec: 5.89 - lr: 0.100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 21:44:47,297 epoch 14 - iter 6/6 - loss 7.68620555 - samples/sec: 32.17 - lr: 0.100000\n",
      "2021-06-20 21:44:47,298 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:44:47,298 EPOCH 14 done: loss 7.6862 - lr 0.1000000\n",
      "2021-06-20 21:44:47,592 DEV : loss 6.638580322265625 - score 0.9782\n",
      "2021-06-20 21:44:47,594 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-06-20 21:44:47,821 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:44:49,090 epoch 15 - iter 1/6 - loss 11.48314667 - samples/sec: 6.31 - lr: 0.100000\n",
      "2021-06-20 21:44:50,196 epoch 15 - iter 2/6 - loss 10.72390366 - samples/sec: 7.24 - lr: 0.100000\n",
      "2021-06-20 21:44:51,351 epoch 15 - iter 3/6 - loss 9.68699137 - samples/sec: 6.93 - lr: 0.100000\n",
      "2021-06-20 21:44:52,381 epoch 15 - iter 4/6 - loss 8.83640289 - samples/sec: 7.77 - lr: 0.100000\n",
      "2021-06-20 21:44:53,271 epoch 15 - iter 5/6 - loss 8.43178711 - samples/sec: 9.00 - lr: 0.100000\n",
      "2021-06-20 21:44:53,513 epoch 15 - iter 6/6 - loss 7.42297363 - samples/sec: 33.26 - lr: 0.100000\n",
      "2021-06-20 21:44:53,513 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:44:53,514 EPOCH 15 done: loss 7.4230 - lr 0.1000000\n",
      "2021-06-20 21:44:53,796 DEV : loss 5.491180419921875 - score 0.9847\n",
      "2021-06-20 21:44:53,799 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-06-20 21:44:54,020 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:44:55,421 epoch 16 - iter 1/6 - loss 4.84693146 - samples/sec: 5.72 - lr: 0.100000\n",
      "2021-06-20 21:44:56,592 epoch 16 - iter 2/6 - loss 5.33459473 - samples/sec: 6.83 - lr: 0.100000\n",
      "2021-06-20 21:44:57,944 epoch 16 - iter 3/6 - loss 7.23832957 - samples/sec: 5.92 - lr: 0.100000\n",
      "2021-06-20 21:44:58,868 epoch 16 - iter 4/6 - loss 7.10354996 - samples/sec: 8.68 - lr: 0.100000\n",
      "2021-06-20 21:44:59,832 epoch 16 - iter 5/6 - loss 7.27792206 - samples/sec: 8.30 - lr: 0.100000\n",
      "2021-06-20 21:45:00,072 epoch 16 - iter 6/6 - loss 8.07648087 - samples/sec: 33.47 - lr: 0.100000\n",
      "2021-06-20 21:45:00,073 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:45:00,074 EPOCH 16 done: loss 8.0765 - lr 0.1000000\n",
      "2021-06-20 21:45:00,356 DEV : loss 8.617843627929688 - score 0.9695\n",
      "2021-06-20 21:45:00,358 BAD EPOCHS (no improvement): 1\n",
      "2021-06-20 21:45:00,359 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:45:01,484 epoch 17 - iter 1/6 - loss 9.31729126 - samples/sec: 7.13 - lr: 0.100000\n",
      "2021-06-20 21:45:02,482 epoch 17 - iter 2/6 - loss 9.48486710 - samples/sec: 8.02 - lr: 0.100000\n",
      "2021-06-20 21:45:03,656 epoch 17 - iter 3/6 - loss 10.05854925 - samples/sec: 6.82 - lr: 0.100000\n",
      "2021-06-20 21:45:04,891 epoch 17 - iter 4/6 - loss 9.55798626 - samples/sec: 6.48 - lr: 0.100000\n",
      "2021-06-20 21:45:05,944 epoch 17 - iter 5/6 - loss 8.80992661 - samples/sec: 7.61 - lr: 0.100000\n",
      "2021-06-20 21:45:06,188 epoch 17 - iter 6/6 - loss 8.03221830 - samples/sec: 32.91 - lr: 0.100000\n",
      "2021-06-20 21:45:06,188 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:45:06,189 EPOCH 17 done: loss 8.0322 - lr 0.1000000\n",
      "2021-06-20 21:45:06,484 DEV : loss 7.6627044677734375 - score 0.9782\n",
      "2021-06-20 21:45:06,486 BAD EPOCHS (no improvement): 2\n",
      "2021-06-20 21:45:06,487 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:45:07,807 epoch 18 - iter 1/6 - loss 7.23592377 - samples/sec: 6.07 - lr: 0.100000\n",
      "2021-06-20 21:45:08,749 epoch 18 - iter 2/6 - loss 6.17112350 - samples/sec: 8.50 - lr: 0.100000\n",
      "2021-06-20 21:45:10,088 epoch 18 - iter 3/6 - loss 6.23763784 - samples/sec: 5.98 - lr: 0.100000\n",
      "2021-06-20 21:45:11,246 epoch 18 - iter 4/6 - loss 6.32711029 - samples/sec: 6.91 - lr: 0.100000\n",
      "2021-06-20 21:45:12,386 epoch 18 - iter 5/6 - loss 6.14930267 - samples/sec: 7.03 - lr: 0.100000\n",
      "2021-06-20 21:45:12,621 epoch 18 - iter 6/6 - loss 6.04229609 - samples/sec: 34.16 - lr: 0.100000\n",
      "2021-06-20 21:45:12,622 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:45:12,623 EPOCH 18 done: loss 6.0423 - lr 0.1000000\n",
      "2021-06-20 21:45:12,929 DEV : loss 4.4367828369140625 - score 0.9847\n",
      "2021-06-20 21:45:12,932 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-06-20 21:45:13,163 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:45:14,134 epoch 19 - iter 1/6 - loss 7.15495300 - samples/sec: 8.25 - lr: 0.100000\n",
      "2021-06-20 21:45:15,285 epoch 19 - iter 2/6 - loss 5.80637932 - samples/sec: 6.95 - lr: 0.100000\n",
      "2021-06-20 21:45:16,640 epoch 19 - iter 3/6 - loss 6.54750188 - samples/sec: 5.91 - lr: 0.100000\n",
      "2021-06-20 21:45:17,873 epoch 19 - iter 4/6 - loss 6.75343227 - samples/sec: 6.50 - lr: 0.100000\n",
      "2021-06-20 21:45:19,016 epoch 19 - iter 5/6 - loss 6.48237076 - samples/sec: 7.01 - lr: 0.100000\n",
      "2021-06-20 21:45:19,271 epoch 19 - iter 6/6 - loss 10.54681206 - samples/sec: 31.45 - lr: 0.100000\n",
      "2021-06-20 21:45:19,272 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:45:19,272 EPOCH 19 done: loss 10.5468 - lr 0.1000000\n",
      "2021-06-20 21:45:19,604 DEV : loss 9.77471923828125 - score 0.9739\n",
      "2021-06-20 21:45:19,606 BAD EPOCHS (no improvement): 1\n",
      "2021-06-20 21:45:19,607 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:45:20,937 epoch 20 - iter 1/6 - loss 14.79257965 - samples/sec: 6.02 - lr: 0.100000\n",
      "2021-06-20 21:45:22,226 epoch 20 - iter 2/6 - loss 10.96653366 - samples/sec: 6.21 - lr: 0.100000\n",
      "2021-06-20 21:45:23,572 epoch 20 - iter 3/6 - loss 9.60325368 - samples/sec: 5.95 - lr: 0.100000\n",
      "2021-06-20 21:45:24,649 epoch 20 - iter 4/6 - loss 8.53016281 - samples/sec: 7.44 - lr: 0.100000\n",
      "2021-06-20 21:45:25,616 epoch 20 - iter 5/6 - loss 7.96596069 - samples/sec: 8.27 - lr: 0.100000\n",
      "2021-06-20 21:45:25,898 epoch 20 - iter 6/6 - loss 8.27029928 - samples/sec: 28.45 - lr: 0.100000\n",
      "2021-06-20 21:45:25,899 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:45:25,900 EPOCH 20 done: loss 8.2703 - lr 0.1000000\n",
      "2021-06-20 21:45:26,209 DEV : loss 6.907135009765625 - score 0.9739\n",
      "2021-06-20 21:45:26,211 BAD EPOCHS (no improvement): 2\n",
      "2021-06-20 21:45:26,212 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:45:27,889 epoch 21 - iter 1/6 - loss 5.15476227 - samples/sec: 4.78 - lr: 0.100000\n",
      "2021-06-20 21:45:28,802 epoch 21 - iter 2/6 - loss 6.76209068 - samples/sec: 8.77 - lr: 0.100000\n",
      "2021-06-20 21:45:29,784 epoch 21 - iter 3/6 - loss 5.98991267 - samples/sec: 8.15 - lr: 0.100000\n",
      "2021-06-20 21:45:30,944 epoch 21 - iter 4/6 - loss 6.34744167 - samples/sec: 6.91 - lr: 0.100000\n",
      "2021-06-20 21:45:32,031 epoch 21 - iter 5/6 - loss 6.15268097 - samples/sec: 7.36 - lr: 0.100000\n",
      "2021-06-20 21:45:32,316 epoch 21 - iter 6/6 - loss 6.20721054 - samples/sec: 28.14 - lr: 0.100000\n",
      "2021-06-20 21:45:32,317 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:45:32,317 EPOCH 21 done: loss 6.2072 - lr 0.1000000\n",
      "2021-06-20 21:45:32,602 DEV : loss 4.550384521484375 - score 0.9847\n",
      "2021-06-20 21:45:32,604 BAD EPOCHS (no improvement): 3\n",
      "2021-06-20 21:45:32,606 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:45:33,761 epoch 22 - iter 1/6 - loss 5.62829590 - samples/sec: 6.93 - lr: 0.100000\n",
      "2021-06-20 21:45:34,801 epoch 22 - iter 2/6 - loss 4.49990082 - samples/sec: 7.69 - lr: 0.100000\n",
      "2021-06-20 21:45:35,795 epoch 22 - iter 3/6 - loss 5.89273834 - samples/sec: 8.06 - lr: 0.100000\n",
      "2021-06-20 21:45:37,009 epoch 22 - iter 4/6 - loss 5.00446510 - samples/sec: 6.59 - lr: 0.100000\n",
      "2021-06-20 21:45:38,328 epoch 22 - iter 5/6 - loss 5.65208740 - samples/sec: 6.07 - lr: 0.100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 21:45:38,603 epoch 22 - iter 6/6 - loss 5.70087687 - samples/sec: 29.11 - lr: 0.100000\n",
      "2021-06-20 21:45:38,604 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:45:38,605 EPOCH 22 done: loss 5.7009 - lr 0.1000000\n",
      "2021-06-20 21:45:38,892 DEV : loss 4.4131317138671875 - score 0.9869\n",
      "2021-06-20 21:45:38,894 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-06-20 21:45:39,131 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:45:40,690 epoch 23 - iter 1/6 - loss 6.30076981 - samples/sec: 5.13 - lr: 0.100000\n",
      "2021-06-20 21:45:41,687 epoch 23 - iter 2/6 - loss 7.02824593 - samples/sec: 8.03 - lr: 0.100000\n",
      "2021-06-20 21:45:42,730 epoch 23 - iter 3/6 - loss 5.70746740 - samples/sec: 7.68 - lr: 0.100000\n",
      "2021-06-20 21:45:43,828 epoch 23 - iter 4/6 - loss 5.44606113 - samples/sec: 7.29 - lr: 0.100000\n",
      "2021-06-20 21:45:44,998 epoch 23 - iter 5/6 - loss 5.59768295 - samples/sec: 6.85 - lr: 0.100000\n",
      "2021-06-20 21:45:45,258 epoch 23 - iter 6/6 - loss 5.32648913 - samples/sec: 30.77 - lr: 0.100000\n",
      "2021-06-20 21:45:45,259 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:45:45,260 EPOCH 23 done: loss 5.3265 - lr 0.1000000\n",
      "2021-06-20 21:45:45,542 DEV : loss 8.489547729492188 - score 0.976\n",
      "2021-06-20 21:45:45,544 BAD EPOCHS (no improvement): 1\n",
      "2021-06-20 21:45:45,545 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:45:46,706 epoch 24 - iter 1/6 - loss 4.90278244 - samples/sec: 6.90 - lr: 0.100000\n",
      "2021-06-20 21:45:47,921 epoch 24 - iter 2/6 - loss 5.12618446 - samples/sec: 6.59 - lr: 0.100000\n",
      "2021-06-20 21:45:48,796 epoch 24 - iter 3/6 - loss 4.97268804 - samples/sec: 9.15 - lr: 0.100000\n",
      "2021-06-20 21:45:49,933 epoch 24 - iter 4/6 - loss 5.53602886 - samples/sec: 7.04 - lr: 0.100000\n",
      "2021-06-20 21:45:50,907 epoch 24 - iter 5/6 - loss 5.53255997 - samples/sec: 8.22 - lr: 0.100000\n",
      "2021-06-20 21:45:51,144 epoch 24 - iter 6/6 - loss 4.73027865 - samples/sec: 33.84 - lr: 0.100000\n",
      "2021-06-20 21:45:51,145 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:45:51,146 EPOCH 24 done: loss 4.7303 - lr 0.1000000\n",
      "2021-06-20 21:45:51,424 DEV : loss 5.199462890625 - score 0.9782\n",
      "2021-06-20 21:45:51,427 BAD EPOCHS (no improvement): 2\n",
      "2021-06-20 21:45:51,429 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:45:52,414 epoch 25 - iter 1/6 - loss 4.94120026 - samples/sec: 8.12 - lr: 0.100000\n",
      "2021-06-20 21:45:53,632 epoch 25 - iter 2/6 - loss 6.37410736 - samples/sec: 6.57 - lr: 0.100000\n",
      "2021-06-20 21:45:54,623 epoch 25 - iter 3/6 - loss 6.15290578 - samples/sec: 8.08 - lr: 0.100000\n",
      "2021-06-20 21:45:55,719 epoch 25 - iter 4/6 - loss 5.79078865 - samples/sec: 7.30 - lr: 0.100000\n",
      "2021-06-20 21:45:56,875 epoch 25 - iter 5/6 - loss 5.43645782 - samples/sec: 6.93 - lr: 0.100000\n",
      "2021-06-20 21:45:57,134 epoch 25 - iter 6/6 - loss 4.84029770 - samples/sec: 30.87 - lr: 0.100000\n",
      "2021-06-20 21:45:57,135 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:45:57,136 EPOCH 25 done: loss 4.8403 - lr 0.1000000\n",
      "2021-06-20 21:45:57,419 DEV : loss 5.5335845947265625 - score 0.9804\n",
      "2021-06-20 21:45:57,421 BAD EPOCHS (no improvement): 3\n",
      "2021-06-20 21:45:57,423 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:45:58,473 epoch 26 - iter 1/6 - loss 5.07302856 - samples/sec: 7.63 - lr: 0.100000\n",
      "2021-06-20 21:45:59,578 epoch 26 - iter 2/6 - loss 7.01546478 - samples/sec: 7.24 - lr: 0.100000\n",
      "2021-06-20 21:46:00,799 epoch 26 - iter 3/6 - loss 6.70630391 - samples/sec: 6.56 - lr: 0.100000\n",
      "2021-06-20 21:46:02,096 epoch 26 - iter 4/6 - loss 6.07321358 - samples/sec: 6.17 - lr: 0.100000\n",
      "2021-06-20 21:46:03,273 epoch 26 - iter 5/6 - loss 6.00529556 - samples/sec: 6.80 - lr: 0.100000\n",
      "2021-06-20 21:46:03,633 epoch 26 - iter 6/6 - loss 6.90779432 - samples/sec: 22.29 - lr: 0.100000\n",
      "2021-06-20 21:46:03,634 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:46:03,635 EPOCH 26 done: loss 6.9078 - lr 0.1000000\n",
      "2021-06-20 21:46:03,951 DEV : loss 5.30718994140625 - score 0.9782\n",
      "Epoch    26: reducing learning rate of group 0 to 5.0000e-02.\n",
      "2021-06-20 21:46:03,955 BAD EPOCHS (no improvement): 4\n",
      "2021-06-20 21:46:03,956 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:46:05,128 epoch 27 - iter 1/6 - loss 4.49143982 - samples/sec: 6.83 - lr: 0.050000\n",
      "2021-06-20 21:46:06,536 epoch 27 - iter 2/6 - loss 5.93644714 - samples/sec: 5.69 - lr: 0.050000\n",
      "2021-06-20 21:46:07,764 epoch 27 - iter 3/6 - loss 5.41193899 - samples/sec: 6.52 - lr: 0.050000\n",
      "2021-06-20 21:46:08,830 epoch 27 - iter 4/6 - loss 4.98697090 - samples/sec: 7.51 - lr: 0.050000\n",
      "2021-06-20 21:46:10,011 epoch 27 - iter 5/6 - loss 4.73402710 - samples/sec: 6.78 - lr: 0.050000\n",
      "2021-06-20 21:46:10,272 epoch 27 - iter 6/6 - loss 4.40330505 - samples/sec: 30.76 - lr: 0.050000\n",
      "2021-06-20 21:46:10,273 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:46:10,274 EPOCH 27 done: loss 4.4033 - lr 0.0500000\n",
      "2021-06-20 21:46:10,575 DEV : loss 3.372314453125 - score 0.9891\n",
      "2021-06-20 21:46:10,578 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-06-20 21:46:10,818 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:46:11,966 epoch 28 - iter 1/6 - loss 1.76061249 - samples/sec: 6.98 - lr: 0.050000\n",
      "2021-06-20 21:46:13,161 epoch 28 - iter 2/6 - loss 2.62620163 - samples/sec: 6.70 - lr: 0.050000\n",
      "2021-06-20 21:46:14,375 epoch 28 - iter 3/6 - loss 3.78235881 - samples/sec: 6.60 - lr: 0.050000\n",
      "2021-06-20 21:46:15,451 epoch 28 - iter 4/6 - loss 4.10113525 - samples/sec: 7.44 - lr: 0.050000\n",
      "2021-06-20 21:46:16,594 epoch 28 - iter 5/6 - loss 4.07129974 - samples/sec: 7.01 - lr: 0.050000\n",
      "2021-06-20 21:46:16,999 epoch 28 - iter 6/6 - loss 3.94517899 - samples/sec: 19.80 - lr: 0.050000\n",
      "2021-06-20 21:46:17,000 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:46:17,001 EPOCH 28 done: loss 3.9452 - lr 0.0500000\n",
      "2021-06-20 21:46:17,380 DEV : loss 3.6361083984375 - score 0.9847\n",
      "2021-06-20 21:46:17,383 BAD EPOCHS (no improvement): 1\n",
      "2021-06-20 21:46:17,385 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:46:18,606 epoch 29 - iter 1/6 - loss 2.69850159 - samples/sec: 6.56 - lr: 0.050000\n",
      "2021-06-20 21:46:19,624 epoch 29 - iter 2/6 - loss 2.96659088 - samples/sec: 7.87 - lr: 0.050000\n",
      "2021-06-20 21:46:20,498 epoch 29 - iter 3/6 - loss 3.71348063 - samples/sec: 9.17 - lr: 0.050000\n",
      "2021-06-20 21:46:21,883 epoch 29 - iter 4/6 - loss 4.35732841 - samples/sec: 5.78 - lr: 0.050000\n",
      "2021-06-20 21:46:23,158 epoch 29 - iter 5/6 - loss 4.86711044 - samples/sec: 6.27 - lr: 0.050000\n",
      "2021-06-20 21:46:23,450 epoch 29 - iter 6/6 - loss 4.96193123 - samples/sec: 27.55 - lr: 0.050000\n",
      "2021-06-20 21:46:23,451 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:46:23,451 EPOCH 29 done: loss 4.9619 - lr 0.0500000\n",
      "2021-06-20 21:46:23,780 DEV : loss 4.733154296875 - score 0.9804\n",
      "2021-06-20 21:46:23,783 BAD EPOCHS (no improvement): 2\n",
      "2021-06-20 21:46:23,784 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:46:25,058 epoch 30 - iter 1/6 - loss 4.77612305 - samples/sec: 6.28 - lr: 0.050000\n",
      "2021-06-20 21:46:26,388 epoch 30 - iter 2/6 - loss 3.67330551 - samples/sec: 6.02 - lr: 0.050000\n",
      "2021-06-20 21:46:27,641 epoch 30 - iter 3/6 - loss 3.02057266 - samples/sec: 6.39 - lr: 0.050000\n",
      "2021-06-20 21:46:28,716 epoch 30 - iter 4/6 - loss 3.42468166 - samples/sec: 7.45 - lr: 0.050000\n",
      "2021-06-20 21:46:29,913 epoch 30 - iter 5/6 - loss 3.38241959 - samples/sec: 6.69 - lr: 0.050000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 21:46:30,332 epoch 30 - iter 6/6 - loss 4.76271375 - samples/sec: 19.16 - lr: 0.050000\n",
      "2021-06-20 21:46:30,333 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:46:30,334 EPOCH 30 done: loss 4.7627 - lr 0.0500000\n",
      "2021-06-20 21:46:30,727 DEV : loss 3.1699676513671875 - score 0.9891\n",
      "2021-06-20 21:46:30,730 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-06-20 21:46:31,037 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:46:32,184 epoch 31 - iter 1/6 - loss 2.58766174 - samples/sec: 6.98 - lr: 0.050000\n",
      "2021-06-20 21:46:33,564 epoch 31 - iter 2/6 - loss 3.73662567 - samples/sec: 5.80 - lr: 0.050000\n",
      "2021-06-20 21:46:34,710 epoch 31 - iter 3/6 - loss 3.95170339 - samples/sec: 7.00 - lr: 0.050000\n",
      "2021-06-20 21:46:36,392 epoch 31 - iter 4/6 - loss 3.56549263 - samples/sec: 4.76 - lr: 0.050000\n",
      "2021-06-20 21:46:37,871 epoch 31 - iter 5/6 - loss 3.44622345 - samples/sec: 5.41 - lr: 0.050000\n",
      "2021-06-20 21:46:38,249 epoch 31 - iter 6/6 - loss 3.40243149 - samples/sec: 21.20 - lr: 0.050000\n",
      "2021-06-20 21:46:38,251 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:46:38,252 EPOCH 31 done: loss 3.4024 - lr 0.0500000\n",
      "2021-06-20 21:46:38,643 DEV : loss 3.8640594482421875 - score 0.9847\n",
      "2021-06-20 21:46:38,646 BAD EPOCHS (no improvement): 1\n",
      "2021-06-20 21:46:38,647 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:46:39,889 epoch 32 - iter 1/6 - loss 1.77731323 - samples/sec: 6.45 - lr: 0.050000\n",
      "2021-06-20 21:46:41,375 epoch 32 - iter 2/6 - loss 2.13545227 - samples/sec: 5.39 - lr: 0.050000\n",
      "2021-06-20 21:46:42,790 epoch 32 - iter 3/6 - loss 2.92721049 - samples/sec: 5.66 - lr: 0.050000\n",
      "2021-06-20 21:46:44,064 epoch 32 - iter 4/6 - loss 2.99409866 - samples/sec: 6.29 - lr: 0.050000\n",
      "2021-06-20 21:46:44,978 epoch 32 - iter 5/6 - loss 3.52076874 - samples/sec: 8.76 - lr: 0.050000\n",
      "2021-06-20 21:46:45,230 epoch 32 - iter 6/6 - loss 3.47645442 - samples/sec: 31.89 - lr: 0.050000\n",
      "2021-06-20 21:46:45,231 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:46:45,231 EPOCH 32 done: loss 3.4765 - lr 0.0500000\n",
      "2021-06-20 21:46:45,521 DEV : loss 3.310638427734375 - score 0.9891\n",
      "2021-06-20 21:46:45,523 BAD EPOCHS (no improvement): 2\n",
      "2021-06-20 21:46:45,525 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:46:46,786 epoch 33 - iter 1/6 - loss 4.17811584 - samples/sec: 6.35 - lr: 0.050000\n",
      "2021-06-20 21:46:47,844 epoch 33 - iter 2/6 - loss 3.55644608 - samples/sec: 7.57 - lr: 0.050000\n",
      "2021-06-20 21:46:48,768 epoch 33 - iter 3/6 - loss 3.62411753 - samples/sec: 8.66 - lr: 0.050000\n",
      "2021-06-20 21:46:49,913 epoch 33 - iter 4/6 - loss 4.07551003 - samples/sec: 7.00 - lr: 0.050000\n",
      "2021-06-20 21:46:51,012 epoch 33 - iter 5/6 - loss 4.05266876 - samples/sec: 7.28 - lr: 0.050000\n",
      "2021-06-20 21:46:51,292 epoch 33 - iter 6/6 - loss 5.10085678 - samples/sec: 28.63 - lr: 0.050000\n",
      "2021-06-20 21:46:51,293 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:46:51,294 EPOCH 33 done: loss 5.1009 - lr 0.0500000\n",
      "2021-06-20 21:46:51,587 DEV : loss 3.371734619140625 - score 0.9847\n",
      "2021-06-20 21:46:51,589 BAD EPOCHS (no improvement): 3\n",
      "2021-06-20 21:46:51,591 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:46:52,671 epoch 34 - iter 1/6 - loss 2.96089554 - samples/sec: 7.42 - lr: 0.050000\n",
      "2021-06-20 21:46:53,896 epoch 34 - iter 2/6 - loss 3.46332359 - samples/sec: 6.54 - lr: 0.050000\n",
      "2021-06-20 21:46:54,886 epoch 34 - iter 3/6 - loss 3.48210017 - samples/sec: 8.09 - lr: 0.050000\n",
      "2021-06-20 21:46:56,065 epoch 34 - iter 4/6 - loss 3.25521564 - samples/sec: 6.79 - lr: 0.050000\n",
      "2021-06-20 21:46:57,169 epoch 34 - iter 5/6 - loss 3.45086899 - samples/sec: 7.25 - lr: 0.050000\n",
      "2021-06-20 21:46:57,419 epoch 34 - iter 6/6 - loss 3.16499011 - samples/sec: 32.07 - lr: 0.050000\n",
      "2021-06-20 21:46:57,420 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:46:57,421 EPOCH 34 done: loss 3.1650 - lr 0.0500000\n",
      "2021-06-20 21:46:57,720 DEV : loss 4.4979095458984375 - score 0.9826\n",
      "Epoch    34: reducing learning rate of group 0 to 2.5000e-02.\n",
      "2021-06-20 21:46:57,723 BAD EPOCHS (no improvement): 4\n",
      "2021-06-20 21:46:57,724 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:46:58,651 epoch 35 - iter 1/6 - loss 3.88561249 - samples/sec: 8.65 - lr: 0.025000\n",
      "2021-06-20 21:46:59,633 epoch 35 - iter 2/6 - loss 3.22985458 - samples/sec: 8.15 - lr: 0.025000\n",
      "2021-06-20 21:47:00,827 epoch 35 - iter 3/6 - loss 2.96009318 - samples/sec: 6.71 - lr: 0.025000\n",
      "2021-06-20 21:47:02,052 epoch 35 - iter 4/6 - loss 3.08469582 - samples/sec: 6.53 - lr: 0.025000\n",
      "2021-06-20 21:47:03,049 epoch 35 - iter 5/6 - loss 3.46814117 - samples/sec: 8.03 - lr: 0.025000\n",
      "2021-06-20 21:47:03,382 epoch 35 - iter 6/6 - loss 3.01523972 - samples/sec: 24.12 - lr: 0.025000\n",
      "2021-06-20 21:47:03,383 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:47:03,383 EPOCH 35 done: loss 3.0152 - lr 0.0250000\n",
      "2021-06-20 21:47:03,675 DEV : loss 2.912567138671875 - score 0.9891\n",
      "2021-06-20 21:47:03,677 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-06-20 21:47:03,905 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:47:05,648 epoch 36 - iter 1/6 - loss 2.18380737 - samples/sec: 4.59 - lr: 0.025000\n",
      "2021-06-20 21:47:06,782 epoch 36 - iter 2/6 - loss 3.16108704 - samples/sec: 7.07 - lr: 0.025000\n",
      "2021-06-20 21:47:07,905 epoch 36 - iter 3/6 - loss 2.74364980 - samples/sec: 7.12 - lr: 0.025000\n",
      "2021-06-20 21:47:09,153 epoch 36 - iter 4/6 - loss 2.64620209 - samples/sec: 6.42 - lr: 0.025000\n",
      "2021-06-20 21:47:10,084 epoch 36 - iter 5/6 - loss 2.80135193 - samples/sec: 8.60 - lr: 0.025000\n",
      "2021-06-20 21:47:10,341 epoch 36 - iter 6/6 - loss 2.96448517 - samples/sec: 31.25 - lr: 0.025000\n",
      "2021-06-20 21:47:10,342 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:47:10,342 EPOCH 36 done: loss 2.9645 - lr 0.0250000\n",
      "2021-06-20 21:47:10,633 DEV : loss 3.4001312255859375 - score 0.9847\n",
      "2021-06-20 21:47:10,636 BAD EPOCHS (no improvement): 1\n",
      "2021-06-20 21:47:10,637 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:47:11,788 epoch 37 - iter 1/6 - loss 3.99349976 - samples/sec: 6.96 - lr: 0.025000\n",
      "2021-06-20 21:47:12,777 epoch 37 - iter 2/6 - loss 3.40663910 - samples/sec: 8.09 - lr: 0.025000\n",
      "2021-06-20 21:47:14,037 epoch 37 - iter 3/6 - loss 3.49721781 - samples/sec: 6.35 - lr: 0.025000\n",
      "2021-06-20 21:47:14,977 epoch 37 - iter 4/6 - loss 3.55158043 - samples/sec: 8.52 - lr: 0.025000\n",
      "2021-06-20 21:47:15,847 epoch 37 - iter 5/6 - loss 3.31347046 - samples/sec: 9.21 - lr: 0.025000\n",
      "2021-06-20 21:47:16,078 epoch 37 - iter 6/6 - loss 2.89447530 - samples/sec: 34.77 - lr: 0.025000\n",
      "2021-06-20 21:47:16,079 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:47:16,080 EPOCH 37 done: loss 2.8945 - lr 0.0250000\n",
      "2021-06-20 21:47:16,370 DEV : loss 2.945465087890625 - score 0.9891\n",
      "2021-06-20 21:47:16,372 BAD EPOCHS (no improvement): 2\n",
      "2021-06-20 21:47:16,373 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:47:17,418 epoch 38 - iter 1/6 - loss 2.67721558 - samples/sec: 7.67 - lr: 0.025000\n",
      "2021-06-20 21:47:18,605 epoch 38 - iter 2/6 - loss 2.84295273 - samples/sec: 6.74 - lr: 0.025000\n",
      "2021-06-20 21:47:19,774 epoch 38 - iter 3/6 - loss 2.31752523 - samples/sec: 6.85 - lr: 0.025000\n",
      "2021-06-20 21:47:20,685 epoch 38 - iter 4/6 - loss 2.18251991 - samples/sec: 8.79 - lr: 0.025000\n",
      "2021-06-20 21:47:21,909 epoch 38 - iter 5/6 - loss 2.86720276 - samples/sec: 6.54 - lr: 0.025000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 21:47:22,192 epoch 38 - iter 6/6 - loss 2.65050507 - samples/sec: 28.36 - lr: 0.025000\n",
      "2021-06-20 21:47:22,193 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:47:22,193 EPOCH 38 done: loss 2.6505 - lr 0.0250000\n",
      "2021-06-20 21:47:22,495 DEV : loss 3.3042449951171875 - score 0.9891\n",
      "2021-06-20 21:47:22,498 BAD EPOCHS (no improvement): 3\n",
      "2021-06-20 21:47:22,499 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:47:23,689 epoch 39 - iter 1/6 - loss 2.75505066 - samples/sec: 6.73 - lr: 0.025000\n",
      "2021-06-20 21:47:24,686 epoch 39 - iter 2/6 - loss 3.60279083 - samples/sec: 8.03 - lr: 0.025000\n",
      "2021-06-20 21:47:25,723 epoch 39 - iter 3/6 - loss 3.09437815 - samples/sec: 7.72 - lr: 0.025000\n",
      "2021-06-20 21:47:26,855 epoch 39 - iter 4/6 - loss 2.63043404 - samples/sec: 7.07 - lr: 0.025000\n",
      "2021-06-20 21:47:28,071 epoch 39 - iter 5/6 - loss 2.73184204 - samples/sec: 6.58 - lr: 0.025000\n",
      "2021-06-20 21:47:28,363 epoch 39 - iter 6/6 - loss 3.36772156 - samples/sec: 27.46 - lr: 0.025000\n",
      "2021-06-20 21:47:28,364 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:47:28,365 EPOCH 39 done: loss 3.3677 - lr 0.0250000\n",
      "2021-06-20 21:47:28,654 DEV : loss 4.26470947265625 - score 0.9869\n",
      "Epoch    39: reducing learning rate of group 0 to 1.2500e-02.\n",
      "2021-06-20 21:47:28,657 BAD EPOCHS (no improvement): 4\n",
      "2021-06-20 21:47:28,658 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:47:29,625 epoch 40 - iter 1/6 - loss 2.35514832 - samples/sec: 8.29 - lr: 0.012500\n",
      "2021-06-20 21:47:30,747 epoch 40 - iter 2/6 - loss 2.58255959 - samples/sec: 7.13 - lr: 0.012500\n",
      "2021-06-20 21:47:31,924 epoch 40 - iter 3/6 - loss 2.63531113 - samples/sec: 6.80 - lr: 0.012500\n",
      "2021-06-20 21:47:32,926 epoch 40 - iter 4/6 - loss 2.93548107 - samples/sec: 7.99 - lr: 0.012500\n",
      "2021-06-20 21:47:34,158 epoch 40 - iter 5/6 - loss 3.21443710 - samples/sec: 6.49 - lr: 0.012500\n",
      "2021-06-20 21:47:34,436 epoch 40 - iter 6/6 - loss 3.16986783 - samples/sec: 28.86 - lr: 0.012500\n",
      "2021-06-20 21:47:34,437 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:47:34,438 EPOCH 40 done: loss 3.1699 - lr 0.0125000\n",
      "2021-06-20 21:47:34,734 DEV : loss 3.8215484619140625 - score 0.9869\n",
      "2021-06-20 21:47:34,736 BAD EPOCHS (no improvement): 1\n",
      "2021-06-20 21:47:34,737 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:47:35,742 epoch 41 - iter 1/6 - loss 4.35225677 - samples/sec: 7.97 - lr: 0.012500\n",
      "2021-06-20 21:47:36,806 epoch 41 - iter 2/6 - loss 3.46826553 - samples/sec: 7.53 - lr: 0.012500\n",
      "2021-06-20 21:47:37,845 epoch 41 - iter 3/6 - loss 2.87284724 - samples/sec: 7.71 - lr: 0.012500\n",
      "2021-06-20 21:47:38,972 epoch 41 - iter 4/6 - loss 2.84856129 - samples/sec: 7.10 - lr: 0.012500\n",
      "2021-06-20 21:47:40,214 epoch 41 - iter 5/6 - loss 2.68337021 - samples/sec: 6.44 - lr: 0.012500\n",
      "2021-06-20 21:47:40,506 epoch 41 - iter 6/6 - loss 2.33595467 - samples/sec: 27.48 - lr: 0.012500\n",
      "2021-06-20 21:47:40,507 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:47:40,508 EPOCH 41 done: loss 2.3360 - lr 0.0125000\n",
      "2021-06-20 21:47:40,806 DEV : loss 3.8094635009765625 - score 0.9891\n",
      "2021-06-20 21:47:40,808 BAD EPOCHS (no improvement): 2\n",
      "2021-06-20 21:47:40,809 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:47:42,220 epoch 42 - iter 1/6 - loss 2.59796143 - samples/sec: 5.68 - lr: 0.012500\n",
      "2021-06-20 21:47:43,082 epoch 42 - iter 2/6 - loss 2.40274239 - samples/sec: 9.29 - lr: 0.012500\n",
      "2021-06-20 21:47:44,093 epoch 42 - iter 3/6 - loss 2.56765366 - samples/sec: 7.91 - lr: 0.012500\n",
      "2021-06-20 21:47:45,334 epoch 42 - iter 4/6 - loss 3.01086521 - samples/sec: 6.45 - lr: 0.012500\n",
      "2021-06-20 21:47:46,394 epoch 42 - iter 5/6 - loss 2.87725449 - samples/sec: 7.56 - lr: 0.012500\n",
      "2021-06-20 21:47:46,667 epoch 42 - iter 6/6 - loss 2.58468310 - samples/sec: 29.36 - lr: 0.012500\n",
      "2021-06-20 21:47:46,668 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:47:46,669 EPOCH 42 done: loss 2.5847 - lr 0.0125000\n",
      "2021-06-20 21:47:46,965 DEV : loss 3.496185302734375 - score 0.9869\n",
      "2021-06-20 21:47:46,967 BAD EPOCHS (no improvement): 3\n",
      "2021-06-20 21:47:46,968 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:47:48,214 epoch 43 - iter 1/6 - loss 2.21509552 - samples/sec: 6.43 - lr: 0.012500\n",
      "2021-06-20 21:47:49,207 epoch 43 - iter 2/6 - loss 2.35686302 - samples/sec: 8.06 - lr: 0.012500\n",
      "2021-06-20 21:47:50,188 epoch 43 - iter 3/6 - loss 1.96374893 - samples/sec: 8.17 - lr: 0.012500\n",
      "2021-06-20 21:47:51,098 epoch 43 - iter 4/6 - loss 1.90282917 - samples/sec: 8.80 - lr: 0.012500\n",
      "2021-06-20 21:47:52,054 epoch 43 - iter 5/6 - loss 2.03416824 - samples/sec: 8.38 - lr: 0.012500\n",
      "2021-06-20 21:47:52,388 epoch 43 - iter 6/6 - loss 1.78646914 - samples/sec: 23.97 - lr: 0.012500\n",
      "2021-06-20 21:47:52,389 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:47:52,390 EPOCH 43 done: loss 1.7865 - lr 0.0125000\n",
      "2021-06-20 21:47:52,685 DEV : loss 3.700164794921875 - score 0.9891\n",
      "Epoch    43: reducing learning rate of group 0 to 6.2500e-03.\n",
      "2021-06-20 21:47:52,687 BAD EPOCHS (no improvement): 4\n",
      "2021-06-20 21:47:52,688 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:47:53,785 epoch 44 - iter 1/6 - loss 2.14596558 - samples/sec: 7.30 - lr: 0.006250\n",
      "2021-06-20 21:47:54,911 epoch 44 - iter 2/6 - loss 2.84207535 - samples/sec: 7.11 - lr: 0.006250\n",
      "2021-06-20 21:47:55,835 epoch 44 - iter 3/6 - loss 2.49128977 - samples/sec: 8.67 - lr: 0.006250\n",
      "2021-06-20 21:47:57,021 epoch 44 - iter 4/6 - loss 2.83464241 - samples/sec: 6.75 - lr: 0.006250\n",
      "2021-06-20 21:47:58,303 epoch 44 - iter 5/6 - loss 2.88933411 - samples/sec: 6.25 - lr: 0.006250\n",
      "2021-06-20 21:47:58,575 epoch 44 - iter 6/6 - loss 2.66573334 - samples/sec: 29.49 - lr: 0.006250\n",
      "2021-06-20 21:47:58,576 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:47:58,577 EPOCH 44 done: loss 2.6657 - lr 0.0062500\n",
      "2021-06-20 21:47:58,865 DEV : loss 3.634307861328125 - score 0.9847\n",
      "2021-06-20 21:47:58,867 BAD EPOCHS (no improvement): 1\n",
      "2021-06-20 21:47:58,869 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:48:00,016 epoch 45 - iter 1/6 - loss 1.84049225 - samples/sec: 6.98 - lr: 0.006250\n",
      "2021-06-20 21:48:01,257 epoch 45 - iter 2/6 - loss 2.37397003 - samples/sec: 6.45 - lr: 0.006250\n",
      "2021-06-20 21:48:02,310 epoch 45 - iter 3/6 - loss 3.01632182 - samples/sec: 7.61 - lr: 0.006250\n",
      "2021-06-20 21:48:03,195 epoch 45 - iter 4/6 - loss 3.22423553 - samples/sec: 9.04 - lr: 0.006250\n",
      "2021-06-20 21:48:04,149 epoch 45 - iter 5/6 - loss 2.96525116 - samples/sec: 8.40 - lr: 0.006250\n",
      "2021-06-20 21:48:04,504 epoch 45 - iter 6/6 - loss 2.85727310 - samples/sec: 22.57 - lr: 0.006250\n",
      "2021-06-20 21:48:04,505 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:48:04,506 EPOCH 45 done: loss 2.8573 - lr 0.0062500\n",
      "2021-06-20 21:48:04,799 DEV : loss 3.3703460693359375 - score 0.9869\n",
      "2021-06-20 21:48:04,801 BAD EPOCHS (no improvement): 2\n",
      "2021-06-20 21:48:04,803 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:48:06,057 epoch 46 - iter 1/6 - loss 3.26860046 - samples/sec: 6.39 - lr: 0.006250\n",
      "2021-06-20 21:48:06,970 epoch 46 - iter 2/6 - loss 2.72280121 - samples/sec: 8.77 - lr: 0.006250\n",
      "2021-06-20 21:48:08,064 epoch 46 - iter 3/6 - loss 2.66588593 - samples/sec: 7.32 - lr: 0.006250\n",
      "2021-06-20 21:48:09,186 epoch 46 - iter 4/6 - loss 2.82732582 - samples/sec: 7.13 - lr: 0.006250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 21:48:10,359 epoch 46 - iter 5/6 - loss 2.62784424 - samples/sec: 6.83 - lr: 0.006250\n",
      "2021-06-20 21:48:10,639 epoch 46 - iter 6/6 - loss 2.46308390 - samples/sec: 28.65 - lr: 0.006250\n",
      "2021-06-20 21:48:10,640 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:48:10,641 EPOCH 46 done: loss 2.4631 - lr 0.0062500\n",
      "2021-06-20 21:48:10,932 DEV : loss 3.3594818115234375 - score 0.9869\n",
      "2021-06-20 21:48:10,934 BAD EPOCHS (no improvement): 3\n",
      "2021-06-20 21:48:10,935 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:48:12,169 epoch 47 - iter 1/6 - loss 2.92898560 - samples/sec: 6.49 - lr: 0.006250\n",
      "2021-06-20 21:48:13,137 epoch 47 - iter 2/6 - loss 2.90645981 - samples/sec: 8.28 - lr: 0.006250\n",
      "2021-06-20 21:48:14,119 epoch 47 - iter 3/6 - loss 3.05461884 - samples/sec: 8.15 - lr: 0.006250\n",
      "2021-06-20 21:48:15,279 epoch 47 - iter 4/6 - loss 3.10236549 - samples/sec: 6.90 - lr: 0.006250\n",
      "2021-06-20 21:48:16,394 epoch 47 - iter 5/6 - loss 2.77922821 - samples/sec: 7.18 - lr: 0.006250\n",
      "2021-06-20 21:48:16,676 epoch 47 - iter 6/6 - loss 2.36169815 - samples/sec: 28.45 - lr: 0.006250\n",
      "2021-06-20 21:48:16,677 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:48:16,677 EPOCH 47 done: loss 2.3617 - lr 0.0062500\n",
      "2021-06-20 21:48:16,967 DEV : loss 3.527984619140625 - score 0.9891\n",
      "Epoch    47: reducing learning rate of group 0 to 3.1250e-03.\n",
      "2021-06-20 21:48:16,969 BAD EPOCHS (no improvement): 4\n",
      "2021-06-20 21:48:16,971 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:48:18,172 epoch 48 - iter 1/6 - loss 1.97725677 - samples/sec: 6.67 - lr: 0.003125\n",
      "2021-06-20 21:48:19,154 epoch 48 - iter 2/6 - loss 1.65457153 - samples/sec: 8.15 - lr: 0.003125\n",
      "2021-06-20 21:48:20,041 epoch 48 - iter 3/6 - loss 1.67768097 - samples/sec: 9.02 - lr: 0.003125\n",
      "2021-06-20 21:48:21,131 epoch 48 - iter 4/6 - loss 2.22300529 - samples/sec: 7.35 - lr: 0.003125\n",
      "2021-06-20 21:48:22,366 epoch 48 - iter 5/6 - loss 2.30467072 - samples/sec: 6.48 - lr: 0.003125\n",
      "2021-06-20 21:48:22,631 epoch 48 - iter 6/6 - loss 2.33877182 - samples/sec: 30.22 - lr: 0.003125\n",
      "2021-06-20 21:48:22,632 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:48:22,633 EPOCH 48 done: loss 2.3388 - lr 0.0031250\n",
      "2021-06-20 21:48:22,934 DEV : loss 3.466766357421875 - score 0.9891\n",
      "2021-06-20 21:48:22,936 BAD EPOCHS (no improvement): 1\n",
      "2021-06-20 21:48:22,937 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:48:23,981 epoch 49 - iter 1/6 - loss 1.92218399 - samples/sec: 7.67 - lr: 0.003125\n",
      "2021-06-20 21:48:25,384 epoch 49 - iter 2/6 - loss 2.05510521 - samples/sec: 5.70 - lr: 0.003125\n",
      "2021-06-20 21:48:26,834 epoch 49 - iter 3/6 - loss 2.51436996 - samples/sec: 5.52 - lr: 0.003125\n",
      "2021-06-20 21:48:27,954 epoch 49 - iter 4/6 - loss 2.60433102 - samples/sec: 7.15 - lr: 0.003125\n",
      "2021-06-20 21:48:28,945 epoch 49 - iter 5/6 - loss 2.55383072 - samples/sec: 8.08 - lr: 0.003125\n",
      "2021-06-20 21:48:29,253 epoch 49 - iter 6/6 - loss 2.39265760 - samples/sec: 26.03 - lr: 0.003125\n",
      "2021-06-20 21:48:29,254 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:48:29,255 EPOCH 49 done: loss 2.3927 - lr 0.0031250\n",
      "2021-06-20 21:48:29,547 DEV : loss 3.4288177490234375 - score 0.9869\n",
      "2021-06-20 21:48:29,549 BAD EPOCHS (no improvement): 2\n",
      "2021-06-20 21:48:29,550 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:48:30,646 epoch 50 - iter 1/6 - loss 2.72228241 - samples/sec: 7.31 - lr: 0.003125\n",
      "2021-06-20 21:48:31,879 epoch 50 - iter 2/6 - loss 2.45585632 - samples/sec: 6.49 - lr: 0.003125\n",
      "2021-06-20 21:48:32,984 epoch 50 - iter 3/6 - loss 2.66628265 - samples/sec: 7.25 - lr: 0.003125\n",
      "2021-06-20 21:48:34,144 epoch 50 - iter 4/6 - loss 2.85364532 - samples/sec: 6.90 - lr: 0.003125\n",
      "2021-06-20 21:48:35,104 epoch 50 - iter 5/6 - loss 2.62144470 - samples/sec: 8.34 - lr: 0.003125\n",
      "2021-06-20 21:48:35,298 epoch 50 - iter 6/6 - loss 2.25276947 - samples/sec: 41.43 - lr: 0.003125\n",
      "2021-06-20 21:48:35,299 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:48:35,299 EPOCH 50 done: loss 2.2528 - lr 0.0031250\n",
      "2021-06-20 21:48:35,595 DEV : loss 3.3992919921875 - score 0.9847\n",
      "2021-06-20 21:48:35,597 BAD EPOCHS (no improvement): 3\n",
      "2021-06-20 21:48:35,598 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:48:36,639 epoch 51 - iter 1/6 - loss 2.98417664 - samples/sec: 7.69 - lr: 0.003125\n",
      "2021-06-20 21:48:37,627 epoch 51 - iter 2/6 - loss 2.72592545 - samples/sec: 8.10 - lr: 0.003125\n",
      "2021-06-20 21:48:39,083 epoch 51 - iter 3/6 - loss 2.56476084 - samples/sec: 5.50 - lr: 0.003125\n",
      "2021-06-20 21:48:40,189 epoch 51 - iter 4/6 - loss 2.34652328 - samples/sec: 7.24 - lr: 0.003125\n",
      "2021-06-20 21:48:41,468 epoch 51 - iter 5/6 - loss 2.56700134 - samples/sec: 6.26 - lr: 0.003125\n",
      "2021-06-20 21:48:41,777 epoch 51 - iter 6/6 - loss 2.34872182 - samples/sec: 25.96 - lr: 0.003125\n",
      "2021-06-20 21:48:41,778 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:48:41,779 EPOCH 51 done: loss 2.3487 - lr 0.0031250\n",
      "2021-06-20 21:48:42,140 DEV : loss 3.449951171875 - score 0.9869\n",
      "Epoch    51: reducing learning rate of group 0 to 1.5625e-03.\n",
      "2021-06-20 21:48:42,143 BAD EPOCHS (no improvement): 4\n",
      "2021-06-20 21:48:42,144 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:48:43,565 epoch 52 - iter 1/6 - loss 3.95683289 - samples/sec: 5.63 - lr: 0.001563\n",
      "2021-06-20 21:48:44,780 epoch 52 - iter 2/6 - loss 2.55554199 - samples/sec: 6.59 - lr: 0.001563\n",
      "2021-06-20 21:48:46,144 epoch 52 - iter 3/6 - loss 2.30961863 - samples/sec: 5.87 - lr: 0.001563\n",
      "2021-06-20 21:48:47,455 epoch 52 - iter 4/6 - loss 2.52766418 - samples/sec: 6.11 - lr: 0.001563\n",
      "2021-06-20 21:48:48,400 epoch 52 - iter 5/6 - loss 2.52462616 - samples/sec: 8.47 - lr: 0.001563\n",
      "2021-06-20 21:48:48,598 epoch 52 - iter 6/6 - loss 2.11714045 - samples/sec: 40.56 - lr: 0.001563\n",
      "2021-06-20 21:48:48,599 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:48:48,600 EPOCH 52 done: loss 2.1171 - lr 0.0015625\n",
      "2021-06-20 21:48:48,952 DEV : loss 3.3996429443359375 - score 0.9869\n",
      "2021-06-20 21:48:48,954 BAD EPOCHS (no improvement): 1\n",
      "2021-06-20 21:48:48,955 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:48:50,269 epoch 53 - iter 1/6 - loss 2.51591492 - samples/sec: 6.09 - lr: 0.001563\n",
      "2021-06-20 21:48:51,309 epoch 53 - iter 2/6 - loss 3.69594193 - samples/sec: 7.70 - lr: 0.001563\n",
      "2021-06-20 21:48:52,754 epoch 53 - iter 3/6 - loss 3.71111298 - samples/sec: 5.54 - lr: 0.001563\n",
      "2021-06-20 21:48:53,876 epoch 53 - iter 4/6 - loss 3.16382408 - samples/sec: 7.14 - lr: 0.001563\n",
      "2021-06-20 21:48:55,042 epoch 53 - iter 5/6 - loss 3.13059082 - samples/sec: 6.87 - lr: 0.001563\n",
      "2021-06-20 21:48:55,297 epoch 53 - iter 6/6 - loss 2.64910889 - samples/sec: 31.52 - lr: 0.001563\n",
      "2021-06-20 21:48:55,298 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:48:55,298 EPOCH 53 done: loss 2.6491 - lr 0.0015625\n",
      "2021-06-20 21:48:55,631 DEV : loss 3.423828125 - score 0.9869\n",
      "2021-06-20 21:48:55,633 BAD EPOCHS (no improvement): 2\n",
      "2021-06-20 21:48:55,634 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:48:57,041 epoch 54 - iter 1/6 - loss 3.16037750 - samples/sec: 5.69 - lr: 0.001563\n",
      "2021-06-20 21:48:58,103 epoch 54 - iter 2/6 - loss 3.30163574 - samples/sec: 7.54 - lr: 0.001563\n",
      "2021-06-20 21:48:59,267 epoch 54 - iter 3/6 - loss 3.59574636 - samples/sec: 6.88 - lr: 0.001563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 21:49:00,242 epoch 54 - iter 4/6 - loss 3.25652504 - samples/sec: 8.21 - lr: 0.001563\n",
      "2021-06-20 21:49:01,185 epoch 54 - iter 5/6 - loss 3.01940460 - samples/sec: 8.49 - lr: 0.001563\n",
      "2021-06-20 21:49:01,463 epoch 54 - iter 6/6 - loss 2.69608180 - samples/sec: 28.89 - lr: 0.001563\n",
      "2021-06-20 21:49:01,464 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:49:01,464 EPOCH 54 done: loss 2.6961 - lr 0.0015625\n",
      "2021-06-20 21:49:01,759 DEV : loss 3.32586669921875 - score 0.9869\n",
      "2021-06-20 21:49:01,761 BAD EPOCHS (no improvement): 3\n",
      "2021-06-20 21:49:01,762 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:49:02,695 epoch 55 - iter 1/6 - loss 1.96430969 - samples/sec: 8.58 - lr: 0.001563\n",
      "2021-06-20 21:49:03,658 epoch 55 - iter 2/6 - loss 1.77180862 - samples/sec: 8.31 - lr: 0.001563\n",
      "2021-06-20 21:49:04,885 epoch 55 - iter 3/6 - loss 2.48303986 - samples/sec: 6.53 - lr: 0.001563\n",
      "2021-06-20 21:49:05,888 epoch 55 - iter 4/6 - loss 2.34271431 - samples/sec: 7.98 - lr: 0.001563\n",
      "2021-06-20 21:49:07,063 epoch 55 - iter 5/6 - loss 2.23070984 - samples/sec: 6.81 - lr: 0.001563\n",
      "2021-06-20 21:49:07,327 epoch 55 - iter 6/6 - loss 2.19618479 - samples/sec: 30.51 - lr: 0.001563\n",
      "2021-06-20 21:49:07,327 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:49:07,328 EPOCH 55 done: loss 2.1962 - lr 0.0015625\n",
      "2021-06-20 21:49:07,665 DEV : loss 3.313079833984375 - score 0.9847\n",
      "Epoch    55: reducing learning rate of group 0 to 7.8125e-04.\n",
      "2021-06-20 21:49:07,667 BAD EPOCHS (no improvement): 4\n",
      "2021-06-20 21:49:07,668 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:49:08,915 epoch 56 - iter 1/6 - loss 2.40152740 - samples/sec: 6.43 - lr: 0.000781\n",
      "2021-06-20 21:49:09,848 epoch 56 - iter 2/6 - loss 1.98741913 - samples/sec: 8.58 - lr: 0.000781\n",
      "2021-06-20 21:49:10,885 epoch 56 - iter 3/6 - loss 2.84838613 - samples/sec: 7.72 - lr: 0.000781\n",
      "2021-06-20 21:49:11,879 epoch 56 - iter 4/6 - loss 2.84225655 - samples/sec: 8.05 - lr: 0.000781\n",
      "2021-06-20 21:49:12,720 epoch 56 - iter 5/6 - loss 2.76174927 - samples/sec: 9.52 - lr: 0.000781\n",
      "2021-06-20 21:49:12,999 epoch 56 - iter 6/6 - loss 2.46377055 - samples/sec: 28.83 - lr: 0.000781\n",
      "2021-06-20 21:49:12,999 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:49:13,000 EPOCH 56 done: loss 2.4638 - lr 0.0007813\n",
      "2021-06-20 21:49:13,296 DEV : loss 3.2844696044921875 - score 0.9847\n",
      "2021-06-20 21:49:13,300 BAD EPOCHS (no improvement): 1\n",
      "2021-06-20 21:49:13,301 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:49:14,275 epoch 57 - iter 1/6 - loss 3.04736710 - samples/sec: 8.22 - lr: 0.000781\n",
      "2021-06-20 21:49:15,291 epoch 57 - iter 2/6 - loss 4.01434135 - samples/sec: 7.88 - lr: 0.000781\n",
      "2021-06-20 21:49:16,472 epoch 57 - iter 3/6 - loss 3.73083623 - samples/sec: 6.78 - lr: 0.000781\n",
      "2021-06-20 21:49:17,578 epoch 57 - iter 4/6 - loss 3.12942219 - samples/sec: 7.23 - lr: 0.000781\n",
      "2021-06-20 21:49:18,805 epoch 57 - iter 5/6 - loss 3.08001938 - samples/sec: 6.53 - lr: 0.000781\n",
      "2021-06-20 21:49:19,052 epoch 57 - iter 6/6 - loss 2.77567736 - samples/sec: 32.46 - lr: 0.000781\n",
      "2021-06-20 21:49:19,053 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:49:19,053 EPOCH 57 done: loss 2.7757 - lr 0.0007813\n",
      "2021-06-20 21:49:19,349 DEV : loss 3.2893218994140625 - score 0.9847\n",
      "2021-06-20 21:49:19,352 BAD EPOCHS (no improvement): 2\n",
      "2021-06-20 21:49:19,353 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:49:20,591 epoch 58 - iter 1/6 - loss 2.31784058 - samples/sec: 6.47 - lr: 0.000781\n",
      "2021-06-20 21:49:21,648 epoch 58 - iter 2/6 - loss 2.07661438 - samples/sec: 7.57 - lr: 0.000781\n",
      "2021-06-20 21:49:22,622 epoch 58 - iter 3/6 - loss 2.05971527 - samples/sec: 8.22 - lr: 0.000781\n",
      "2021-06-20 21:49:23,716 epoch 58 - iter 4/6 - loss 2.27981567 - samples/sec: 7.32 - lr: 0.000781\n",
      "2021-06-20 21:49:24,888 epoch 58 - iter 5/6 - loss 2.41607666 - samples/sec: 6.83 - lr: 0.000781\n",
      "2021-06-20 21:49:25,137 epoch 58 - iter 6/6 - loss 2.09785970 - samples/sec: 32.23 - lr: 0.000781\n",
      "2021-06-20 21:49:25,138 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:49:25,139 EPOCH 58 done: loss 2.0979 - lr 0.0007813\n",
      "2021-06-20 21:49:25,430 DEV : loss 3.2688140869140625 - score 0.9847\n",
      "2021-06-20 21:49:25,432 BAD EPOCHS (no improvement): 3\n",
      "2021-06-20 21:49:25,434 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:49:26,616 epoch 59 - iter 1/6 - loss 2.33341980 - samples/sec: 6.78 - lr: 0.000781\n",
      "2021-06-20 21:49:28,010 epoch 59 - iter 2/6 - loss 2.42540741 - samples/sec: 5.74 - lr: 0.000781\n",
      "2021-06-20 21:49:29,119 epoch 59 - iter 3/6 - loss 2.64807892 - samples/sec: 7.22 - lr: 0.000781\n",
      "2021-06-20 21:49:30,308 epoch 59 - iter 4/6 - loss 2.87331200 - samples/sec: 6.73 - lr: 0.000781\n",
      "2021-06-20 21:49:31,738 epoch 59 - iter 5/6 - loss 2.77214050 - samples/sec: 5.60 - lr: 0.000781\n",
      "2021-06-20 21:49:31,945 epoch 59 - iter 6/6 - loss 2.34260813 - samples/sec: 38.93 - lr: 0.000781\n",
      "2021-06-20 21:49:31,945 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:49:31,946 EPOCH 59 done: loss 2.3426 - lr 0.0007813\n",
      "2021-06-20 21:49:32,244 DEV : loss 3.2901611328125 - score 0.9847\n",
      "Epoch    59: reducing learning rate of group 0 to 3.9063e-04.\n",
      "2021-06-20 21:49:32,246 BAD EPOCHS (no improvement): 4\n",
      "2021-06-20 21:49:32,247 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:49:33,618 epoch 60 - iter 1/6 - loss 2.35142517 - samples/sec: 5.84 - lr: 0.000391\n",
      "2021-06-20 21:49:34,820 epoch 60 - iter 2/6 - loss 2.72989273 - samples/sec: 6.66 - lr: 0.000391\n",
      "2021-06-20 21:49:35,899 epoch 60 - iter 3/6 - loss 2.57222239 - samples/sec: 7.42 - lr: 0.000391\n",
      "2021-06-20 21:49:36,925 epoch 60 - iter 4/6 - loss 2.79683685 - samples/sec: 7.80 - lr: 0.000391\n",
      "2021-06-20 21:49:38,009 epoch 60 - iter 5/6 - loss 2.42494812 - samples/sec: 7.39 - lr: 0.000391\n",
      "2021-06-20 21:49:38,276 epoch 60 - iter 6/6 - loss 3.49481964 - samples/sec: 30.02 - lr: 0.000391\n",
      "2021-06-20 21:49:38,277 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:49:38,277 EPOCH 60 done: loss 3.4948 - lr 0.0003906\n",
      "2021-06-20 21:49:38,596 DEV : loss 3.278961181640625 - score 0.9869\n",
      "2021-06-20 21:49:38,598 BAD EPOCHS (no improvement): 1\n",
      "2021-06-20 21:49:38,599 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:49:39,847 epoch 61 - iter 1/6 - loss 2.65927887 - samples/sec: 6.41 - lr: 0.000391\n",
      "2021-06-20 21:49:41,012 epoch 61 - iter 2/6 - loss 2.36318970 - samples/sec: 6.88 - lr: 0.000391\n",
      "2021-06-20 21:49:42,062 epoch 61 - iter 3/6 - loss 2.26612345 - samples/sec: 7.62 - lr: 0.000391\n",
      "2021-06-20 21:49:43,054 epoch 61 - iter 4/6 - loss 2.21164513 - samples/sec: 8.07 - lr: 0.000391\n",
      "2021-06-20 21:49:43,962 epoch 61 - iter 5/6 - loss 2.32922821 - samples/sec: 8.82 - lr: 0.000391\n",
      "2021-06-20 21:49:44,217 epoch 61 - iter 6/6 - loss 2.68164444 - samples/sec: 31.42 - lr: 0.000391\n",
      "2021-06-20 21:49:44,218 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:49:44,219 EPOCH 61 done: loss 2.6816 - lr 0.0003906\n",
      "2021-06-20 21:49:44,536 DEV : loss 3.285736083984375 - score 0.9869\n",
      "2021-06-20 21:49:44,538 BAD EPOCHS (no improvement): 2\n",
      "2021-06-20 21:49:44,539 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:49:45,665 epoch 62 - iter 1/6 - loss 1.38745880 - samples/sec: 7.11 - lr: 0.000391\n",
      "2021-06-20 21:49:46,608 epoch 62 - iter 2/6 - loss 1.61395073 - samples/sec: 8.50 - lr: 0.000391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 21:49:47,801 epoch 62 - iter 3/6 - loss 1.93868128 - samples/sec: 6.71 - lr: 0.000391\n",
      "2021-06-20 21:49:49,031 epoch 62 - iter 4/6 - loss 1.95111370 - samples/sec: 6.51 - lr: 0.000391\n",
      "2021-06-20 21:49:50,087 epoch 62 - iter 5/6 - loss 2.11245651 - samples/sec: 7.58 - lr: 0.000391\n",
      "2021-06-20 21:49:50,363 epoch 62 - iter 6/6 - loss 1.96470579 - samples/sec: 29.08 - lr: 0.000391\n",
      "2021-06-20 21:49:50,364 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:49:50,364 EPOCH 62 done: loss 1.9647 - lr 0.0003906\n",
      "2021-06-20 21:49:50,652 DEV : loss 3.2808074951171875 - score 0.9869\n",
      "2021-06-20 21:49:50,654 BAD EPOCHS (no improvement): 3\n",
      "2021-06-20 21:49:50,655 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:49:51,845 epoch 63 - iter 1/6 - loss 2.08188629 - samples/sec: 6.73 - lr: 0.000391\n",
      "2021-06-20 21:49:52,962 epoch 63 - iter 2/6 - loss 1.76362991 - samples/sec: 7.17 - lr: 0.000391\n",
      "2021-06-20 21:49:53,860 epoch 63 - iter 3/6 - loss 1.87789408 - samples/sec: 8.91 - lr: 0.000391\n",
      "2021-06-20 21:49:55,081 epoch 63 - iter 4/6 - loss 2.41148186 - samples/sec: 6.56 - lr: 0.000391\n",
      "2021-06-20 21:49:56,071 epoch 63 - iter 5/6 - loss 2.46423645 - samples/sec: 8.09 - lr: 0.000391\n",
      "2021-06-20 21:49:56,357 epoch 63 - iter 6/6 - loss 2.10187022 - samples/sec: 27.97 - lr: 0.000391\n",
      "2021-06-20 21:49:56,358 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:49:56,359 EPOCH 63 done: loss 2.1019 - lr 0.0003906\n",
      "2021-06-20 21:49:56,649 DEV : loss 3.287445068359375 - score 0.9869\n",
      "Epoch    63: reducing learning rate of group 0 to 1.9531e-04.\n",
      "2021-06-20 21:49:56,651 BAD EPOCHS (no improvement): 4\n",
      "2021-06-20 21:49:56,652 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:49:57,641 epoch 64 - iter 1/6 - loss 2.83423615 - samples/sec: 8.10 - lr: 0.000195\n",
      "2021-06-20 21:49:58,839 epoch 64 - iter 2/6 - loss 2.59318161 - samples/sec: 6.69 - lr: 0.000195\n",
      "2021-06-20 21:49:59,841 epoch 64 - iter 3/6 - loss 2.90001678 - samples/sec: 7.99 - lr: 0.000195\n",
      "2021-06-20 21:50:00,948 epoch 64 - iter 4/6 - loss 2.80099678 - samples/sec: 7.23 - lr: 0.000195\n",
      "2021-06-20 21:50:02,169 epoch 64 - iter 5/6 - loss 2.74174805 - samples/sec: 6.56 - lr: 0.000195\n",
      "2021-06-20 21:50:02,408 epoch 64 - iter 6/6 - loss 3.02740479 - samples/sec: 33.69 - lr: 0.000195\n",
      "2021-06-20 21:50:02,408 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:50:02,409 EPOCH 64 done: loss 3.0274 - lr 0.0001953\n",
      "2021-06-20 21:50:02,704 DEV : loss 3.294342041015625 - score 0.9869\n",
      "2021-06-20 21:50:02,706 BAD EPOCHS (no improvement): 1\n",
      "2021-06-20 21:50:02,708 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:50:03,650 epoch 65 - iter 1/6 - loss 5.17945862 - samples/sec: 8.50 - lr: 0.000195\n",
      "2021-06-20 21:50:04,542 epoch 65 - iter 2/6 - loss 4.27263260 - samples/sec: 8.98 - lr: 0.000195\n",
      "2021-06-20 21:50:05,546 epoch 65 - iter 3/6 - loss 3.43003845 - samples/sec: 7.97 - lr: 0.000195\n",
      "2021-06-20 21:50:06,844 epoch 65 - iter 4/6 - loss 3.24837875 - samples/sec: 6.17 - lr: 0.000195\n",
      "2021-06-20 21:50:08,045 epoch 65 - iter 5/6 - loss 3.20126801 - samples/sec: 6.66 - lr: 0.000195\n",
      "2021-06-20 21:50:08,368 epoch 65 - iter 6/6 - loss 2.75518672 - samples/sec: 24.89 - lr: 0.000195\n",
      "2021-06-20 21:50:08,369 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:50:08,369 EPOCH 65 done: loss 2.7552 - lr 0.0001953\n",
      "2021-06-20 21:50:08,666 DEV : loss 3.2966461181640625 - score 0.9869\n",
      "2021-06-20 21:50:08,668 BAD EPOCHS (no improvement): 2\n",
      "2021-06-20 21:50:08,669 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:50:09,806 epoch 66 - iter 1/6 - loss 2.02787018 - samples/sec: 7.05 - lr: 0.000195\n",
      "2021-06-20 21:50:11,000 epoch 66 - iter 2/6 - loss 2.67892456 - samples/sec: 6.71 - lr: 0.000195\n",
      "2021-06-20 21:50:12,129 epoch 66 - iter 3/6 - loss 2.49625905 - samples/sec: 7.09 - lr: 0.000195\n",
      "2021-06-20 21:50:13,048 epoch 66 - iter 4/6 - loss 2.68007088 - samples/sec: 8.71 - lr: 0.000195\n",
      "2021-06-20 21:50:14,029 epoch 66 - iter 5/6 - loss 2.43288422 - samples/sec: 8.17 - lr: 0.000195\n",
      "2021-06-20 21:50:14,387 epoch 66 - iter 6/6 - loss 3.18658320 - samples/sec: 22.36 - lr: 0.000195\n",
      "2021-06-20 21:50:14,388 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:50:14,389 EPOCH 66 done: loss 3.1866 - lr 0.0001953\n",
      "2021-06-20 21:50:14,680 DEV : loss 3.293121337890625 - score 0.9869\n",
      "2021-06-20 21:50:14,682 BAD EPOCHS (no improvement): 3\n",
      "2021-06-20 21:50:14,683 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:50:15,931 epoch 67 - iter 1/6 - loss 2.48595428 - samples/sec: 6.42 - lr: 0.000195\n",
      "2021-06-20 21:50:17,071 epoch 67 - iter 2/6 - loss 2.27851486 - samples/sec: 7.02 - lr: 0.000195\n",
      "2021-06-20 21:50:18,069 epoch 67 - iter 3/6 - loss 2.69253286 - samples/sec: 8.03 - lr: 0.000195\n",
      "2021-06-20 21:50:19,033 epoch 67 - iter 4/6 - loss 3.07972717 - samples/sec: 8.31 - lr: 0.000195\n",
      "2021-06-20 21:50:20,083 epoch 67 - iter 5/6 - loss 2.79301300 - samples/sec: 7.62 - lr: 0.000195\n",
      "2021-06-20 21:50:20,350 epoch 67 - iter 6/6 - loss 2.60997136 - samples/sec: 30.10 - lr: 0.000195\n",
      "2021-06-20 21:50:20,351 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:50:20,351 EPOCH 67 done: loss 2.6100 - lr 0.0001953\n",
      "2021-06-20 21:50:20,645 DEV : loss 3.2884521484375 - score 0.9869\n",
      "Epoch    67: reducing learning rate of group 0 to 9.7656e-05.\n",
      "2021-06-20 21:50:20,647 BAD EPOCHS (no improvement): 4\n",
      "2021-06-20 21:50:20,648 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:50:20,649 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:50:20,650 learning rate too small - quitting training!\n",
      "2021-06-20 21:50:20,651 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:50:20,878 ----------------------------------------------------------------------------------------------------\n",
      "2021-06-20 21:50:20,879 Testing using best model ...\n",
      "2021-06-20 21:50:20,885 loading file /Users/varunnathan/Documents/General/ExternalTest/Prodigal/model/flair_v1/best-model.pt\n",
      "2021-06-20 21:50:34,691 \t0.9964\n",
      "2021-06-20 21:50:34,693 \n",
      "Results:\n",
      "- F-score (micro): 0.9964\n",
      "- F-score (macro): 0.9747\n",
      "- Accuracy (incl. no class): 0.9964\n",
      "\n",
      "By class:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "             O     1.0000    0.9955    0.9978       446\n",
      "          DATE     1.0000    1.0000    1.0000        34\n",
      "  NUM_PAYMENTS     0.8000    1.0000    0.8889         4\n",
      "PAYMENT_AMOUNT     1.0000    1.0000    1.0000        32\n",
      "  PAYMENT_DATE     0.9744    1.0000    0.9870        38\n",
      "\n",
      "      accuracy                         0.9964       554\n",
      "     macro avg     0.9549    0.9991    0.9747       554\n",
      "  weighted avg     0.9968    0.9964    0.9965       554\n",
      "\n",
      "2021-06-20 21:50:34,693 ----------------------------------------------------------------------------------------------------\n",
      "load model\n",
      "2021-06-20 21:50:34,706 loading file /Users/varunnathan/Documents/General/ExternalTest/Prodigal/model/flair_v1/final-model.pt\n",
      "CPU times: user 8min 49s, sys: 25.1 s, total: 9min 14s\n",
      "Wall time: 9min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "config = {\"use_crf\": True, \"hidden_size\": 50, \"learning_rate\": 0.1, \n",
    "          \"mini_batch_size\": 8, \"max_epochs\": 75}\n",
    "model1 = train(corpus, FLAIR_MODEL_DIR, fine_tuning=False, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "demographic-gossip",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-21 06:59:42,042 loading file /Users/varunnathan/Documents/General/ExternalTest/Prodigal/model/flair_v1/final-model.pt\n"
     ]
    }
   ],
   "source": [
    "import flair\n",
    "from flair.models import SequenceTagger\n",
    "import torch\n",
    "from flair.data import Sentence\n",
    "import copy\n",
    "flair.device = torch.device('cpu')\n",
    "\n",
    "model = SequenceTagger.load(os.path.join(FLAIR_MODEL_DIR, 'final-model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "altered-giving",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contraction\n"
     ]
    }
   ],
   "source": [
    "text = \"let's review the arrangement that he all have set up today today's date \\\n",
    "is monday december the twenty first and you have authorized the total i of two debit \\\n",
    "transactions in the amount of one hundred dollars should be taken from your debit card \\\n",
    "on today's date monday the twenty first and on january the sixteenth you understand that \\\n",
    "the payment you are authorizing will be processed as electronic service to your \\\n",
    "account and you can send to this recording that trying to signature for this payment \\\n",
    "arrangement please state your name\"\n",
    "out1, out2 = predict(model, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "adolescent-waters",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'text': 'december',\n",
       "   'start_pos': 83,\n",
       "   'end_pos': 91,\n",
       "   'labels': [DATE (0.9815)],\n",
       "   'pred_label': 'DATE',\n",
       "   'pred_score': 0.9815053343772888},\n",
       "  {'text': 'the',\n",
       "   'start_pos': 92,\n",
       "   'end_pos': 95,\n",
       "   'labels': [DATE (0.9951)],\n",
       "   'pred_label': 'DATE',\n",
       "   'pred_score': 0.9951266050338745},\n",
       "  {'text': 'twenty',\n",
       "   'start_pos': 96,\n",
       "   'end_pos': 102,\n",
       "   'labels': [DATE (0.9991)],\n",
       "   'pred_label': 'DATE',\n",
       "   'pred_score': 0.9991453886032104},\n",
       "  {'text': 'first',\n",
       "   'start_pos': 103,\n",
       "   'end_pos': 108,\n",
       "   'labels': [DATE (0.9979)],\n",
       "   'pred_label': 'DATE',\n",
       "   'pred_score': 0.9979279041290283},\n",
       "  {'text': 'two',\n",
       "   'start_pos': 148,\n",
       "   'end_pos': 151,\n",
       "   'labels': [NUM_PAYMENTS (0.844)],\n",
       "   'pred_label': 'NUM_PAYMENTS',\n",
       "   'pred_score': 0.843999981880188},\n",
       "  {'text': 'one',\n",
       "   'start_pos': 188,\n",
       "   'end_pos': 191,\n",
       "   'labels': [PAYMENT_AMOUNT (0.989)],\n",
       "   'pred_label': 'PAYMENT_AMOUNT',\n",
       "   'pred_score': 0.9890416264533997},\n",
       "  {'text': 'hundred',\n",
       "   'start_pos': 192,\n",
       "   'end_pos': 199,\n",
       "   'labels': [PAYMENT_AMOUNT (0.9996)],\n",
       "   'pred_label': 'PAYMENT_AMOUNT',\n",
       "   'pred_score': 0.999630331993103},\n",
       "  {'text': 'dollars',\n",
       "   'start_pos': 200,\n",
       "   'end_pos': 207,\n",
       "   'labels': [PAYMENT_AMOUNT (0.9994)],\n",
       "   'pred_label': 'PAYMENT_AMOUNT',\n",
       "   'pred_score': 0.9993543028831482},\n",
       "  {'text': 'twenty',\n",
       "   'start_pos': 272,\n",
       "   'end_pos': 278,\n",
       "   'labels': [PAYMENT_DATE (0.9567)],\n",
       "   'pred_label': 'PAYMENT_DATE',\n",
       "   'pred_score': 0.9566527605056763},\n",
       "  {'text': 'first',\n",
       "   'start_pos': 279,\n",
       "   'end_pos': 284,\n",
       "   'labels': [PAYMENT_DATE (0.9887)],\n",
       "   'pred_label': 'PAYMENT_DATE',\n",
       "   'pred_score': 0.988723874092102},\n",
       "  {'text': 'january',\n",
       "   'start_pos': 292,\n",
       "   'end_pos': 299,\n",
       "   'labels': [PAYMENT_DATE (0.9755)],\n",
       "   'pred_label': 'PAYMENT_DATE',\n",
       "   'pred_score': 0.9754578471183777},\n",
       "  {'text': 'the',\n",
       "   'start_pos': 300,\n",
       "   'end_pos': 303,\n",
       "   'labels': [PAYMENT_DATE (0.9641)],\n",
       "   'pred_label': 'PAYMENT_DATE',\n",
       "   'pred_score': 0.9641032218933105},\n",
       "  {'text': 'sixteenth',\n",
       "   'start_pos': 304,\n",
       "   'end_pos': 313,\n",
       "   'labels': [PAYMENT_DATE (0.9884)],\n",
       "   'pred_label': 'PAYMENT_DATE',\n",
       "   'pred_score': 0.988373339176178}],\n",
       " [{'text': 'december the twenty first',\n",
       "   'start_pos': 83,\n",
       "   'end_pos': 108,\n",
       "   'pred_label': 'DATE',\n",
       "   'pred_score': 0.9815053343772888},\n",
       "  {'text': 'two',\n",
       "   'start_pos': 148,\n",
       "   'end_pos': 151,\n",
       "   'labels': [NUM_PAYMENTS (0.844)],\n",
       "   'pred_label': 'NUM_PAYMENTS',\n",
       "   'pred_score': 0.843999981880188},\n",
       "  {'text': 'one hundred dollars',\n",
       "   'start_pos': 188,\n",
       "   'end_pos': 207,\n",
       "   'pred_label': 'PAYMENT_AMOUNT',\n",
       "   'pred_score': 0.9890416264533997},\n",
       "  {'text': 'twenty first',\n",
       "   'start_pos': 272,\n",
       "   'end_pos': 284,\n",
       "   'pred_label': 'PAYMENT_DATE',\n",
       "   'pred_score': 0.9566527605056763},\n",
       "  {'text': 'january the sixteenth',\n",
       "   'start_pos': 292,\n",
       "   'end_pos': 313,\n",
       "   'pred_label': 'PAYMENT_DATE',\n",
       "   'pred_score': 0.9641032218933105}])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1, out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "secondary-scenario",
   "metadata": {},
   "outputs": [],
   "source": [
    "### free up memory\n",
    "del model, model1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-sodium",
   "metadata": {},
   "source": [
    "## Experiment 3 - Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "broadband-river",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'bert-base-cased'\n",
    "BERT_MODEL_DIR = os.path.join(MODEL_DIR, \"bert_base_cased_v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "downtown-fitting",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertForTokenClassification: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['dropout_113', 'classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_token_classification_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert (TFBertMainLayer)       multiple                  108310272 \n",
      "_________________________________________________________________\n",
      "dropout_113 (Dropout)        multiple                  0         \n",
      "_________________________________________________________________\n",
      "classifier (Dense)           multiple                  4614      \n",
      "=================================================================\n",
      "Total params: 108,314,886\n",
      "Trainable params: 108,314,886\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig, TFAutoModelForTokenClassification\n",
    "\n",
    "config = AutoConfig.from_pretrained(MODEL_NAME, num_labels=6)\n",
    "model = TFAutoModelForTokenClassification.from_pretrained(MODEL_NAME, config=config)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "broken-monaco",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename: str):\n",
    "    with open(filename, 'r') as file:\n",
    "        lines = [line[:-1].split() for line in file]\n",
    "    samples, start = [], 0\n",
    "    for end, parts in enumerate(lines):\n",
    "        if not parts:\n",
    "            sample = [(token, tag) for token, tag in lines[start:end]]\n",
    "            samples.append(sample)\n",
    "            start = end + 1\n",
    "    if start < end:\n",
    "        samples.append(lines[start:end])\n",
    "    return samples\n",
    "\n",
    "train_samples = load_data(os.path.join(FLAIR_FT_MODEL_DIR, 'train.txt'))\n",
    "samples = train_samples\n",
    "schema = ['_'] + sorted({tag for sentence in samples for _, tag in sentence})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "decimal-passport",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,\n",
       " [('nine', 'O'),\n",
       "  ('seven', 'O'),\n",
       "  ('three', 'O'),\n",
       "  ('and', 'O'),\n",
       "  ('then', 'O'),\n",
       "  ('let', 'O'),\n",
       "  ('us', 'O'),\n",
       "  ('just', 'O'),\n",
       "  ('go', 'O'),\n",
       "  ('over', 'O'),\n",
       "  ('with', 'O'),\n",
       "  ('this', 'O'),\n",
       "  ('arrangement', 'O'),\n",
       "  ('and', 'O'),\n",
       "  ('then', 'O'),\n",
       "  ('we', 'O'),\n",
       "  ('will', 'O'),\n",
       "  ('be', 'O'),\n",
       "  ('completely', 'O'),\n",
       "  ('set', 'O'),\n",
       "  ('please', 'O'),\n",
       "  ('state', 'O'),\n",
       "  ('mister', 'O'),\n",
       "  ('is', 'O'),\n",
       "  ('december', 'DATE'),\n",
       "  ('twenty', 'DATE'),\n",
       "  ('first', 'DATE'),\n",
       "  ('two', 'DATE'),\n",
       "  ('thousand', 'DATE'),\n",
       "  ('twenty', 'DATE'),\n",
       "  ('authorize', 'O'),\n",
       "  ('authorized', 'O'),\n",
       "  ('one', 'NUM_PAYMENTS'),\n",
       "  ('time', 'NUM_PAYMENTS'),\n",
       "  ('transaction', 'O'),\n",
       "  ('and', 'O'),\n",
       "  ('of', 'O'),\n",
       "  ('twelve', 'PAYMENT_AMOUNT'),\n",
       "  ('dollar', 'PAYMENT_AMOUNT'),\n",
       "  ('and', 'PAYMENT_AMOUNT'),\n",
       "  ('ninety', 'PAYMENT_AMOUNT'),\n",
       "  ('seven', 'PAYMENT_AMOUNT'),\n",
       "  ('cents', 'PAYMENT_AMOUNT'),\n",
       "  ('be', 'O'),\n",
       "  ('address', 'O'),\n",
       "  ('from', 'O'),\n",
       "  ('your', 'O'),\n",
       "  ('card', 'O'),\n",
       "  ('will', 'O'),\n",
       "  ('be', 'O'),\n",
       "  ('processed', 'O'),\n",
       "  ('as', 'O'),\n",
       "  ('an', 'O'),\n",
       "  ('electronic', 'O'),\n",
       "  ('and', 'O'),\n",
       "  ('solutions', 'O'),\n",
       "  ('and', 'O'),\n",
       "  ('your', 'O'),\n",
       "  ('stevens', 'O'),\n",
       "  ('if', 'O'),\n",
       "  ('you', 'O'),\n",
       "  ('just', 'O'),\n",
       "  ('need', 'O'),\n",
       "  ('to', 'O'),\n",
       "  ('cause', 'O'),\n",
       "  ('it', 'O'),\n",
       "  ('has', 'O'),\n",
       "  ('recording', 'O'),\n",
       "  ('shipping', 'O'),\n",
       "  ('is', 'O'),\n",
       "  ('your', 'O'),\n",
       "  ('electronic', 'O'),\n",
       "  ('signature', 'O'),\n",
       "  ('can', 'O'),\n",
       "  ('please', 'O'),\n",
       "  ('speak', 'O'),\n",
       "  ('your', 'O'),\n",
       "  ('full', 'O'),\n",
       "  ('name', 'O'),\n",
       "  ('ai', 'O'),\n",
       "  ('i', 'O'),\n",
       "  ('agree', 'O')],\n",
       " ['_', 'DATE', 'NUM_PAYMENTS', 'O', 'PAYMENT_AMOUNT', 'PAYMENT_DATE'])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples), samples[0], schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cognitive-easter",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "unavailable-least",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([101, 2730, 102], [101, 2936, 102])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('recording')['input_ids'], tokenizer('speak')['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "assigned-official",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 506 ms, sys: 2.4 ms, total: 509 ms\n",
      "Wall time: 507 ms\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "def tokenize_sample(sample):\n",
    "    seq = [\n",
    "            (subtoken, tag)\n",
    "            for token, tag in sample\n",
    "            for subtoken in tokenizer(token)['input_ids'][1:-1]\n",
    "           ]\n",
    "    return [(101, 'O')] + seq + [(102, 'O')]\n",
    "\n",
    "\n",
    "def preprocess_bert(samples, schema):\n",
    "    tag_index = {tag: i for i, tag in enumerate(schema)}\n",
    "    tokenized_samples = list(map(tokenize_sample, samples))\n",
    "    max_len = max(map(len, tokenized_samples))\n",
    "    X = np.zeros((len(samples), max_len), dtype=np.int32)\n",
    "    y = np.zeros((len(samples), max_len), dtype=np.int32)\n",
    "    for i, sentence in enumerate(tokenized_samples):\n",
    "        for j, (subtoken_id, tag) in enumerate(sentence):\n",
    "            X[i, j] = subtoken_id\n",
    "            y[i, j] = tag_index[tag]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "%time X_train, y_train = preprocess_bert(train_samples, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "becoming-oregon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50, 191), (50, 191))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "lonely-enough",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  101,  2551,  1978,  1210,  1105,  1173,  1519,  1366,  1198,\n",
       "         1301,  1166,  1114,  1142,  6204,  1105,  1173,  1195,  1209,\n",
       "         1129,  2423,  1383,  4268,  1352, 12791,  1200,  1110,  1260,\n",
       "         2093, 10615,  2570,  1148,  1160,  4032,  2570,  2351,  3708,\n",
       "         9320,  1141,  1159, 13618,  1105,  1104,  4030,  8876,  1105,\n",
       "        16696,  1978, 18748,  1129,  4134,  1121,  1240,  3621,  1209,\n",
       "         1129, 14659,  1112,  1126,  4828,  1105,  7995,  1105,  1240,\n",
       "          188,  1566,  7912,  1116,  1191,  1128,  1198,  1444,  1106,\n",
       "         2612,  1122,  1144,  2730,  8629,  1110,  1240,  4828,  8250,\n",
       "         1169,  4268,  2936,  1240,  1554,  1271,   170,  1182,   178,\n",
       "         5340,   102,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0], dtype=int32),\n",
       " 82,\n",
       " array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 2, 2, 3, 3, 3, 4, 4,\n",
       "        4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0], len(train_samples[0]), y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "accredited-dutch",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_index = {tag: i for i, tag in enumerate(schema)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "impressed-prescription",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_for_token_classification_2/bert/pooler/dense/kernel:0', 'tf_bert_for_token_classification_2/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_for_token_classification_2/bert/pooler/dense/kernel:0', 'tf_bert_for_token_classification_2/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_for_token_classification_2/bert/pooler/dense/kernel:0', 'tf_bert_for_token_classification_2/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_for_token_classification_2/bert/pooler/dense/kernel:0', 'tf_bert_for_token_classification_2/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "6/6 [==============================] - 25s 4s/step - loss: 1.3300 - accuracy: 0.6229 - val_loss: 0.9279 - val_accuracy: 0.8346\n",
      "Epoch 2/25\n",
      "6/6 [==============================] - 23s 4s/step - loss: 0.6523 - accuracy: 0.8870 - val_loss: 0.6046 - val_accuracy: 0.8408\n",
      "Epoch 3/25\n",
      "6/6 [==============================] - 23s 4s/step - loss: 0.4375 - accuracy: 0.8885 - val_loss: 0.4972 - val_accuracy: 0.8408\n",
      "Epoch 4/25\n",
      "6/6 [==============================] - 23s 4s/step - loss: 0.3306 - accuracy: 0.8908 - val_loss: 0.3845 - val_accuracy: 0.8607\n",
      "Epoch 5/25\n",
      "6/6 [==============================] - 26s 4s/step - loss: 0.2619 - accuracy: 0.9096 - val_loss: 0.3265 - val_accuracy: 0.8723\n",
      "Epoch 6/25\n",
      "6/6 [==============================] - 23s 4s/step - loss: 0.2178 - accuracy: 0.9318 - val_loss: 0.2813 - val_accuracy: 0.8827\n",
      "Epoch 7/25\n",
      "6/6 [==============================] - 25s 4s/step - loss: 0.1842 - accuracy: 0.9465 - val_loss: 0.2364 - val_accuracy: 0.9099\n",
      "Epoch 8/25\n",
      "6/6 [==============================] - 23s 4s/step - loss: 0.1538 - accuracy: 0.9592 - val_loss: 0.1897 - val_accuracy: 0.9487\n",
      "Epoch 9/25\n",
      "6/6 [==============================] - 25s 4s/step - loss: 0.1245 - accuracy: 0.9694 - val_loss: 0.1486 - val_accuracy: 0.9770\n",
      "Epoch 10/25\n",
      "6/6 [==============================] - 24s 4s/step - loss: 0.1039 - accuracy: 0.9772 - val_loss: 0.1269 - val_accuracy: 0.9780\n",
      "Epoch 11/25\n",
      "6/6 [==============================] - 24s 4s/step - loss: 0.0898 - accuracy: 0.9778 - val_loss: 0.1149 - val_accuracy: 0.9791\n",
      "Epoch 12/25\n",
      "6/6 [==============================] - 23s 4s/step - loss: 0.0768 - accuracy: 0.9835 - val_loss: 0.0984 - val_accuracy: 0.9812\n",
      "Epoch 13/25\n",
      "6/6 [==============================] - 22s 4s/step - loss: 0.0660 - accuracy: 0.9856 - val_loss: 0.0832 - val_accuracy: 0.9812\n",
      "Epoch 14/25\n",
      "6/6 [==============================] - 24s 4s/step - loss: 0.0574 - accuracy: 0.9869 - val_loss: 0.0824 - val_accuracy: 0.9791\n",
      "Epoch 15/25\n",
      "6/6 [==============================] - 24s 4s/step - loss: 0.0500 - accuracy: 0.9889 - val_loss: 0.0790 - val_accuracy: 0.9791\n",
      "Epoch 16/25\n",
      "6/6 [==============================] - 25s 4s/step - loss: 0.0465 - accuracy: 0.9902 - val_loss: 0.0604 - val_accuracy: 0.9822\n",
      "Epoch 17/25\n",
      "6/6 [==============================] - 25s 4s/step - loss: 0.0400 - accuracy: 0.9907 - val_loss: 0.0693 - val_accuracy: 0.9801\n",
      "Epoch 18/25\n",
      "6/6 [==============================] - 24s 4s/step - loss: 0.0363 - accuracy: 0.9919 - val_loss: 0.0728 - val_accuracy: 0.9812\n",
      "Epoch 19/25\n",
      "6/6 [==============================] - 25s 4s/step - loss: 0.0320 - accuracy: 0.9928 - val_loss: 0.0677 - val_accuracy: 0.9822\n",
      "Epoch 20/25\n",
      "6/6 [==============================] - 25s 4s/step - loss: 0.0284 - accuracy: 0.9933 - val_loss: 0.0643 - val_accuracy: 0.9822\n",
      "Epoch 21/25\n",
      "6/6 [==============================] - 25s 4s/step - loss: 0.0258 - accuracy: 0.9943 - val_loss: 0.0541 - val_accuracy: 0.9832\n",
      "Epoch 22/25\n",
      "6/6 [==============================] - 26s 4s/step - loss: 0.0227 - accuracy: 0.9945 - val_loss: 0.0630 - val_accuracy: 0.9832\n",
      "Epoch 23/25\n",
      "6/6 [==============================] - 26s 4s/step - loss: 0.0217 - accuracy: 0.9949 - val_loss: 0.0665 - val_accuracy: 0.9822\n",
      "Epoch 24/25\n",
      "6/6 [==============================] - 24s 4s/step - loss: 0.0183 - accuracy: 0.9965 - val_loss: 0.0574 - val_accuracy: 0.9843\n",
      "Epoch 25/25\n",
      "6/6 [==============================] - 24s 4s/step - loss: 0.0169 - accuracy: 0.9965 - val_loss: 0.0545 - val_accuracy: 0.9864\n",
      "CPU times: user 1h 20min 58s, sys: 20min 20s, total: 1h 41min 18s\n",
      "Wall time: 12min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# fine-tuning\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "EPOCHS = 25\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(lr=0.00001)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics='accuracy')\n",
    "history = model.fit(tf.constant(X_train), tf.constant(y_train),\n",
    "                    validation_split=0.1, epochs=EPOCHS, \n",
    "                    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "municipal-warehouse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Users/varunnathan/Documents/General/ExternalTest/Prodigal/model/bert_base_cased_v2/tokenizer_config.json',\n",
       " '/Users/varunnathan/Documents/General/ExternalTest/Prodigal/model/bert_base_cased_v2/special_tokens_map.json',\n",
       " '/Users/varunnathan/Documents/General/ExternalTest/Prodigal/model/bert_base_cased_v2/vocab.txt',\n",
       " '/Users/varunnathan/Documents/General/ExternalTest/Prodigal/model/bert_base_cased_v2/added_tokens.json')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save\n",
    "BERT_MODEL_DIR_V2 = os.path.join(MODEL_DIR, \"bert_base_cased_v2\")\n",
    "model.save_pretrained(BERT_MODEL_DIR_V2)\n",
    "tokenizer.save_pretrained(BERT_MODEL_DIR_V2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "collect-smile",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(191, 1, 6)\n"
     ]
    }
   ],
   "source": [
    "# prediction\n",
    "def aggregate(sample, predictions, schema):\n",
    "    results = []\n",
    "    i = 1\n",
    "    for token, y_true in sample:\n",
    "        nr_subtoken = len(tokenizer(token)['input_ids']) - 2\n",
    "        pred = predictions[i: i+nr_subtoken]\n",
    "        i += nr_subtoken\n",
    "        y_pred = schema[np.argmax(np.sum(pred, axis=0))]\n",
    "        results.append((token, y_true, y_pred))\n",
    "    return results\n",
    "\n",
    "\n",
    "y_probs = model.predict(X_train[1])[0]\n",
    "print(y_probs.shape)\n",
    "predictions = [aggregate(sample, predictions, schema)\n",
    "               for sample, predictions in zip([train_samples[1]], y_probs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "outstanding-pitch",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at /Users/varunnathan/Documents/General/ExternalTest/Prodigal/model/bert_base_cased_v2 were not used when initializing TFBertForTokenClassification: ['dropout_113']\n",
      "- This IS expected if you are initializing TFBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at /Users/varunnathan/Documents/General/ExternalTest/Prodigal/model/bert_base_cased_v2 and are newly initialized: ['dropout_151']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, TFAutoModelForTokenClassification, AutoTokenizer\n",
    "\n",
    "model1 = TFAutoModelForTokenClassification.from_pretrained(BERT_MODEL_DIR_V2)\n",
    "tokenizer1 = AutoTokenizer.from_pretrained(BERT_MODEL_DIR_V2)\n",
    "\n",
    "ner_model = pipeline('ner', model=model1, tokenizer=tokenizer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "naval-skating",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_index_inv = {'LABEL_'+str(v): k for k, v in tag_index.items()}\n",
    "\n",
    "\n",
    "def predict_bert(ner_model, tag_index_inv, text):\n",
    "    \n",
    "    # preprocess\n",
    "    text_pre = preprocess(text)\n",
    "    \n",
    "    # prediction\n",
    "    pred = ner_model(text_pre)\n",
    "    \n",
    "    # formatting the prediction\n",
    "    pred_n = []\n",
    "    for row in pred:\n",
    "        if row['entity'] in ['LABEL_'+str(x) for x in [1, 2, 4, 5]]:\n",
    "            row1 = copy.deepcopy(row)\n",
    "            row1['entity'] = tag_index_inv[row1['entity']]\n",
    "            row1['start_pos'] = row1['end_pos'] = row1['index']\n",
    "            pred_n.append(row1)\n",
    "    \n",
    "    # combining contiguous predictions\n",
    "    out = combine_contiguous_words(pred_n, label_k='entity', start_pos_k='start_pos',\n",
    "                                   end_pos_k='end_pos', text_k='word', score_k='score')\n",
    "    \n",
    "    return pred_n, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "occasional-yacht",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json.dump(tag_index_inv, open(os.path.join(BERT_MODEL_DIR_V2, 'tag_index_inv.json'), 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "compliant-shower",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contraction\n",
      "CPU times: user 765 ms, sys: 234 ms, total: 1e+03 ms\n",
      "Wall time: 256 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "text = \"let's review the arrangement that he all have set up today today's date \\\n",
    "is monday december the twenty first and you have authorized the total i of two debit \\\n",
    "transactions in the amount of one hundred dollars should be taken from your debit card \\\n",
    "on today's date monday the twenty first and on january the sixteenth you understand that \\\n",
    "the payment you are authorizing will be processed as electronic service to your \\\n",
    "account and you can send to this recording that trying to signature for this payment \\\n",
    "arrangement please state your name\"\n",
    "out1, out2 = predict_bert(ner_model, tag_index_inv, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "everyday-header",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'word': 'de', 'score': 0.9796044826507568, 'entity': 'DATE', 'index': 20, 'start_pos': 20, 'end_pos': 20}, {'word': '##ce', 'score': 0.9726102948188782, 'entity': 'DATE', 'index': 21, 'start_pos': 21, 'end_pos': 21}, {'word': '##mber', 'score': 0.9820989370346069, 'entity': 'DATE', 'index': 22, 'start_pos': 22, 'end_pos': 22}, {'word': 'the', 'score': 0.9865468740463257, 'entity': 'DATE', 'index': 23, 'start_pos': 23, 'end_pos': 23}, {'word': 'twenty', 'score': 0.9836658239364624, 'entity': 'DATE', 'index': 24, 'start_pos': 24, 'end_pos': 24}, {'word': 'first', 'score': 0.983189046382904, 'entity': 'DATE', 'index': 25, 'start_pos': 25, 'end_pos': 25}, {'word': 'two', 'score': 0.4268897771835327, 'entity': 'NUM_PAYMENTS', 'index': 34, 'start_pos': 34, 'end_pos': 34}, {'word': 'one', 'score': 0.9655413627624512, 'entity': 'PAYMENT_AMOUNT', 'index': 42, 'start_pos': 42, 'end_pos': 42}, {'word': 'hundred', 'score': 0.9662790298461914, 'entity': 'PAYMENT_AMOUNT', 'index': 43, 'start_pos': 43, 'end_pos': 43}, {'word': 'dollars', 'score': 0.9711687564849854, 'entity': 'PAYMENT_AMOUNT', 'index': 44, 'start_pos': 44, 'end_pos': 44}, {'word': 'the', 'score': 0.6789507269859314, 'entity': 'PAYMENT_DATE', 'index': 60, 'start_pos': 60, 'end_pos': 60}, {'word': 'twenty', 'score': 0.9340254068374634, 'entity': 'PAYMENT_DATE', 'index': 61, 'start_pos': 61, 'end_pos': 61}, {'word': 'first', 'score': 0.906613290309906, 'entity': 'PAYMENT_DATE', 'index': 62, 'start_pos': 62, 'end_pos': 62}, {'word': 'j', 'score': 0.9536680579185486, 'entity': 'PAYMENT_DATE', 'index': 65, 'start_pos': 65, 'end_pos': 65}, {'word': '##anu', 'score': 0.9303603768348694, 'entity': 'PAYMENT_DATE', 'index': 66, 'start_pos': 66, 'end_pos': 66}, {'word': '##ary', 'score': 0.8911349177360535, 'entity': 'PAYMENT_DATE', 'index': 67, 'start_pos': 67, 'end_pos': 67}, {'word': 'the', 'score': 0.9302597641944885, 'entity': 'PAYMENT_DATE', 'index': 68, 'start_pos': 68, 'end_pos': 68}, {'word': 'sixteenth', 'score': 0.9130687713623047, 'entity': 'PAYMENT_DATE', 'index': 69, 'start_pos': 69, 'end_pos': 69}]\n",
      "\n",
      "[{'word': 'de ##ce ##mber the twenty first', 'start_pos': 20, 'end_pos': 25, 'entity': 'DATE', 'score': 0.9726102948188782}, {'word': 'two', 'score': 0.4268897771835327, 'entity': 'NUM_PAYMENTS', 'index': 34, 'start_pos': 34, 'end_pos': 34}, {'word': 'one hundred dollars', 'start_pos': 42, 'end_pos': 44, 'entity': 'PAYMENT_AMOUNT', 'score': 0.9655413627624512}, {'word': 'the twenty first', 'start_pos': 60, 'end_pos': 62, 'entity': 'PAYMENT_DATE', 'score': 0.6789507269859314}, {'word': 'j ##anu ##ary the sixteenth', 'start_pos': 65, 'end_pos': 69, 'entity': 'PAYMENT_DATE', 'score': 0.8911349177360535}]\n"
     ]
    }
   ],
   "source": [
    "print(out1)\n",
    "print()\n",
    "print(out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civic-webster",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
