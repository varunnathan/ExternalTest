Steps to deploy models for inference using TorchServe
============================================================

1. Custom handler class
2. Convert model ckpts to .mar file and persist in model store
3. Configure logging and metrics
4. Start model server and ensure that http requests can be sent
