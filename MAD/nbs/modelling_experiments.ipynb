{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments\n",
    "1. NN Classification\n",
    "2. NN Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "import math\n",
    "import copy\n",
    "import pickle\n",
    "import zipfile\n",
    "from textwrap import wrap\n",
    "from pathlib import Path\n",
    "from itertools import zip_longest\n",
    "from collections import defaultdict\n",
    "from urllib.error import URLError\n",
    "from urllib.request import urlopen\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch import tensor\n",
    "from torch.nn import functional as F \n",
    "from torch.optim.lr_scheduler import _LRScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/Users/varunn/Documents/ExternalTest/MAD/src/\")\n",
    "from constants import *\n",
    "from metadata_utils import _find_files\n",
    "from baseline_feats_utils import feat_type_feats_dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user': ['num_interactions',\n",
       "  'mean_price_interactions',\n",
       "  'earliest_interaction_date',\n",
       "  'min_num_interactions_per_pdt',\n",
       "  'max_num_interactions_per_pdt',\n",
       "  'mean_num_interactions_per_pdt',\n",
       "  'min_num_interactions_per_ont',\n",
       "  'max_num_interactions_per_ont',\n",
       "  'mean_num_interactions_per_ont',\n",
       "  'min_num_interactions_per_brand',\n",
       "  'max_num_interactions_per_brand',\n",
       "  'mean_num_interactions_per_brand'],\n",
       " 'item': ['num_interactions',\n",
       "  'earliest_interaction_date',\n",
       "  'min_num_interactions_per_user',\n",
       "  'max_num_interactions_per_user',\n",
       "  'mean_num_interactions_per_user']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_type_feats_dct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1 - NN Classification with baseline features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import IterableDataset\n",
    "from itertools import chain, islice\n",
    "\n",
    "\n",
    "class InteractionsStream(IterableDataset):\n",
    "\n",
    "    def __init__(self, sample, model_type, file_name=None,\n",
    "                 interim_data_dir=INTERIM_DATA_DIR, user_col=USER_COL,\n",
    "                 item_col=ITEM_COL, ontology_col=ONTOLOGY_COL,\n",
    "                 brand_col=BRAND_COL, price_col=PRICE_COL, dv_col=DV_COL,\n",
    "                 date_col=DATE_COL, end_token='.gz', chunksize=10):\n",
    "\n",
    "        data_dir = interim_data_dir\n",
    "        \n",
    "        if file_name is None:\n",
    "            files = _find_files(data_dir, end_token)\n",
    "            if sample == 'train':\n",
    "                self.files = [os.path.join(data_dir, x) for x in files\n",
    "                              if not x.startswith('0005')]\n",
    "            elif sample == 'test':\n",
    "                self.files = [os.path.join(data_dir, x) for x in files\n",
    "                              if x.startswith('0005')]\n",
    "        else:\n",
    "            self.files = [os.path.join(data_dir, file_name)]\n",
    "        print(self.files)\n",
    "        \n",
    "        self.model_type = model_type\n",
    "        self.user_col = user_col\n",
    "        self.item_col = item_col\n",
    "        self.ontology_col = ontology_col\n",
    "        self.brand_col = brand_col\n",
    "        self.price_col = price_col\n",
    "        self.date_col = date_col\n",
    "        self.dv_col = dv_col\n",
    "        self.feat_type_feats_dct = feat_type_feats_dct\n",
    "        self.chunksize = chunksize\n",
    "        user_feats = ['{}_{}'.format(self.user_col, x) for x in\n",
    "                      self.feat_type_feats_dct['user']\n",
    "                      if x != 'earliest_interaction_date']\n",
    "        user_feats.append('{}_days_since_earliest_interaction'.format(\n",
    "            self.user_col))\n",
    "        item_feats = ['{}_{}'.format(self.item_col, x) for x in\n",
    "                      self.feat_type_feats_dct['item']\n",
    "                      if x != 'earliest_interaction_date']\n",
    "        item_feats.append('{}_days_since_earliest_interaction'.format(\n",
    "            self.item_col))\n",
    "        self.numeric_feats = [self.price_col] + user_feats + item_feats\n",
    "        self.cat_feats = [self.user_col, self.item_col, self.ontology_col,\n",
    "                          self.brand_col]\n",
    "        \n",
    "\n",
    "    def read_file(self, fn):\n",
    "        \n",
    "        df = pd.read_csv(fn, compression='gzip', sep='|', iterator=True,\n",
    "                         chunksize=self.chunksize)\n",
    "        return df\n",
    "    \n",
    "    def get_dv_for_classification(self, dv_lst):\n",
    "        \n",
    "        if self.model_type == 'classification':\n",
    "            return [int(x-1) for x in dv_lst]\n",
    "        else:\n",
    "            return [int(x) for x in dv_lst]\n",
    "\n",
    "    def process_data(self, fn):\n",
    "\n",
    "        print('read data')\n",
    "        data = self.read_file(fn)\n",
    "\n",
    "        for row in data:\n",
    "            x1 = row[self.cat_feats].values.tolist()\n",
    "            x2 = row[self.numeric_feats].values.tolist()\n",
    "            y = self.get_dv_for_classification(\n",
    "                    row[self.dv_col].tolist())\n",
    "            yield (x1, x2, y)\n",
    "\n",
    "    def get_stream(self, files):\n",
    "        return chain.from_iterable(map(self.process_data, files))\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self.get_stream(self.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductRecommendationModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Defines the neural network for product recommendation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embedding_sizes, n_cont, n_classes=3):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.ModuleList([nn.Embedding(categories, size) for\n",
    "                                         categories, size in embedding_sizes])\n",
    "        n_emb = sum(e.embedding_dim for e in self.embeddings)\n",
    "        self.n_emb, self.n_cont, self.n_classes = n_emb, n_cont, n_classes\n",
    "        self.lin1 = nn.Linear(self.n_emb + self.n_cont, 300)\n",
    "        self.lin2 = nn.Linear(300, 100)\n",
    "        self.lin3 = nn.Linear(100, self.n_classes)\n",
    "        self.bn1 = nn.BatchNorm1d(self.n_cont)\n",
    "        self.bn2 = nn.BatchNorm1d(300)\n",
    "        self.bn3 = nn.BatchNorm1d(100)\n",
    "        self.emb_drop = nn.Dropout(0.6)\n",
    "        self.drops = nn.Dropout(0.3)\n",
    "\n",
    "\n",
    "    def forward(self, x_cat, x_cont):\n",
    "        x = [e(x_cat[:, i]) for i, e in enumerate(self.embeddings)]\n",
    "        x = torch.cat(x, 1)\n",
    "        x = self.emb_drop(x)\n",
    "        x2 = self.bn1(x_cont)\n",
    "        x = torch.cat([x, x2], 1)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = self.drops(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(self.lin2(x))\n",
    "        x = self.drops(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.lin3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as torch_optim\n",
    "from torch import tensor\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def choose_embedding_size(cat_cols, cat_num_values, min_emb_dim=100):\n",
    "    \"\"\"\n",
    "    cat_cols: list of categorical columns\n",
    "    cat_num_values: list of number of unique values for each categorical column\n",
    "    \"\"\"\n",
    "\n",
    "    embedded_cols = dict(zip(cat_cols, cat_num_values))\n",
    "    embedding_sizes = [(n_categories, min(min_emb_dim, (n_categories+1)//2))\n",
    "                       for _, n_categories in embedded_cols.items()]\n",
    "    return embedding_sizes\n",
    "\n",
    "\n",
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "\n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl:\n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)\n",
    "\n",
    "\n",
    "def get_optimizer(model, lr = 0.001, wd = 0.0):\n",
    "\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optim = torch_optim.Adam(parameters, lr=lr, weight_decay=wd)\n",
    "    return optim\n",
    "\n",
    "\n",
    "def construct_tensor(a):\n",
    "\n",
    "    final = []\n",
    "    for i in a:\n",
    "        out = []\n",
    "        for j in i:\n",
    "            out.append(j.tolist())\n",
    "        out1 = []\n",
    "        for item in zip(*out):\n",
    "            out1.append(list(item))\n",
    "        final += out1\n",
    "    return tensor(final)\n",
    "\n",
    "\n",
    "def construct_tensor_y(a):\n",
    "\n",
    "    out = []\n",
    "    for i in a:\n",
    "        out += i.tolist()\n",
    "    return tensor(out)\n",
    "\n",
    "\n",
    "def train_model(model, optim, train_dl, train_size, chunksize, batch_size,\n",
    "                device, loss_fn=F.cross_entropy):\n",
    "\n",
    "    model.train()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    with tqdm(total=train_size // (batch_size * chunksize)) as pbar:\n",
    "        for x1, x2, y in train_dl:\n",
    "            x1, x2, y = (construct_tensor(x1), construct_tensor(x2),\n",
    "                         construct_tensor_y(y))\n",
    "            x1 = x1.to(device)\n",
    "            x2 = x2.to(device)\n",
    "            y = y.to(device)\n",
    "            batch = y.size()[0]\n",
    "            output = model(x1, x2)\n",
    "            loss = loss_fn(output, y)\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            total += batch\n",
    "            sum_loss += loss.item()\n",
    "            pbar.update(1)\n",
    "    return sum_loss/total\n",
    "\n",
    "\n",
    "def val_loss(model, valid_dl, test_size, chunksize, batch_size,\n",
    "             device, loss_fn=F.cross_entropy):\n",
    "\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    correct = 0\n",
    "    sum_auc_macro = 0\n",
    "    sum_auc_micro = 0\n",
    "    num_aucs = 0\n",
    "    with tqdm(total=test_size // (batch_size * chunksize)) as pbar:\n",
    "        for x1, x2, y in valid_dl:\n",
    "            x1, x2, y = (construct_tensor(x1), construct_tensor(x2),\n",
    "                         construct_tensor_y(y))\n",
    "            x1 = x1.to(device)\n",
    "            x2 = x2.to(device)\n",
    "            y = y.to(device)\n",
    "            batch = y.size()[0]\n",
    "            out = model(x1, x2)\n",
    "            loss = loss_fn(out, y)\n",
    "            sum_loss += loss.item()\n",
    "            total += batch\n",
    "            pred = torch.max(out, 1)[1]\n",
    "            pred_prob = F.softmax(out, dim=1)\n",
    "            y_onehot = F.one_hot(y)\n",
    "            correct += (pred == y).float().sum().item()\n",
    "            pred_prob = pred_prob.cpu().detach().numpy()\n",
    "            y_onehot = y_onehot.cpu().detach().numpy()\n",
    "            try:\n",
    "                sum_auc_macro += roc_auc_score(y_onehot, pred_prob,\n",
    "                                               average='macro')\n",
    "                sum_auc_micro += roc_auc_score(y_onehot, pred_prob,\n",
    "                                               average='micro')\n",
    "                num_aucs += 1\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            pbar.update(1)\n",
    "    print(\"valid loss %.3f, accuracy %.3f, macro auc %.3f and micro auc %.3f\" % (\n",
    "        sum_loss/total, correct/total, sum_auc_macro/num_aucs, sum_auc_micro/num_aucs))\n",
    "    return sum_loss/total, correct/total, sum_auc_macro/num_aucs, sum_auc_micro/num_aucs\n",
    "\n",
    "\n",
    "def train_loop(model, train_dl, valid_dl, epochs, train_size,\n",
    "               test_size, chunksize, batch_size, device, lr=0.01,\n",
    "               wd=0.0, loss_fn=F.cross_entropy):\n",
    "\n",
    "    optim = get_optimizer(model, lr = lr, wd = wd)\n",
    "    start = time.time()\n",
    "    losses = []\n",
    "    for i in range(epochs):\n",
    "        stats = {'epoch': i+1}\n",
    "        train_loss = train_model(model, optim, train_dl, train_size,\n",
    "                                 chunksize, batch_size, device,\n",
    "                                 loss_fn)\n",
    "        print(\"training loss: \", train_loss)\n",
    "        stats['train_loss'] = train_loss\n",
    "        loss, acc, auc_macro, auc_micro = val_loss(\n",
    "            model, valid_dl, test_size, chunksize, batch_size, device, loss_fn)\n",
    "        print('time taken: %0.2f' % (time.time() - start))\n",
    "        stats['test_loss'] = loss\n",
    "        stats['test_acc'] = acc\n",
    "        stats['test_auc_macro'] = auc_macro\n",
    "        stats['test_auc_micro'] = auc_micro\n",
    "        losses.append(stats)\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBALS\n",
    "TRAIN_FILE_NAME = '0000_part_00.gz'\n",
    "TEST_FILE_NAME = '0005_part_07.gz'\n",
    "N_USERS = 10130223\n",
    "N_ITEMS = 1175648\n",
    "N_ONTOLOGIES = 801\n",
    "N_BRANDS = 1686\n",
    "BATCH_SIZE = 50\n",
    "CHUNKSIZE = 100\n",
    "TRAIN_SIZE = 4812995 # corresponds to FILE_NAME\n",
    "TEST_SIZE = 1371989    # corresponds to FILE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose embedding size\n",
    "\n",
    "cat_cols = [USER_COL, ITEM_COL, ONTOLOGY_COL, BRAND_COL]\n",
    "cat_num_values = [N_USERS, N_ITEMS, N_ONTOLOGIES, N_BRANDS]\n",
    "embedding_sizes = choose_embedding_size(cat_cols, cat_num_values, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10130223, 150), (1175648, 150), (801, 150), (1686, 150)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/varunn/Documents/ExternalTest_Data/MAD/interim/0000_part_00.gz']\n",
      "['/Users/varunn/Documents/ExternalTest_Data/MAD/interim/0005_part_07.gz']\n"
     ]
    }
   ],
   "source": [
    "# dataset\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = InteractionsStream(\n",
    "    file_name=TRAIN_FILE_NAME, model_type='classification',\n",
    "    sample='train', chunksize=CHUNKSIZE)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n",
    "                          shuffle=False)\n",
    "\n",
    "test_dataset = InteractionsStream(\n",
    "    file_name=TEST_FILE_NAME, model_type='classification',\n",
    "    sample='test', chunksize=CHUNKSIZE)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
    "                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of numeric vars:  18\n"
     ]
    }
   ],
   "source": [
    "n_cont = len(train_loader.dataset.numeric_feats)\n",
    "print('number of numeric vars: ', n_cont)\n",
    "\n",
    "net = ProductRecommendationModel(embedding_sizes, n_cont, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProductRecommendationModel(\n",
       "  (embeddings): ModuleList(\n",
       "    (0): Embedding(10130223, 150)\n",
       "    (1): Embedding(1175648, 150)\n",
       "    (2): Embedding(801, 150)\n",
       "    (3): Embedding(1686, 150)\n",
       "  )\n",
       "  (lin1): Linear(in_features=618, out_features=300, bias=True)\n",
       "  (lin2): Linear(in_features=300, out_features=100, bias=True)\n",
       "  (lin3): Linear(in_features=100, out_features=3, bias=True)\n",
       "  (bn1): BatchNorm1d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn3): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (emb_drop): Dropout(p=0.6, inplace=False)\n",
       "  (drops): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProductRecommendationModel(\n",
       "  (embeddings): ModuleList(\n",
       "    (0): Embedding(10130223, 150)\n",
       "    (1): Embedding(1175648, 150)\n",
       "    (2): Embedding(801, 150)\n",
       "    (3): Embedding(1686, 150)\n",
       "  )\n",
       "  (lin1): Linear(in_features=618, out_features=300, bias=True)\n",
       "  (lin2): Linear(in_features=300, out_features=100, bias=True)\n",
       "  (lin3): Linear(in_features=100, out_features=3, bias=True)\n",
       "  (bn1): BatchNorm1d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn3): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (emb_drop): Dropout(p=0.6, inplace=False)\n",
       "  (drops): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_device(net, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read data\n",
      "tensor([[ 6301963,  1084662,      431,     1356],\n",
      "        [ 5588197,   674750,      783,     1147],\n",
      "        [ 7712525,   886279,      512,     1592],\n",
      "        ...,\n",
      "        [ 3451614,   787244,      431,      616],\n",
      "        [ 2818598,   303725,      104,      279],\n",
      "        [10071369,   655860,      277,     1289]])\n",
      "\n",
      "\n",
      "tensor([[8.9900e+02, 9.2000e+01, 1.7840e+03,  ..., 6.0000e+00, 1.0883e+00,\n",
      "         4.0625e-03],\n",
      "        [1.2990e+03, 2.0000e+00, 1.0490e+03,  ..., 7.0000e+00, 1.0166e+00,\n",
      "         1.4421e-02],\n",
      "        [7.9900e+02, 7.0000e+00, 1.1552e+03,  ..., 9.0000e+00, 1.0309e+00,\n",
      "         3.8264e-02],\n",
      "        ...,\n",
      "        [6.9900e+02, 2.0920e+03, 1.4653e+03,  ..., 1.4000e+01, 1.0604e+00,\n",
      "         4.2753e-01],\n",
      "        [2.4561e+04, 7.0000e+00, 2.1362e+04,  ..., 5.6000e+01, 1.1150e+00,\n",
      "         3.6240e-01],\n",
      "        [1.2990e+03, 1.0000e+01, 1.2334e+03,  ..., 2.3000e+01, 1.2392e+00,\n",
      "         3.5769e-01]])\n",
      "\n",
      "\n",
      "tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tensor([[7623743,  532609,     431,      27],\n",
      "        [1289100, 1118903,     783,      27],\n",
      "        [5236694, 1142639,     336,     381],\n",
      "        ...,\n",
      "        [7142598, 1054395,     623,    1480],\n",
      "        [6436377, 1020149,     512,    1246],\n",
      "        [8936079,  239761,     696,     444]])\n",
      "\n",
      "\n",
      "tensor([[6.9900e+02, 6.8000e+01, 1.3507e+03,  ..., 9.0000e+00, 1.1016e+00,\n",
      "         3.6411e-01],\n",
      "        [1.8990e+03, 6.4000e+01, 1.0225e+03,  ..., 6.0000e+00, 1.0258e+00,\n",
      "         4.0576e-01],\n",
      "        [9.4500e+02, 2.0000e+00, 9.4500e+02,  ..., 4.7000e+01, 1.1414e+00,\n",
      "         2.1497e-01],\n",
      "        ...,\n",
      "        [1.4990e+03, 6.7200e+02, 6.8635e+03,  ..., 8.0000e+00, 1.0287e+00,\n",
      "         0.0000e+00],\n",
      "        [9.9900e+02, 3.6000e+02, 7.6035e+02,  ..., 6.0000e+00, 1.0521e+00,\n",
      "         5.5554e-01],\n",
      "        [2.5990e+03, 4.1000e+02, 2.2856e+03,  ..., 7.0000e+00, 1.0999e+00,\n",
      "         3.0370e-02]])\n",
      "\n",
      "\n",
      "tensor([0, 1, 0,  ..., 0, 0, 1])\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "\n",
    "for x1, x2, y in islice(train_loader, 2):\n",
    "    x1, x2, y = (construct_tensor(x1), construct_tensor(x2),\n",
    "                 construct_tensor_y(y))\n",
    "    print(x1)\n",
    "    print('\\n')\n",
    "    print(x2)\n",
    "    print('\\n')\n",
    "    print(y)\n",
    "    print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read data\n",
      "tensor([[4852310,  911340,     431,    1480],\n",
      "        [ 551584,  693320,     696,    1507],\n",
      "        [6013644,  876085,     217,    1327],\n",
      "        [2954929,  630337,     329,    1222]])\n",
      "\n",
      "\n",
      "tensor([[1.0990e+03, 7.7600e+02, 2.6948e+03, 1.0000e+00, 1.3000e+01, 1.0270e+00,\n",
      "         1.0000e+00, 2.6000e+01, 1.5190e+00, 1.0000e+00, 2.3000e+01, 1.3889e+00,\n",
      "         8.8655e+00, 1.8800e+02, 1.0000e+00, 4.0000e+00, 1.0271e+00, 3.8233e+01],\n",
      "        [1.9990e+03, 9.3000e+01, 2.4667e+03, 1.0000e+00, 5.0000e+00, 2.2821e+00,\n",
      "         1.0000e+00, 8.0000e+00, 2.3345e+00, 1.0000e+00, 5.0000e+00, 2.3013e+00,\n",
      "         4.4421e-02, 4.7400e+02, 1.0000e+00, 3.0000e+00, 1.0091e+00, 1.5834e+01],\n",
      "        [5.3990e+03, 1.0150e+03, 2.6539e+03, 1.0000e+00, 1.1000e+01, 1.0242e+00,\n",
      "         1.0000e+00, 1.7000e+01, 1.2651e+00, 1.0000e+00, 1.9000e+01, 1.1541e+00,\n",
      "         3.6472e+01, 1.2100e+03, 1.0000e+00, 4.0000e+00, 1.0462e+00, 4.6897e+01],\n",
      "        [6.9990e+03, 1.4200e+02, 9.2414e+03, 1.0000e+00, 1.3000e+01, 1.7399e+00,\n",
      "         1.0000e+00, 2.0000e+01, 3.7077e+00, 1.0000e+00, 1.4000e+01, 2.3898e+00,\n",
      "         7.6399e+00, 3.6700e+02, 1.0000e+00, 4.0000e+00, 1.0485e+00, 4.6537e+01]])\n",
      "\n",
      "\n",
      "tensor([0, 0, 0, 0])\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "shape of y:  torch.Size([4])\n",
      "shape of x1:  torch.Size([4, 4])\n",
      "model output:  tensor([[-0.0711, -0.4902, -0.1096],\n",
      "        [ 0.0231,  0.2375,  0.0631],\n",
      "        [-1.2216,  0.3066,  0.7207],\n",
      "        [ 1.6102, -0.3220, -0.5119]], grad_fn=<AddmmBackward>)\n",
      "Loss:  1.2295490503311157\n",
      "tensor([[2936231,  537273,     285,     708],\n",
      "        [9021967,  391848,     423,    1147],\n",
      "        [9176139,  353310,     104,    1331],\n",
      "        [7103251,  387957,     696,    1262]])\n",
      "\n",
      "\n",
      "tensor([[4.9900e+02, 1.6300e+02, 8.2049e+02, 1.0000e+00, 8.0000e+00, 1.4736e+00,\n",
      "         1.0000e+00, 1.6000e+01, 2.2698e+00, 1.0000e+00, 1.5000e+01, 2.2934e+00,\n",
      "         4.6419e+01, 3.5700e+02, 1.0000e+00, 3.0000e+00, 1.0161e+00, 9.0450e+00],\n",
      "        [1.8990e+03, 6.8100e+02, 1.4869e+03, 1.0000e+00, 5.0000e+00, 1.1717e+00,\n",
      "         1.0000e+00, 5.6000e+01, 4.3186e+00, 1.0000e+00, 3.4000e+01, 2.6000e+00,\n",
      "         4.4224e+01, 9.8900e+02, 1.0000e+00, 5.0000e+00, 1.1788e+00, 4.6632e+01],\n",
      "        [1.0590e+04, 5.8000e+01, 1.0427e+04, 1.0000e+00, 3.0000e+00, 1.0056e+00,\n",
      "         1.0000e+00, 8.0000e+00, 1.0597e+00, 1.0000e+00, 4.0000e+00, 1.0165e+00,\n",
      "         1.1597e-02, 2.0129e+05, 1.0000e+00, 3.6000e+01, 1.1544e+00, 4.4142e+01],\n",
      "        [3.9990e+03, 6.3600e+02, 4.1824e+03, 1.0000e+00, 5.0000e+00, 1.0252e+00,\n",
      "         1.0000e+00, 2.9000e+01, 1.9373e+00, 1.0000e+00, 2.0000e+01, 1.4321e+00,\n",
      "         2.6331e+01, 6.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 2.1332e+01]])\n",
      "\n",
      "\n",
      "tensor([0, 1, 0, 0])\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "shape of y:  torch.Size([4])\n",
      "shape of x1:  torch.Size([4, 4])\n",
      "model output:  tensor([[-0.8942, -0.7563,  0.2515],\n",
      "        [ 0.2780, -0.5287, -0.1046],\n",
      "        [ 0.7131,  1.3218, -0.3916],\n",
      "        [ 0.2436, -0.3051,  0.4071]], grad_fn=<AddmmBackward>)\n",
      "Loss:  1.3488292694091797\n"
     ]
    }
   ],
   "source": [
    "for x1, x2, y in islice(test_loader, 2):\n",
    "    x1, x2, y = (construct_tensor(x1), construct_tensor(x2),\n",
    "                 construct_tensor_y(y))\n",
    "    x1 = x1.to(device)\n",
    "    x2 = x2.to(device)\n",
    "    y = y.to(device)\n",
    "    print(x1)\n",
    "    print('\\n')\n",
    "    print(x2)\n",
    "    print('\\n')\n",
    "    print(y)\n",
    "    print('\\n\\n\\n')\n",
    "    print('shape of y: ', y.size())\n",
    "    print('shape of x1: ', x1.size())\n",
    "    out = net(x1, x2)\n",
    "    print('model output: ', out)\n",
    "    loss = F.cross_entropy(out, y)\n",
    "    print('Loss: ', loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/962 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read data\n"
     ]
    }
   ],
   "source": [
    "losses = train_loop(model=net, train_dl=train_loader,\n",
    "                    valid_dl=test_loader, epochs=1,\n",
    "                    train_size=TRAIN_SIZE, test_size=TEST_SIZE,\n",
    "                    chunksize=CHUNKSIZE, batch_size=BATCH_SIZE,\n",
    "                    device=device, lr=0.02, wd=0.00001,\n",
    "                    loss_fn=F.cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
