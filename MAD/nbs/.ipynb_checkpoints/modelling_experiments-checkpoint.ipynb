{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments\n",
    "1. NN Classification\n",
    "2. NN Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "import math\n",
    "import copy\n",
    "import pickle\n",
    "import zipfile\n",
    "from textwrap import wrap\n",
    "from pathlib import Path\n",
    "from itertools import zip_longest\n",
    "from collections import defaultdict\n",
    "from urllib.error import URLError\n",
    "from urllib.request import urlopen\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch import tensor\n",
    "from torch.nn import functional as F \n",
    "from torch.optim.lr_scheduler import _LRScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/data/ExternalTest/MAD/src/\")\n",
    "from constants import *\n",
    "from metadata_utils import _find_files\n",
    "from baseline_feats_utils import feat_type_feats_dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user': ['num_interactions',\n",
       "  'mean_price_interactions',\n",
       "  'earliest_interaction_date',\n",
       "  'min_num_interactions_per_pdt',\n",
       "  'max_num_interactions_per_pdt',\n",
       "  'mean_num_interactions_per_pdt',\n",
       "  'min_num_interactions_per_ont',\n",
       "  'max_num_interactions_per_ont',\n",
       "  'mean_num_interactions_per_ont',\n",
       "  'min_num_interactions_per_brand',\n",
       "  'max_num_interactions_per_brand',\n",
       "  'mean_num_interactions_per_brand'],\n",
       " 'item': ['num_interactions',\n",
       "  'earliest_interaction_date',\n",
       "  'min_num_interactions_per_user',\n",
       "  'max_num_interactions_per_user',\n",
       "  'mean_num_interactions_per_user']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_type_feats_dct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1 - NN Classification with baseline features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import IterableDataset\n",
    "from itertools import chain, islice\n",
    "\n",
    "\n",
    "class InteractionsStream(IterableDataset):\n",
    "\n",
    "    def __init__(self, sample, model_type, file_name=None,\n",
    "                 interim_data_dir=INTERIM_DATA_DIR, user_col=USER_COL,\n",
    "                 item_col=ITEM_COL, ontology_col=ONTOLOGY_COL,\n",
    "                 brand_col=BRAND_COL, price_col=PRICE_COL, dv_col=DV_COL,\n",
    "                 date_col=DATE_COL, end_token='.gz', chunksize=10):\n",
    "\n",
    "        data_dir = interim_data_dir\n",
    "        \n",
    "        if file_name is None:\n",
    "            files = _find_files(data_dir, end_token)\n",
    "            if sample == 'train':\n",
    "                self.files = [os.path.join(data_dir, x) for x in files\n",
    "                              if not x.startswith('0005')]\n",
    "            elif sample == 'test':\n",
    "                self.files = [os.path.join(data_dir, x) for x in files\n",
    "                              if x.startswith('0005')]\n",
    "        else:\n",
    "            self.files = [os.path.join(data_dir, file_name)]\n",
    "        print(self.files)\n",
    "        \n",
    "        self.model_type = model_type\n",
    "        self.user_col = user_col\n",
    "        self.item_col = item_col\n",
    "        self.ontology_col = ontology_col\n",
    "        self.brand_col = brand_col\n",
    "        self.price_col = price_col\n",
    "        self.date_col = date_col\n",
    "        self.dv_col = dv_col\n",
    "        self.feat_type_feats_dct = feat_type_feats_dct\n",
    "        self.chunksize = chunksize\n",
    "        user_feats = ['{}_{}'.format(self.user_col, x) for x in\n",
    "                      self.feat_type_feats_dct['user']\n",
    "                      if x != 'earliest_interaction_date']\n",
    "        user_feats.append('{}_days_since_earliest_interaction'.format(\n",
    "            self.user_col))\n",
    "        item_feats = ['{}_{}'.format(self.item_col, x) for x in\n",
    "                      self.feat_type_feats_dct['item']\n",
    "                      if x != 'earliest_interaction_date']\n",
    "        item_feats.append('{}_days_since_earliest_interaction'.format(\n",
    "            self.item_col))\n",
    "        self.numeric_feats = [self.price_col] + user_feats + item_feats\n",
    "        self.cat_feats = [self.user_col, self.item_col, self.ontology_col,\n",
    "                          self.brand_col]\n",
    "        \n",
    "\n",
    "    def read_file(self, fn):\n",
    "        \n",
    "        df = pd.read_csv(fn, compression='gzip', sep='|', iterator=True,\n",
    "                         chunksize=self.chunksize)\n",
    "        return df\n",
    "    \n",
    "    def get_dv_for_classification(self, dv_lst):\n",
    "        \n",
    "        if self.model_type == 'classification':\n",
    "            return [int(x-1) for x in dv_lst]\n",
    "        else:\n",
    "            return [int(x) for x in dv_lst]\n",
    "\n",
    "    def process_data(self, fn):\n",
    "\n",
    "        print('read data')\n",
    "        data = self.read_file(fn)\n",
    "\n",
    "        for row in data:\n",
    "            x1 = row[self.cat_feats].values.tolist()\n",
    "            x2 = row[self.numeric_feats].values.tolist()\n",
    "            y = self.get_dv_for_classification(\n",
    "                    row[self.dv_col].tolist())\n",
    "            yield (x1, x2, y)\n",
    "\n",
    "    def get_stream(self, files):\n",
    "        return chain.from_iterable(map(self.process_data, files))\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self.get_stream(self.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductRecommendationModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Defines the neural network for product recommendation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embedding_sizes, n_cont, n_classes=3):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.ModuleList([nn.Embedding(categories, size) for\n",
    "                                         categories, size in embedding_sizes])\n",
    "        n_emb = sum(e.embedding_dim for e in self.embeddings)\n",
    "        self.n_emb, self.n_cont, self.n_classes = n_emb, n_cont, n_classes\n",
    "        self.lin1 = nn.Linear(self.n_emb + self.n_cont, 300)\n",
    "        self.lin2 = nn.Linear(300, 100)\n",
    "        self.lin3 = nn.Linear(100, self.n_classes)\n",
    "        self.bn1 = nn.BatchNorm1d(self.n_cont)\n",
    "        self.bn2 = nn.BatchNorm1d(300)\n",
    "        self.bn3 = nn.BatchNorm1d(100)\n",
    "        self.emb_drop = nn.Dropout(0.6)\n",
    "        self.drops = nn.Dropout(0.3)\n",
    "\n",
    "\n",
    "    def forward(self, x_cat, x_cont):\n",
    "        x = [e(x_cat[:, i]) for i, e in enumerate(self.embeddings)]\n",
    "        x = torch.cat(x, 1)\n",
    "        x = self.emb_drop(x)\n",
    "        x2 = self.bn1(x_cont)\n",
    "        x = torch.cat([x, x2], 1)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = self.drops(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(self.lin2(x))\n",
    "        x = self.drops(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.lin3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as torch_optim\n",
    "from torch import tensor\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def choose_embedding_size(cat_cols, cat_num_values, min_emb_dim=100):\n",
    "    \"\"\"\n",
    "    cat_cols: list of categorical columns\n",
    "    cat_num_values: list of number of unique values for each categorical column\n",
    "    \"\"\"\n",
    "\n",
    "    embedded_cols = dict(zip(cat_cols, cat_num_values))\n",
    "    embedding_sizes = [(n_categories, min(min_emb_dim, (n_categories+1)//2))\n",
    "                       for _, n_categories in embedded_cols.items()]\n",
    "    return embedding_sizes\n",
    "\n",
    "\n",
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "\n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl:\n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)\n",
    "\n",
    "\n",
    "def get_optimizer(model, lr = 0.001, wd = 0.0):\n",
    "\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optim = torch_optim.Adam(parameters, lr=lr, weight_decay=wd)\n",
    "    return optim\n",
    "\n",
    "\n",
    "def construct_tensor(a):\n",
    "\n",
    "    final = []\n",
    "    for i in a:\n",
    "        out = []\n",
    "        for j in i:\n",
    "            out.append(j.tolist())\n",
    "        out1 = []\n",
    "        for item in zip(*out):\n",
    "            out1.append(list(item))\n",
    "        final += out1\n",
    "    return tensor(final)\n",
    "\n",
    "\n",
    "def construct_tensor_y(a):\n",
    "\n",
    "    out = []\n",
    "    for i in a:\n",
    "        out += i.tolist()\n",
    "    return tensor(out)\n",
    "\n",
    "\n",
    "def train_model(model, optim, train_dl, train_size, chunksize, batch_size,\n",
    "                device, loss_fn=F.cross_entropy):\n",
    "\n",
    "    model.train()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    with tqdm(total=train_size // (batch_size * chunksize)) as pbar:\n",
    "        for x1, x2, y in train_dl:\n",
    "            x1, x2, y = (construct_tensor(x1), construct_tensor(x2),\n",
    "                         construct_tensor_y(y))\n",
    "            x1 = x1.to(device)\n",
    "            x2 = x2.to(device)\n",
    "            y = y.to(device)\n",
    "            batch = y.size()[0]\n",
    "            output = model(x1, x2)\n",
    "            loss = loss_fn(output, y)\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            total += batch\n",
    "            sum_loss += loss.item()\n",
    "            pbar.update(1)\n",
    "    return sum_loss/total\n",
    "\n",
    "\n",
    "def val_loss(model, valid_dl, test_size, chunksize, batch_size,\n",
    "             device, loss_fn=F.cross_entropy):\n",
    "\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    correct = 0\n",
    "    sum_auc_macro = 0\n",
    "    sum_auc_micro = 0\n",
    "    num_aucs = 0\n",
    "    with tqdm(total=test_size // (batch_size * chunksize)) as pbar:\n",
    "        for x1, x2, y in valid_dl:\n",
    "            x1, x2, y = (construct_tensor(x1), construct_tensor(x2),\n",
    "                         construct_tensor_y(y))\n",
    "            x1 = x1.to(device)\n",
    "            x2 = x2.to(device)\n",
    "            y = y.to(device)\n",
    "            batch = y.size()[0]\n",
    "            out = model(x1, x2)\n",
    "            loss = loss_fn(out, y)\n",
    "            sum_loss += loss.item()\n",
    "            total += batch\n",
    "            pred = torch.max(out, 1)[1]\n",
    "            pred_prob = F.softmax(out, dim=1)\n",
    "            y_onehot = F.one_hot(y)\n",
    "            correct += (pred == y).float().sum().item()\n",
    "            pred_prob = pred_prob.cpu().detach().numpy()\n",
    "            y_onehot = y_onehot.cpu().detach().numpy()\n",
    "            try:\n",
    "                sum_auc_macro += roc_auc_score(y_onehot, pred_prob,\n",
    "                                               average='macro')\n",
    "                sum_auc_micro += roc_auc_score(y_onehot, pred_prob,\n",
    "                                               average='micro')\n",
    "                num_aucs += 1\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            pbar.update(1)\n",
    "    print(\"valid loss %.3f, accuracy %.3f, macro auc %.3f and micro auc %.3f\" % (\n",
    "        sum_loss/total, correct/total, sum_auc_macro/num_aucs, sum_auc_micro/num_aucs))\n",
    "    return sum_loss/total, correct/total, sum_auc_macro/num_aucs, sum_auc_micro/num_aucs\n",
    "\n",
    "\n",
    "def train_loop(model, train_dl, valid_dl, epochs, train_size,\n",
    "               test_size, chunksize, batch_size, device, lr=0.01,\n",
    "               wd=0.0, loss_fn=F.cross_entropy):\n",
    "\n",
    "    optim = get_optimizer(model, lr = lr, wd = wd)\n",
    "    start = time.time()\n",
    "    losses = []\n",
    "    for i in range(epochs):\n",
    "        stats = {'epoch': i+1}\n",
    "        train_loss = train_model(model, optim, train_dl, train_size,\n",
    "                                 chunksize, batch_size, device,\n",
    "                                 loss_fn)\n",
    "        print(\"training loss: \", train_loss)\n",
    "        stats['train_loss'] = train_loss\n",
    "        loss, acc, auc_macro, auc_micro = val_loss(\n",
    "            model, valid_dl, test_size, chunksize, batch_size, device, loss_fn)\n",
    "        print('time taken: %0.2f' % (time.time() - start))\n",
    "        stats['test_loss'] = loss\n",
    "        stats['test_acc'] = acc\n",
    "        stats['test_auc_macro'] = auc_macro\n",
    "        stats['test_auc_micro'] = auc_micro\n",
    "        losses.append(stats)\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBALS\n",
    "TRAIN_FILE_NAME = '0000_part_00.gz'\n",
    "TEST_FILE_NAME = '0005_part_07.gz'\n",
    "N_USERS = 10130223\n",
    "N_ITEMS = 1175648\n",
    "N_ONTOLOGIES = 801\n",
    "N_BRANDS = 1686\n",
    "BATCH_SIZE = 50\n",
    "CHUNKSIZE = 100\n",
    "TRAIN_SIZE = 4812995 # corresponds to FILE_NAME\n",
    "TEST_SIZE = 1371989    # corresponds to FILE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose embedding size\n",
    "\n",
    "cat_cols = [USER_COL, ITEM_COL, ONTOLOGY_COL, BRAND_COL]\n",
    "cat_num_values = [N_USERS, N_ITEMS, N_ONTOLOGIES, N_BRANDS]\n",
    "embedding_sizes = choose_embedding_size(cat_cols, cat_num_values, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10130223, 150), (1175648, 150), (801, 150), (1686, 150)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/data/ExternalTest_Data/MAD/interim/0000_part_00.gz']\n",
      "['/data/ExternalTest_Data/MAD/interim/0005_part_07.gz']\n"
     ]
    }
   ],
   "source": [
    "# dataset\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = InteractionsStream(\n",
    "    file_name=TRAIN_FILE_NAME, model_type='classification',\n",
    "    sample='train', chunksize=CHUNKSIZE)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n",
    "                          shuffle=False)\n",
    "\n",
    "test_dataset = InteractionsStream(\n",
    "    file_name=TEST_FILE_NAME, model_type='classification',\n",
    "    sample='test', chunksize=CHUNKSIZE)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
    "                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of numeric vars:  18\n"
     ]
    }
   ],
   "source": [
    "n_cont = len(train_loader.dataset.numeric_feats)\n",
    "print('number of numeric vars: ', n_cont)\n",
    "\n",
    "net = ProductRecommendationModel(embedding_sizes, n_cont, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProductRecommendationModel(\n",
       "  (embeddings): ModuleList(\n",
       "    (0): Embedding(10130223, 150)\n",
       "    (1): Embedding(1175648, 150)\n",
       "    (2): Embedding(801, 150)\n",
       "    (3): Embedding(1686, 150)\n",
       "  )\n",
       "  (lin1): Linear(in_features=618, out_features=300, bias=True)\n",
       "  (lin2): Linear(in_features=300, out_features=100, bias=True)\n",
       "  (lin3): Linear(in_features=100, out_features=3, bias=True)\n",
       "  (bn1): BatchNorm1d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn3): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (emb_drop): Dropout(p=0.6, inplace=False)\n",
       "  (drops): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProductRecommendationModel(\n",
       "  (embeddings): ModuleList(\n",
       "    (0): Embedding(10130223, 150)\n",
       "    (1): Embedding(1175648, 150)\n",
       "    (2): Embedding(801, 150)\n",
       "    (3): Embedding(1686, 150)\n",
       "  )\n",
       "  (lin1): Linear(in_features=618, out_features=300, bias=True)\n",
       "  (lin2): Linear(in_features=300, out_features=100, bias=True)\n",
       "  (lin3): Linear(in_features=100, out_features=3, bias=True)\n",
       "  (bn1): BatchNorm1d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn3): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (emb_drop): Dropout(p=0.6, inplace=False)\n",
       "  (drops): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_device(net, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read data\n",
      "tensor([[ 6301963,  1084662,      431,     1356],\n",
      "        [ 5588197,   674750,      783,     1147],\n",
      "        [ 7712525,   886279,      512,     1592],\n",
      "        ...,\n",
      "        [ 3451614,   787244,      431,      616],\n",
      "        [ 2818598,   303725,      104,      279],\n",
      "        [10071369,   655860,      277,     1289]]) \t torch.Size([5000, 4])\n",
      "\n",
      "\n",
      "tensor([[8.9900e+02, 9.2000e+01, 1.7840e+03,  ..., 6.0000e+00, 1.0883e+00,\n",
      "         4.0625e-03],\n",
      "        [1.2990e+03, 2.0000e+00, 1.0490e+03,  ..., 7.0000e+00, 1.0166e+00,\n",
      "         1.4421e-02],\n",
      "        [7.9900e+02, 7.0000e+00, 1.1552e+03,  ..., 9.0000e+00, 1.0309e+00,\n",
      "         3.8264e-02],\n",
      "        ...,\n",
      "        [6.9900e+02, 2.0920e+03, 1.4653e+03,  ..., 1.4000e+01, 1.0604e+00,\n",
      "         4.2753e-01],\n",
      "        [2.4561e+04, 7.0000e+00, 2.1362e+04,  ..., 5.6000e+01, 1.1150e+00,\n",
      "         3.6240e-01],\n",
      "        [1.2990e+03, 1.0000e+01, 1.2334e+03,  ..., 2.3000e+01, 1.2392e+00,\n",
      "         3.5769e-01]])\n",
      "\n",
      "\n",
      "tensor([0, 0, 0,  ..., 0, 0, 0]) \t torch.Size([5000])\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tensor([[7623743,  532609,     431,      27],\n",
      "        [1289100, 1118903,     783,      27],\n",
      "        [5236694, 1142639,     336,     381],\n",
      "        ...,\n",
      "        [7142598, 1054395,     623,    1480],\n",
      "        [6436377, 1020149,     512,    1246],\n",
      "        [8936079,  239761,     696,     444]]) \t torch.Size([5000, 4])\n",
      "\n",
      "\n",
      "tensor([[6.9900e+02, 6.8000e+01, 1.3507e+03,  ..., 9.0000e+00, 1.1016e+00,\n",
      "         3.6411e-01],\n",
      "        [1.8990e+03, 6.4000e+01, 1.0225e+03,  ..., 6.0000e+00, 1.0258e+00,\n",
      "         4.0576e-01],\n",
      "        [9.4500e+02, 2.0000e+00, 9.4500e+02,  ..., 4.7000e+01, 1.1414e+00,\n",
      "         2.1497e-01],\n",
      "        ...,\n",
      "        [1.4990e+03, 6.7200e+02, 6.8635e+03,  ..., 8.0000e+00, 1.0287e+00,\n",
      "         0.0000e+00],\n",
      "        [9.9900e+02, 3.6000e+02, 7.6035e+02,  ..., 6.0000e+00, 1.0521e+00,\n",
      "         5.5554e-01],\n",
      "        [2.5990e+03, 4.1000e+02, 2.2856e+03,  ..., 7.0000e+00, 1.0999e+00,\n",
      "         3.0370e-02]])\n",
      "\n",
      "\n",
      "tensor([0, 1, 0,  ..., 0, 0, 1]) \t torch.Size([5000])\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "\n",
    "for x1, x2, y in islice(train_loader, 2):\n",
    "    x1, x2, y = (construct_tensor(x1), construct_tensor(x2),\n",
    "                 construct_tensor_y(y))\n",
    "    print(x1, '\\t', x1.shape)\n",
    "    print('\\n')\n",
    "    print(x2)\n",
    "    print('\\n')\n",
    "    print(y, '\\t', y.shape)\n",
    "    print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read data\n",
      "tensor([[4852310,  911340,     431,    1480],\n",
      "        [2045175,  329759,     222,    1437],\n",
      "        [3325676,  898016,     591,    1327],\n",
      "        ...,\n",
      "        [8872253,  330470,     512,    1246],\n",
      "        [4438804,  755157,     676,     285],\n",
      "        [ 218297,  751396,     512,    1246]])\n",
      "\n",
      "\n",
      "tensor([[1.0990e+03, 7.7600e+02, 2.6948e+03,  ..., 4.0000e+00, 1.0271e+00,\n",
      "         3.8233e+01],\n",
      "        [2.9900e+02, 4.7700e+02, 1.0494e+03,  ..., 5.0000e+00, 1.0723e+00,\n",
      "         1.2464e+02],\n",
      "        [5.2950e+03, 2.0500e+02, 7.3025e+03,  ..., 1.3000e+01, 1.0593e+00,\n",
      "         5.2573e+01],\n",
      "        ...,\n",
      "        [7.9900e+02, 1.4800e+02, 1.8393e+03,  ..., 4.0000e+00, 1.2493e+00,\n",
      "         2.3438e+01],\n",
      "        [1.9450e+04, 1.4000e+01, 1.6188e+04,  ..., 8.0000e+00, 1.0815e+00,\n",
      "         5.7662e+01],\n",
      "        [8.9900e+02, 3.0170e+03, 1.0183e+03,  ..., 6.0000e+00, 1.0485e+00,\n",
      "         3.6528e+00]])\n",
      "\n",
      "\n",
      "tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "shape of y:  torch.Size([5000])\n",
      "shape of x1:  torch.Size([5000, 4])\n",
      "model output:  tensor([[ 0.1260, -0.1536, -1.1293],\n",
      "        [-1.2177,  0.3609,  0.4198],\n",
      "        [-0.0077,  0.1829,  0.1271],\n",
      "        ...,\n",
      "        [ 0.1313,  1.8333, -0.9428],\n",
      "        [-0.2829,  0.0661,  0.6678],\n",
      "        [ 0.7039, -0.9060, -0.7269]], grad_fn=<AddmmBackward>)\n",
      "Loss:  1.2070536613464355\n",
      "tensor([[4903701,  651065,     305,      92],\n",
      "        [1272851,   34381,     269,     757],\n",
      "        [9367627,  495360,     695,     906],\n",
      "        ...,\n",
      "        [7363311, 1044419,     104,     808],\n",
      "        [6259246,   28778,     695,    1293],\n",
      "        [4438809,  822761,     431,    1506]])\n",
      "\n",
      "\n",
      "tensor([[4.6990e+04, 3.9000e+01, 5.2252e+04,  ..., 2.1000e+01, 1.1219e+00,\n",
      "         1.6460e+01],\n",
      "        [1.8490e+03, 8.5000e+01, 1.7685e+03,  ..., 3.0000e+00, 1.1595e+00,\n",
      "         3.4722e-05],\n",
      "        [7.9900e+02, 3.7400e+02, 1.7752e+03,  ..., 3.0000e+00, 1.0576e+00,\n",
      "         3.8426e-03],\n",
      "        ...,\n",
      "        [1.2999e+04, 4.1200e+02, 1.3171e+04,  ..., 1.4000e+01, 1.0820e+00,\n",
      "         1.0417e-02],\n",
      "        [1.7950e+03, 3.6800e+02, 1.7601e+03,  ..., 6.0000e+00, 1.0863e+00,\n",
      "         7.1766e+01],\n",
      "        [6.9900e+02, 1.7800e+02, 1.2172e+03,  ..., 6.0000e+00, 1.0627e+00,\n",
      "         1.8583e+01]])\n",
      "\n",
      "\n",
      "tensor([0, 1, 0,  ..., 0, 0, 0])\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "shape of y:  torch.Size([5000])\n",
      "shape of x1:  torch.Size([5000, 4])\n",
      "model output:  tensor([[ 0.5392,  1.0166, -0.6138],\n",
      "        [-1.3347, -1.9443,  0.1898],\n",
      "        [ 0.6006, -0.1528, -0.3030],\n",
      "        ...,\n",
      "        [ 0.2860, -0.5553, -0.3061],\n",
      "        [ 0.0516, -0.2369, -0.2896],\n",
      "        [-0.2996, -0.5008, -0.1856]], grad_fn=<AddmmBackward>)\n",
      "Loss:  1.2068145275115967\n"
     ]
    }
   ],
   "source": [
    "for x1, x2, y in islice(test_loader, 2):\n",
    "    x1, x2, y = (construct_tensor(x1), construct_tensor(x2),\n",
    "                 construct_tensor_y(y))\n",
    "    x1 = x1.to(device)\n",
    "    x2 = x2.to(device)\n",
    "    y = y.to(device)\n",
    "    print(x1)\n",
    "    print('\\n')\n",
    "    print(x2)\n",
    "    print('\\n')\n",
    "    print(y)\n",
    "    print('\\n\\n\\n')\n",
    "    print('shape of y: ', y.size())\n",
    "    print('shape of x1: ', x1.size())\n",
    "    out = net(x1, x2)\n",
    "    print('model output: ', out)\n",
    "    loss = F.cross_entropy(out, y)\n",
    "    print('Loss: ', loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/962 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 87/962 [13:31<2:15:14,  9.27s/it]"
     ]
    }
   ],
   "source": [
    "losses = train_loop(model=net, train_dl=train_loader,\n",
    "                    valid_dl=test_loader, epochs=1,\n",
    "                    train_size=TRAIN_SIZE, test_size=TEST_SIZE,\n",
    "                    chunksize=CHUNKSIZE, batch_size=BATCH_SIZE,\n",
    "                    device=device, lr=0.02, wd=0.00001,\n",
    "                    loss_fn=F.cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
